{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "@author: sumanyumuku98\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline\n",
    "from numpy import moveaxis\n",
    "from skimage import io, transform\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import plotly\n",
    "# import bokeh\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device='cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# COnverting the Multi-Class Problem into Binary-CLass\n",
    "\n",
    "# C0: Undistracted driving\n",
    "# C1-C9: Distracted driving\n",
    "# \"\"\"\n",
    "# INFO_FILE = pd.read_csv(\"state-farm-distracted-driver-detection/driver_imgs_list.csv\")\n",
    "# INFO_FILE['Binary_labels'] = INFO_FILE.apply(lambda row: 0 if row.classname=='c0' else 1, axis=1 )\n",
    "# NUM_CLASSES=2\n",
    "# INFO_FILE.head()\n",
    "# temp_dir='data/v1_cam1_no_split/'\n",
    "NUM_CLASSES=10\n",
    "CLASS_LABELS=['c' + str(i) for i in range(10)]\n",
    "CLASSES_LIST=['Drive Safe', 'Text Right', 'Talk Right', 'Text Left', 'Talk Left',\n",
    "              'Adjust Radio', 'Drink', 'Reach Behind', 'Hair & Makeup', 'Talk Passenger']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'\n",
    "CAMERA1='Camera 1'\n",
    "CAMERA2='Camera 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Models\n",
    "#######################################################\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad=False\n",
    "mobilenet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)\n",
    "# mobilenet.classifier.add_module(\"2\",torch.nn.Softmax(dim=-1))\n",
    "########################################################\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad=False\n",
    "resnet.fc = torch.nn.Linear(2048,NUM_CLASSES)\n",
    "# resnet.add_module(\"softmax\",torch.nn.Softmax(dim=-1))\n",
    "########################################################\n",
    "vgg = models.vgg16(pretrained=True)\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad=False\n",
    "vgg.classifier[6] = torch.nn.Linear(4096,NUM_CLASSES)\n",
    "# vgg.classifier.add_module(\"softmax\",torch.nn.Softmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezenet = models.squeezenet1_1(pretrained=True)\n",
    "for param in squeezenet.parameters():\n",
    "    param.requires_grad=False\n",
    "squeezenet.classifier[1]=torch.nn.Conv2d(512,NUM_CLASSES,kernel_size=(1,1),stride=(1,1))\n",
    "    \n",
    "#############################\n",
    "# mnasnet = models.mnasnet1_0(pretrained=True)\n",
    "# for param in mnasnet.parameters():\n",
    "#     param.requires_grad=False\n",
    "# mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)\n",
    "# mnasnet.classifier.add_module(\"2\",torch.nn.Softmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocess for pytorch pretrained models\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(sample):\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    transform=  transforms.Compose([\n",
    "        transforms.RandomResizedCrop(299),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,])\n",
    "    \n",
    "    img = sample['image']\n",
    "    label = sample['label']\n",
    "    \n",
    "#     print(label, type(label))\n",
    "    \n",
    "    sample['image'] = transform(img)\n",
    "    sample['label'] = torch.as_tensor(label)\n",
    "    \n",
    "    return sample\n",
    "    \n",
    "class Driver_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self,IMAGE_PREDIR,preprocess = None, mode='train',split=0.8):\n",
    "        \n",
    "        self.root_dir = IMAGE_PREDIR\n",
    "        self.transform = preprocess\n",
    "        self.mode=mode\n",
    "        self.split=split\n",
    "        self.totalTrainImages=[]\n",
    "        self.totalTrainLabels=[]\n",
    "        self.totalTestImages=[]\n",
    "        self.totalTestLabels=[]\n",
    "        self.images=None\n",
    "        self.labels=None\n",
    "        \n",
    "        for c in CLASS_LABELS:\n",
    "            for name in glob.glob(self.root_dir+CAMERA1+'/train/'+c+'/*.jpg'):\n",
    "                self.totalTrainImages.append(name)\n",
    "                self.totalTrainLabels.append(CLASS_LABELS.index(c))\n",
    "            for name in glob.glob(self.root_dir+CAMERA2+'/train/'+c+'/*.jpg'):\n",
    "                self.totalTrainImages.append(name)\n",
    "                self.totalTrainLabels.append(CLASS_LABELS.index(c))\n",
    "                \n",
    "            for name in glob.glob(self.root_dir+CAMERA1+'/test/'+c+'/*.jpg'):\n",
    "                self.totalTestImages.append(name)\n",
    "                self.totalTestLabels.append(CLASS_LABELS.index(c))\n",
    "            for name in glob.glob(self.root_dir+CAMERA2+'/test/'+c+'/*.jpg'):\n",
    "                self.totalTestImages.append(name)\n",
    "                self.totalTestLabels.append(CLASS_LABELS.index(c))\n",
    "        \n",
    "        shuffle_list=list(zip(self.totalTrainImages,self.totalTrainLabels))\n",
    "        random.shuffle(shuffle_list)\n",
    "        self.totalTrainImages,self.totalTrainLabels=zip(*shuffle_list)\n",
    "        \n",
    "        if self.mode=='train':\n",
    "            length=len(self.totalTrainImages)\n",
    "            self.images= self.totalTrainImages[:int(self.split*length)]\n",
    "            self.labels=self.totalTrainLabels[:int(self.split*length)]\n",
    "        \n",
    "        elif self.mode=='val':\n",
    "            length=len(self.totalTrainImages)\n",
    "            self.images= self.totalTrainImages[int(self.split*length):]\n",
    "            self.labels=self.totalTrainLabels[int(self.split*length):]\n",
    "        else:\n",
    "            self.images=self.totalTestImages\n",
    "            self.labels=self.totalTestLabels\n",
    "\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "#         print(type(label))\n",
    "        img_name = self.images[idx]\n",
    "        img = Image.open(img_name)\n",
    "\n",
    "        sample = {'image': img, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def listcheck(self):\n",
    "        return self.images,self.labels\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData= Driver_Dataset(IMAGE_PREDIR,preprocess,'train',0.95)\n",
    "valData=Driver_Dataset(IMAGE_PREDIR,preprocess,'val',0.95)\n",
    "trainLoader=DataLoader(trainData,batch_size=16,num_workers=4)\n",
    "valLoader=DataLoader(valData,batch_size=16,num_workers=4)\n",
    "# DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crossloss=torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,dataloaderList,epochs, device = 'cpu',saveName=None):\n",
    "    model.to(device)\n",
    "    trainloader=dataloaderList[0]\n",
    "    valloader=dataloaderList[1]\n",
    "    paramsToUpdate=[]\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            paramsToUpdate.append(param)\n",
    "    \n",
    "    optimizer=torch.optim.SGD(paramsToUpdate,lr=1e-4)\n",
    "\n",
    "    valAccList=[]\n",
    "    \n",
    "    print('Start Training...')\n",
    "    for epoch in range(epochs):\n",
    "        running_loss=0\n",
    "        \n",
    "        for i_batch, data in enumerate(trainloader):\n",
    "            \n",
    "\n",
    "            images=Variable(data['image'],requires_grad=True).to(device)\n",
    "            labels=Variable(data['label']).to(device)\n",
    "            \n",
    "            outputs=model(images)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss=Crossloss(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss+=loss.item()\n",
    "            \n",
    "            # Print Training Statistics\n",
    "            del images,labels,outputs\n",
    "            \n",
    "            if i_batch%100==99:\n",
    "                print('[%2d,%5d] Training Loss: %.3f'  % \n",
    "                      (epoch+1,i_batch+1,running_loss/100))\n",
    "                running_loss=0\n",
    "                \n",
    "        print('Validating the model')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valPreds=[]\n",
    "            valLabels=[]\n",
    "            for i_batch, data in enumerate(valloader):\n",
    "                \n",
    "                images= data['image'].to(device)\n",
    "                labels= data['label'].numpy()\n",
    "                \n",
    "                preds=model(images)\n",
    "                preds=preds.cpu().numpy()\n",
    "                \n",
    "                pred_labels=np.argmax(preds,axis=-1)\n",
    "                valPreds.append(pred_labels)\n",
    "                valLabels.append(labels)\n",
    "            \n",
    "            valPreds=np.concatenate(valPreds)\n",
    "            valLabels=np.concatenate(valLabels)\n",
    "            size=valPreds.shape[0]\n",
    "            running_corrects=np.sum(valPreds==valLabels)\n",
    "        \n",
    "            acc=float(running_corrects)/size\n",
    "            valAccList.append(acc)\n",
    "            print('Accuracy after epoch %2d is %.3f' % (epoch+1,acc))\n",
    "#             print(valPreds)\n",
    "#             print(valLabels)\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    print(\"Saving Model\")\n",
    "    torch.save(model.state_dict(),'Model_weights/'+saveName+'.pt')\n",
    "    \n",
    "    return model,valAccList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "[ 1,  100] Training Loss: 2.302\n",
      "[ 1,  200] Training Loss: 2.284\n",
      "[ 1,  300] Training Loss: 2.268\n",
      "[ 1,  400] Training Loss: 2.266\n",
      "[ 1,  500] Training Loss: 2.277\n",
      "[ 1,  600] Training Loss: 2.293\n",
      "[ 1,  700] Training Loss: 2.271\n",
      "Validating the model\n",
      "Accuracy after epoch  1 is 0.175\n",
      "[ 2,  100] Training Loss: 2.264\n",
      "[ 2,  200] Training Loss: 2.270\n",
      "[ 2,  300] Training Loss: 2.255\n",
      "[ 2,  400] Training Loss: 2.233\n",
      "[ 2,  500] Training Loss: 2.244\n",
      "[ 2,  600] Training Loss: 2.256\n",
      "[ 2,  700] Training Loss: 2.245\n",
      "Validating the model\n",
      "Accuracy after epoch  2 is 0.197\n",
      "[ 3,  100] Training Loss: 2.221\n",
      "[ 3,  200] Training Loss: 2.237\n",
      "[ 3,  300] Training Loss: 2.222\n",
      "[ 3,  400] Training Loss: 2.223\n",
      "[ 3,  500] Training Loss: 2.217\n",
      "[ 3,  600] Training Loss: 2.224\n",
      "[ 3,  700] Training Loss: 2.213\n",
      "Validating the model\n",
      "Accuracy after epoch  3 is 0.197\n",
      "[ 4,  100] Training Loss: 2.207\n",
      "[ 4,  200] Training Loss: 2.210\n",
      "[ 4,  300] Training Loss: 2.207\n",
      "[ 4,  400] Training Loss: 2.182\n",
      "[ 4,  500] Training Loss: 2.200\n",
      "[ 4,  600] Training Loss: 2.222\n",
      "[ 4,  700] Training Loss: 2.191\n",
      "Validating the model\n",
      "Accuracy after epoch  4 is 0.199\n",
      "[ 5,  100] Training Loss: 2.185\n",
      "[ 5,  200] Training Loss: 2.209\n",
      "[ 5,  300] Training Loss: 2.175\n",
      "[ 5,  400] Training Loss: 2.175\n",
      "[ 5,  500] Training Loss: 2.179\n",
      "[ 5,  600] Training Loss: 2.181\n",
      "[ 5,  700] Training Loss: 2.174\n",
      "Validating the model\n",
      "Accuracy after epoch  5 is 0.221\n",
      "[ 6,  100] Training Loss: 2.176\n",
      "[ 6,  200] Training Loss: 2.189\n",
      "[ 6,  300] Training Loss: 2.165\n",
      "[ 6,  400] Training Loss: 2.159\n",
      "[ 6,  500] Training Loss: 2.166\n",
      "[ 6,  600] Training Loss: 2.180\n",
      "[ 6,  700] Training Loss: 2.157\n",
      "Validating the model\n",
      "Accuracy after epoch  6 is 0.207\n",
      "[ 7,  100] Training Loss: 2.152\n",
      "[ 7,  200] Training Loss: 2.175\n",
      "[ 7,  300] Training Loss: 2.155\n",
      "[ 7,  400] Training Loss: 2.138\n",
      "[ 7,  500] Training Loss: 2.149\n",
      "[ 7,  600] Training Loss: 2.164\n",
      "[ 7,  700] Training Loss: 2.144\n",
      "Validating the model\n",
      "Accuracy after epoch  7 is 0.209\n",
      "[ 8,  100] Training Loss: 2.146\n",
      "[ 8,  200] Training Loss: 2.166\n",
      "[ 8,  300] Training Loss: 2.121\n",
      "[ 8,  400] Training Loss: 2.109\n",
      "[ 8,  500] Training Loss: 2.137\n",
      "[ 8,  600] Training Loss: 2.149\n",
      "[ 8,  700] Training Loss: 2.133\n",
      "Validating the model\n",
      "Accuracy after epoch  8 is 0.221\n",
      "[ 9,  100] Training Loss: 2.130\n",
      "[ 9,  200] Training Loss: 2.133\n",
      "[ 9,  300] Training Loss: 2.117\n",
      "[ 9,  400] Training Loss: 2.108\n",
      "[ 9,  500] Training Loss: 2.138\n",
      "[ 9,  600] Training Loss: 2.142\n",
      "[ 9,  700] Training Loss: 2.124\n",
      "Validating the model\n",
      "Accuracy after epoch  9 is 0.225\n",
      "[10,  100] Training Loss: 2.111\n",
      "[10,  200] Training Loss: 2.138\n",
      "[10,  300] Training Loss: 2.102\n",
      "[10,  400] Training Loss: 2.100\n",
      "[10,  500] Training Loss: 2.114\n",
      "[10,  600] Training Loss: 2.111\n",
      "[10,  700] Training Loss: 2.106\n",
      "Validating the model\n",
      "Accuracy after epoch 10 is 0.213\n",
      "Finished Training\n",
      "Saving Model\n"
     ]
    }
   ],
   "source": [
    "squeezenetTrainedModel,valAcc=  train(squeezenet,[trainLoader,valLoader],10,device,'squeezenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "[ 1,  100] Training Loss: 2.348\n",
      "[ 1,  200] Training Loss: 2.306\n",
      "[ 1,  300] Training Loss: 2.278\n",
      "[ 1,  400] Training Loss: 2.251\n",
      "[ 1,  500] Training Loss: 2.264\n",
      "[ 1,  600] Training Loss: 2.255\n",
      "[ 1,  700] Training Loss: 2.241\n",
      "Validating the model\n",
      "Accuracy after epoch  1 is 0.186\n",
      "[ 2,  100] Training Loss: 2.241\n",
      "[ 2,  200] Training Loss: 2.270\n",
      "[ 2,  300] Training Loss: 2.233\n",
      "[ 2,  400] Training Loss: 2.228\n",
      "[ 2,  500] Training Loss: 2.235\n",
      "[ 2,  600] Training Loss: 2.234\n",
      "[ 2,  700] Training Loss: 2.236\n",
      "Validating the model\n",
      "Accuracy after epoch  2 is 0.167\n",
      "[ 3,  100] Training Loss: 2.228\n",
      "[ 3,  200] Training Loss: 2.251\n",
      "[ 3,  300] Training Loss: 2.222\n",
      "[ 3,  400] Training Loss: 2.229\n",
      "[ 3,  500] Training Loss: 2.227\n",
      "[ 3,  600] Training Loss: 2.245\n",
      "[ 3,  700] Training Loss: 2.221\n",
      "Validating the model\n",
      "Accuracy after epoch  3 is 0.174\n",
      "[ 4,  100] Training Loss: 2.230\n",
      "[ 4,  200] Training Loss: 2.243\n",
      "[ 4,  300] Training Loss: 2.230\n",
      "[ 4,  400] Training Loss: 2.214\n",
      "[ 4,  500] Training Loss: 2.225\n",
      "[ 4,  600] Training Loss: 2.219\n",
      "[ 4,  700] Training Loss: 2.217\n",
      "Validating the model\n",
      "Accuracy after epoch  4 is 0.193\n",
      "[ 5,  100] Training Loss: 2.216\n",
      "[ 5,  200] Training Loss: 2.240\n",
      "[ 5,  300] Training Loss: 2.210\n",
      "[ 5,  400] Training Loss: 2.208\n",
      "[ 5,  500] Training Loss: 2.217\n",
      "[ 5,  600] Training Loss: 2.211\n",
      "[ 5,  700] Training Loss: 2.205\n",
      "Validating the model\n",
      "Accuracy after epoch  5 is 0.183\n",
      "[ 6,  100] Training Loss: 2.210\n",
      "[ 6,  200] Training Loss: 2.225\n",
      "[ 6,  300] Training Loss: 2.200\n",
      "[ 6,  400] Training Loss: 2.203\n",
      "[ 6,  500] Training Loss: 2.208\n",
      "[ 6,  600] Training Loss: 2.215\n",
      "[ 6,  700] Training Loss: 2.200\n",
      "Validating the model\n",
      "Accuracy after epoch  6 is 0.204\n",
      "[ 7,  100] Training Loss: 2.203\n",
      "[ 7,  200] Training Loss: 2.217\n",
      "[ 7,  300] Training Loss: 2.194\n",
      "[ 7,  400] Training Loss: 2.203\n",
      "[ 7,  500] Training Loss: 2.201\n",
      "[ 7,  600] Training Loss: 2.203\n",
      "[ 7,  700] Training Loss: 2.188\n",
      "Validating the model\n",
      "Accuracy after epoch  7 is 0.193\n",
      "[ 8,  100] Training Loss: 2.196\n",
      "[ 8,  200] Training Loss: 2.212\n",
      "[ 8,  300] Training Loss: 2.194\n",
      "[ 8,  400] Training Loss: 2.193\n",
      "[ 8,  500] Training Loss: 2.204\n",
      "[ 8,  600] Training Loss: 2.190\n",
      "[ 8,  700] Training Loss: 2.181\n",
      "Validating the model\n",
      "Accuracy after epoch  8 is 0.196\n",
      "[ 9,  100] Training Loss: 2.191\n",
      "[ 9,  200] Training Loss: 2.203\n",
      "[ 9,  300] Training Loss: 2.179\n",
      "[ 9,  400] Training Loss: 2.176\n",
      "[ 9,  500] Training Loss: 2.184\n",
      "[ 9,  600] Training Loss: 2.184\n",
      "[ 9,  700] Training Loss: 2.171\n",
      "Validating the model\n",
      "Accuracy after epoch  9 is 0.196\n",
      "[10,  100] Training Loss: 2.186\n",
      "[10,  200] Training Loss: 2.206\n",
      "[10,  300] Training Loss: 2.173\n",
      "[10,  400] Training Loss: 2.173\n",
      "[10,  500] Training Loss: 2.182\n",
      "[10,  600] Training Loss: 2.188\n",
      "[10,  700] Training Loss: 2.173\n",
      "Validating the model\n",
      "Accuracy after epoch 10 is 0.199\n",
      "Finished Training\n",
      "Saving Model\n"
     ]
    }
   ],
   "source": [
    "mobilenetTrainedModel,valAcc=  train(mobilenet,[trainLoader,valLoader],10,device,'mobilenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "[ 1,  100] Training Loss: 2.301\n",
      "[ 1,  200] Training Loss: 2.274\n",
      "[ 1,  300] Training Loss: 2.240\n",
      "[ 1,  400] Training Loss: 2.242\n",
      "[ 1,  500] Training Loss: 2.244\n",
      "[ 1,  600] Training Loss: 2.239\n",
      "[ 1,  700] Training Loss: 2.236\n",
      "Validating the model\n",
      "Accuracy after epoch  1 is 0.189\n",
      "[ 2,  100] Training Loss: 2.233\n",
      "[ 2,  200] Training Loss: 2.249\n",
      "[ 2,  300] Training Loss: 2.223\n",
      "[ 2,  400] Training Loss: 2.231\n",
      "[ 2,  500] Training Loss: 2.241\n",
      "[ 2,  600] Training Loss: 2.232\n",
      "[ 2,  700] Training Loss: 2.221\n",
      "Validating the model\n",
      "Accuracy after epoch  2 is 0.189\n",
      "[ 3,  100] Training Loss: 2.228\n",
      "[ 3,  200] Training Loss: 2.240\n",
      "[ 3,  300] Training Loss: 2.214\n",
      "[ 3,  400] Training Loss: 2.222\n",
      "[ 3,  500] Training Loss: 2.229\n",
      "[ 3,  600] Training Loss: 2.226\n",
      "[ 3,  700] Training Loss: 2.212\n",
      "Validating the model\n",
      "Accuracy after epoch  3 is 0.189\n",
      "[ 4,  100] Training Loss: 2.217\n",
      "[ 4,  200] Training Loss: 2.231\n",
      "[ 4,  300] Training Loss: 2.211\n",
      "[ 4,  400] Training Loss: 2.211\n",
      "[ 4,  500] Training Loss: 2.220\n",
      "[ 4,  600] Training Loss: 2.214\n",
      "[ 4,  700] Training Loss: 2.200\n",
      "Validating the model\n",
      "Accuracy after epoch  4 is 0.188\n",
      "[ 5,  100] Training Loss: 2.208\n",
      "[ 5,  200] Training Loss: 2.228\n",
      "[ 5,  300] Training Loss: 2.201\n",
      "[ 5,  400] Training Loss: 2.202\n",
      "[ 5,  500] Training Loss: 2.212\n",
      "[ 5,  600] Training Loss: 2.208\n",
      "[ 5,  700] Training Loss: 2.195\n",
      "Validating the model\n",
      "Accuracy after epoch  5 is 0.191\n",
      "[ 6,  100] Training Loss: 2.196\n",
      "[ 6,  200] Training Loss: 2.213\n",
      "[ 6,  300] Training Loss: 2.195\n",
      "[ 6,  400] Training Loss: 2.198\n",
      "[ 6,  500] Training Loss: 2.203\n",
      "[ 6,  600] Training Loss: 2.202\n",
      "[ 6,  700] Training Loss: 2.188\n",
      "Validating the model\n",
      "Accuracy after epoch  6 is 0.196\n",
      "[ 7,  100] Training Loss: 2.193\n",
      "[ 7,  200] Training Loss: 2.211\n",
      "[ 7,  300] Training Loss: 2.187\n",
      "[ 7,  400] Training Loss: 2.191\n",
      "[ 7,  500] Training Loss: 2.191\n",
      "[ 7,  600] Training Loss: 2.197\n",
      "[ 7,  700] Training Loss: 2.183\n",
      "Validating the model\n",
      "Accuracy after epoch  7 is 0.191\n",
      "[ 8,  100] Training Loss: 2.185\n",
      "[ 8,  200] Training Loss: 2.206\n",
      "[ 8,  300] Training Loss: 2.176\n",
      "[ 8,  400] Training Loss: 2.183\n",
      "[ 8,  500] Training Loss: 2.184\n",
      "[ 8,  600] Training Loss: 2.187\n",
      "[ 8,  700] Training Loss: 2.173\n",
      "Validating the model\n",
      "Accuracy after epoch  8 is 0.207\n",
      "[ 9,  100] Training Loss: 2.176\n",
      "[ 9,  200] Training Loss: 2.197\n",
      "[ 9,  300] Training Loss: 2.177\n",
      "[ 9,  400] Training Loss: 2.176\n",
      "[ 9,  500] Training Loss: 2.179\n",
      "[ 9,  600] Training Loss: 2.180\n",
      "[ 9,  700] Training Loss: 2.170\n",
      "Validating the model\n",
      "Accuracy after epoch  9 is 0.199\n",
      "[10,  100] Training Loss: 2.167\n",
      "[10,  200] Training Loss: 2.190\n",
      "[10,  300] Training Loss: 2.166\n",
      "[10,  400] Training Loss: 2.166\n",
      "[10,  500] Training Loss: 2.175\n",
      "[10,  600] Training Loss: 2.176\n",
      "[10,  700] Training Loss: 2.160\n",
      "Validating the model\n",
      "Accuracy after epoch 10 is 0.201\n",
      "Finished Training\n",
      "Saving Model\n"
     ]
    }
   ],
   "source": [
    "resnetTrainedModel,valAcc=  train(resnet,[trainLoader,valLoader],10,device,'resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "[ 1,  100] Training Loss: 2.366\n",
      "[ 1,  200] Training Loss: 2.316\n",
      "[ 1,  300] Training Loss: 2.301\n",
      "[ 1,  400] Training Loss: 2.267\n",
      "[ 1,  500] Training Loss: 2.264\n",
      "[ 1,  600] Training Loss: 2.264\n",
      "[ 1,  700] Training Loss: 2.252\n",
      "Validating the model\n",
      "Accuracy after epoch  1 is 0.183\n",
      "[ 2,  100] Training Loss: 2.238\n",
      "[ 2,  200] Training Loss: 2.251\n",
      "[ 2,  300] Training Loss: 2.241\n",
      "[ 2,  400] Training Loss: 2.247\n",
      "[ 2,  500] Training Loss: 2.237\n",
      "[ 2,  600] Training Loss: 2.236\n",
      "[ 2,  700] Training Loss: 2.216\n",
      "Validating the model\n",
      "Accuracy after epoch  2 is 0.185\n",
      "[ 3,  100] Training Loss: 2.236\n",
      "[ 3,  200] Training Loss: 2.228\n",
      "[ 3,  300] Training Loss: 2.219\n",
      "[ 3,  400] Training Loss: 2.221\n",
      "[ 3,  500] Training Loss: 2.222\n",
      "[ 3,  600] Training Loss: 2.223\n",
      "[ 3,  700] Training Loss: 2.205\n",
      "Validating the model\n",
      "Accuracy after epoch  3 is 0.191\n",
      "[ 4,  100] Training Loss: 2.211\n",
      "[ 4,  200] Training Loss: 2.214\n",
      "[ 4,  300] Training Loss: 2.208\n",
      "[ 4,  400] Training Loss: 2.194\n",
      "[ 4,  500] Training Loss: 2.212\n",
      "[ 4,  600] Training Loss: 2.206\n",
      "[ 4,  700] Training Loss: 2.182\n",
      "Validating the model\n",
      "Accuracy after epoch  4 is 0.194\n",
      "[ 5,  100] Training Loss: 2.191\n",
      "[ 5,  200] Training Loss: 2.205\n",
      "[ 5,  300] Training Loss: 2.193\n",
      "[ 5,  400] Training Loss: 2.178\n",
      "[ 5,  500] Training Loss: 2.202\n",
      "[ 5,  600] Training Loss: 2.190\n",
      "[ 5,  700] Training Loss: 2.176\n",
      "Validating the model\n",
      "Accuracy after epoch  5 is 0.207\n",
      "[ 6,  100] Training Loss: 2.179\n",
      "[ 6,  200] Training Loss: 2.189\n",
      "[ 6,  300] Training Loss: 2.162\n",
      "[ 6,  400] Training Loss: 2.155\n",
      "[ 6,  500] Training Loss: 2.179\n",
      "[ 6,  600] Training Loss: 2.180\n",
      "[ 6,  700] Training Loss: 2.163\n",
      "Validating the model\n",
      "Accuracy after epoch  6 is 0.221\n",
      "[ 7,  100] Training Loss: 2.167\n",
      "[ 7,  200] Training Loss: 2.188\n",
      "[ 7,  300] Training Loss: 2.154\n",
      "[ 7,  400] Training Loss: 2.150\n",
      "[ 7,  500] Training Loss: 2.171\n",
      "[ 7,  600] Training Loss: 2.157\n",
      "[ 7,  700] Training Loss: 2.147\n",
      "Validating the model\n",
      "Accuracy after epoch  7 is 0.237\n",
      "[ 8,  100] Training Loss: 2.140\n",
      "[ 8,  200] Training Loss: 2.175\n",
      "[ 8,  300] Training Loss: 2.148\n",
      "[ 8,  400] Training Loss: 2.134\n",
      "[ 8,  500] Training Loss: 2.155\n",
      "[ 8,  600] Training Loss: 2.158\n",
      "[ 8,  700] Training Loss: 2.141\n",
      "Validating the model\n",
      "Accuracy after epoch  8 is 0.226\n",
      "[ 9,  100] Training Loss: 2.150\n",
      "[ 9,  200] Training Loss: 2.155\n",
      "[ 9,  300] Training Loss: 2.132\n",
      "[ 9,  400] Training Loss: 2.131\n",
      "[ 9,  500] Training Loss: 2.135\n",
      "[ 9,  600] Training Loss: 2.133\n",
      "[ 9,  700] Training Loss: 2.128\n",
      "Validating the model\n",
      "Accuracy after epoch  9 is 0.204\n",
      "[10,  100] Training Loss: 2.127\n",
      "[10,  200] Training Loss: 2.148\n",
      "[10,  300] Training Loss: 2.124\n",
      "[10,  400] Training Loss: 2.127\n",
      "[10,  500] Training Loss: 2.126\n",
      "[10,  600] Training Loss: 2.146\n",
      "[10,  700] Training Loss: 2.119\n",
      "Validating the model\n",
      "Accuracy after epoch 10 is 0.231\n",
      "Finished Training\n",
      "Saving Model\n"
     ]
    }
   ],
   "source": [
    "vggTrainedModel,valAcc=  train(vgg,[trainLoader,valLoader],10,device,'vgg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
