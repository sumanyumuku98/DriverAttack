 1/1: import pandas as pd
 1/2:
df = pd.read_csv('HomeA-meter2_2016.csv')
df.head()
 1/3: import pandas as pd
 4/1: import pandas as pd
 5/1: import pandas as pd
 6/1: import pandas as pd
 7/1: import pandas as pd
 7/2:
df = pd.read_csv('HomeA-meter2_2016.csv')
df.head()
 7/3:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
 7/4: df = df.drop('use [kW]', axis = 1)
 7/5: df = df.drop('gen [kW]', axis = 1)
 7/6: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
 7/7:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
 7/8: df = df.drop('Date & Time', axis = 1)
 7/9: df.head()
7/10: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
7/11: df.head()
7/12:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
7/13: df.head()
7/14: df.count()
7/15: df.info()
7/16: df.desc()
7/17: df.describe()
 8/1:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
 9/1:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
10/1:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
10/2:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
import scipy.misc.imsave() as imsave

import matplotlib.pyplot as plt
import os
import numpy as np
10/3:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
import scipy.misc.imsave as imsave

import matplotlib.pyplot as plt
import os
import numpy as np
10/4:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
11/1:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
12/1:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
12/2:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
from scipy.misc.pilutil import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
12/3:
import torch
from torch import nn
from torch.autograd import Variable
from torch.autograd.gradcheck import zero_gradients
from torch.utils.data import Dataset, DataLoader

import torchvision.transforms as T
from torchvision.models.inception import inception_v3

from PIL import Image
# from scipy.misc.pilutil import imsave

import matplotlib.pyplot as plt
import os
import numpy as np
12/4:
classes = eval(open('classes.txt').read())
trans = T.Compose([T.ToTensor(), T.Lambda(lambda t: t.unsqueeze(0))])
reverse_trans = lambda x: np.asarray(T.ToPILImage()(x))

eps = 2 * 8 / 225. 
steps = 40
norm = float('inf')
step_alpha = 0.01 

model = inception_v3(pretrained=True, transform_input=True).cuda()
loss = nn.CrossEntropyLoss()
model.eval();
12/5:
def load_image(img_path):
    img = trans(Image.open(img_path).convert('RGB'))
    return img

def get_class(img):
    x = Variable(img, volatile=True).cuda()
    cls = model(x).data.max(1)[1].cpu().numpy()[0]
    return classes[cls]

def draw_result(img, noise, adv_img):
    fig, ax = plt.subplots(1, 3, figsize=(15, 10))
    orig_class, attack_class = get_class(img), get_class(adv_img)
    ax[0].imshow(reverse_trans(img[0]))
    ax[0].set_title('Original image: {}'.format(orig_class.split(',')[0]))
    ax[1].imshow(noise[0].cpu().numpy().transpose(1, 2, 0))
    ax[1].set_title('Attacking noise')
    ax[2].imshow(reverse_trans(adv_img[0]))
    ax[2].set_title('Adversarial example: {}'.format(attack_class))
    for i in range(3):
        ax[i].set_axis_off()
    plt.tight_layout()
    plt.show()
12/6:
def non_targeted_attack(img):
    img = img.cuda()
    label = torch.zeros(1, 1).cuda()
    
    x, y = Variable(img, requires_grad=True), Variable(label)
    for step in range(steps):
        zero_gradients(x)
        out = model(x)
        y.data = out.data.max(1)[1]
        _loss = loss(out, y)
        _loss.backward()
        normed_grad = step_alpha * torch.sign(x.grad.data)
        step_adv = x.data + normed_grad
        adv = step_adv - img
        adv = torch.clamp(adv, -eps, eps)
        result = img + adv
        result = torch.clamp(result, 0.0, 1.0)
        x.data = result
    return result.cpu(), adv.cpu()
12/7:
img = load_image('input.png')
adv_img, noise = non_targeted_attack(img)
draw_result(img, noise, adv_img)
12/8:
def targeted_attack(img, label):
    img = img.cuda()
    label = torch.Tensor([label]).long().cuda()
    
    x, y = Variable(img, requires_grad=True), Variable(label)
    for step in range(steps):
        zero_gradients(x)
        out = model(x)
        _loss = loss(out, y)
        _loss.backward()
        normed_grad = step_alpha * torch.sign(x.grad.data)
        step_adv = x.data - normed_grad
        adv = step_adv - img
        adv = torch.clamp(adv, -eps, eps)
        result = img + adv
        result = torch.clamp(result, 0.0, 1.0)
        x.data = result
    return result.cpu(), adv.cpu()
12/9:
img = load_image('input.png')
adv_img, noise = targeted_attack(img, 859)
draw_result(img, noise, adv_img)
13/1:
from __future__ import print_function

import os
import argparse

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from advertorch.context import ctx_noparamgrad_and_eval
from advertorch.test_utils import LeNet5
from advertorch_examples.utils import get_mnist_train_loader
from advertorch_examples.utils import get_mnist_test_loader
from advertorch_examples.utils import TRAINED_MODEL_PATH
13/2:
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Train MNIST')
    parser.add_argument('--seed', default=0, type=int)
    parser.add_argument('--mode', default="cln", help="cln | adv")
    parser.add_argument('--train_batch_size', default=50, type=int)
    parser.add_argument('--test_batch_size', default=1000, type=int)
    parser.add_argument('--log_interval', default=200, type=int)
    args = parser.parse_args()

    torch.manual_seed(args.seed)
    use_cuda = torch.cuda.is_available()
    device = torch.device("cuda" if use_cuda else "cpu")
    if args.mode == "cln":
        flag_advtrain = False
        nb_epoch = 10
        model_filename = "mnist_lenet5_clntrained.pt"
    elif args.mode == "adv":
        flag_advtrain = True
        nb_epoch = 90
        model_filename = "mnist_lenet5_advtrained.pt"
    else:
        raise

    train_loader = get_mnist_train_loader(
        batch_size=args.train_batch_size, shuffle=True)
    test_loader = get_mnist_test_loader(
        batch_size=args.test_batch_size, shuffle=False)

    model = LeNet5()
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    if flag_advtrain:
        from advertorch.attacks import LinfPGDAttack
        adversary = LinfPGDAttack(
            model, loss_fn=nn.CrossEntropyLoss(reduction="sum"), eps=0.3,
            nb_iter=40, eps_iter=0.01, rand_init=True, clip_min=0.0,
            clip_max=1.0, targeted=False)

    for epoch in range(nb_epoch):
        model.train()
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            ori = data
            if flag_advtrain:
                # when performing attack, the model needs to be in eval mode
                # also the parameters should be accumulating gradients
                with ctx_noparamgrad_and_eval(model):
                    data = adversary.perturb(data, target)

            optimizer.zero_grad()
            output = model(data)
            loss = F.cross_entropy(
                output, target, reduction='elementwise_mean')
            loss.backward()
            optimizer.step()
            if batch_idx % args.log_interval == 0:
                print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                    epoch, batch_idx *
                    len(data), len(train_loader.dataset),
                    100. * batch_idx / len(train_loader), loss.item()))

        model.eval()
        test_clnloss = 0
        clncorrect = 0

        if flag_advtrain:
            test_advloss = 0
            advcorrect = 0

        for clndata, target in test_loader:
            clndata, target = clndata.to(device), target.to(device)
            with torch.no_grad():
                output = model(clndata)
            test_clnloss += F.cross_entropy(
                output, target, reduction='sum').item()
            pred = output.max(1, keepdim=True)[1]
            clncorrect += pred.eq(target.view_as(pred)).sum().item()

            if flag_advtrain:
                advdata = adversary.perturb(clndata, target)
                with torch.no_grad():
                    output = model(advdata)
                test_advloss += F.cross_entropy(
                    output, target, reduction='sum').item()
                pred = output.max(1, keepdim=True)[1]
                advcorrect += pred.eq(target.view_as(pred)).sum().item()

        test_clnloss /= len(test_loader.dataset)
        print('\nTest set: avg cln loss: {:.4f},'
              ' cln acc: {}/{} ({:.0f}%)\n'.format(
                  test_clnloss, clncorrect, len(test_loader.dataset),
                  100. * clncorrect / len(test_loader.dataset)))
        if flag_advtrain:
            test_advloss /= len(test_loader.dataset)
            print('Test set: avg adv loss: {:.4f},'
                  ' adv acc: {}/{} ({:.0f}%)\n'.format(
                      test_advloss, advcorrect, len(test_loader.dataset),
                      100. * advcorrect / len(test_loader.dataset)))

    torch.save(
        model.state_dict(),
os.path.join(TRAINED_MODEL_PATH, model_filename))
14/1:
import matplotlib.pyplot as plt
%matplotlib inline

import os
import argparse
import torch
import torch.nn as nn

from advertorch.utils import predict_from_logits
from advertorch_examples.utils import get_mnist_test_loader
from advertorch_examples.utils import _imshow

torch.manual_seed(0)
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
14/2:
from advertorch.test_utils import LeNet5
from advertorch_examples.utils import TRAINED_MODEL_PATH

filename = "mnist_lenet5_clntrained.pt"
# filename = "mnist_lenet5_advtrained.pt"

model = LeNet5()
model.load_state_dict(
    torch.load(os.path.join(TRAINED_MODEL_PATH, filename)))
model.to(device)
model.eval()
14/3:
batch_size = 5
loader = get_mnist_test_loader(batch_size=batch_size)
for cln_data, true_label in loader:
    break
cln_data, true_label = cln_data.to(device), true_label.to(device)
14/4:
from advertorch.attacks import LinfPGDAttack

adversary = LinfPGDAttack(
    model, loss_fn=nn.CrossEntropyLoss(reduction="sum"), eps=0.15,
    nb_iter=40, eps_iter=0.01, rand_init=True, clip_min=0.0, clip_max=1.0,
    targeted=False)
14/5: adv_untargeted = adversary.perturb(cln_data, true_label)
14/6:
target = torch.ones_like(true_label) * 3
adversary.targeted = True
adv_targeted = adversary.perturb(cln_data, target)
14/7:
pred_cln = predict_from_logits(model(cln_data))
pred_untargeted_adv = predict_from_logits(model(adv_untargeted))
pred_targeted_adv = predict_from_logits(model(adv_targeted))

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 8))
for ii in range(batch_size):
    plt.subplot(3, batch_size, ii + 1)
    _imshow(cln_data[ii])
    plt.title("clean \n pred: {}".format(pred_cln[ii]))
    plt.subplot(3, batch_size, ii + 1 + batch_size)
    _imshow(adv_untargeted[ii])
    plt.title("untargeted \n adv \n pred: {}".format(
        pred_untargeted_adv[ii]))
    plt.subplot(3, batch_size, ii + 1 + batch_size * 2)
    _imshow(adv_targeted[ii])
    plt.title("targeted to 3 \n adv \n pred: {}".format(
        pred_targeted_adv[ii]))

plt.tight_layout()
plt.show()
14/8:
from advertorch.defenses import MedianSmoothing2D
from advertorch.defenses import BitSqueezing
from advertorch.defenses import JPEGFilter

bits_squeezing = BitSqueezing(bit_depth=5)
median_filter = MedianSmoothing2D(kernel_size=3)
jpeg_filter = JPEGFilter(10)

defense = nn.Sequential(
    jpeg_filter,
    bits_squeezing,
    median_filter,
)
14/9:
adv = adv_untargeted
adv_defended = defense(adv)
cln_defended = defense(cln_data)
14/10:
pred_cln = predict_from_logits(model(cln_data))
pred_cln_defended = predict_from_logits(model(cln_defended))
pred_adv = predict_from_logits(model(adv))
pred_adv_defended = predict_from_logits(model(adv_defended))


import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for ii in range(batch_size):
    plt.subplot(4, batch_size, ii + 1)
    _imshow(cln_data[ii])
    plt.title("clean \n pred: {}".format(pred_cln[ii]))
    plt.subplot(4, batch_size, ii + 1 + batch_size)
    _imshow(cln_data[ii])
    plt.title("defended clean \n pred: {}".format(pred_cln_defended[ii]))
    plt.subplot(4, batch_size, ii + 1 + batch_size * 2)
    _imshow(adv[ii])
    plt.title("adv \n pred: {}".format(
        pred_adv[ii]))
    plt.subplot(4, batch_size, ii + 1 + batch_size * 3)
    _imshow(adv_defended[ii])
    plt.title("defended adv \n pred: {}".format(
        pred_adv_defended[ii]))

plt.tight_layout()
plt.show()
14/11:
pred_cln = predict_from_logits(model(cln_data))
pred_cln_defended = predict_from_logits(model(cln_defended))
pred_adv = predict_from_logits(model(adv))
pred_adv_defended = predict_from_logits(model(adv_defended))


import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for ii in range(batch_size):
    plt.subplot(4, batch_size, ii + 1)
    _imshow(cln_data[ii])
    plt.title("clean \n pred: {}".format(pred_cln[ii]))
    plt.subplot(4, batch_size, ii + 1 + batch_size)
    _imshow(cln_data[ii])
    plt.title("defended clean \n pred: {}".format(pred_cln_defended[ii]))
    plt.subplot(4, batch_size, ii + 1 + batch_size * 2)
    _imshow(adv[ii])
    plt.title("adv \n pred: {}".format(
        pred_adv[ii]))
    plt.subplot(4, batch_size, ii + 1 + batch_size * 3)
    _imshow(adv_defended[ii])
    plt.title("defended adv \n pred: {}".format(
        pred_adv_defended[ii]))

plt.tight_layout()
plt.show()
14/12:
from advertorch.bpda import BPDAWrapper
defense_withbpda = BPDAWrapper(defense, forwardsub=lambda x: x)
defended_model = nn.Sequential(defense_withbpda, model)
bpda_adversary = LinfPGDAttack(
    defended_model, loss_fn=nn.CrossEntropyLoss(reduction="sum"), eps=0.15,
    nb_iter=1000, eps_iter=0.005, rand_init=True, clip_min=0.0, clip_max=1.0,
    targeted=False)


bpda_adv = bpda_adversary.perturb(cln_data, true_label)
bpda_adv_defended = defense(bpda_adv)
14/13:
pred_cln = predict_from_logits(model(cln_data))
pred_bpda_adv = predict_from_logits(model(bpda_adv))
pred_bpda_adv_defended = predict_from_logits(model(bpda_adv_defended))


import matplotlib.pyplot as plt
plt.figure(figsize=(10, 8))
for ii in range(batch_size):
    plt.subplot(3, batch_size, ii + 1)
    _imshow(cln_data[ii])
    plt.title("clean \n pred: {}".format(pred_cln[ii]))
    plt.subplot(3, batch_size, ii + 1 + batch_size)
    _imshow(bpda_adv[ii])
    plt.title("bpda adv \n pred: {}".format(
        pred_bpda_adv[ii]))
    plt.subplot(3, batch_size, ii + 1 + batch_size * 2)
    _imshow(bpda_adv_defended[ii])
    plt.title("defended \n bpda adv \n pred: {}".format(
        pred_bpda_adv_defended[ii]))

plt.tight_layout()
plt.show()
17/1: import pandas as pd
17/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
17/3: df = df.drop('use [kW]', axis = 1)
17/4: df = df.drop('gen [kW]', axis = 1)
17/5: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
17/6:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
17/7: df = df.drop('Date & Time', axis = 1)
17/8: df.head()
17/9: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
17/10: df.head()
17/11:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
17/12: df.head()
17/13: df.astype(bool).sum(axis = 0)
17/14: df.fillna(0).astype(bool).sum(axis=1)
17/15: df.astype(bool).sum(axis = 0)
17/16: df.count()
17/17: df.info()
17/18: df.describe()
17/19: df.describe()
17/20:
import matplotlib.pyplot as plt
%matplotlib inline
17/21: df.boxplot(column= 'Furnace', by='Month')
17/22: df.boxplot(column='Cellar Outlets', by='Month')
17/23: df.boxplot(column='Washing Machine', by='Month')
17/24: df.boxplot(column='Refrigerator', by='Month')
17/25: df.boxplot(column='Dishwasher', by='Month')
17/26: df.boxplot(column='Kitchen Lights', by='Month')
17/27: df.boxplot(column='Bedroom 1 Outlets', by='Month')
17/28: df.boxplot(column='Bedroom 1 Lights', by='Month')
17/29: df.boxplot(column='Master Bedroom Outlets', by='Month')
17/30: df.boxplot(column='Master Bedroom Lights', by='Month')
17/31: df.boxplot(column='Heating Duct', by='Month')
18/1:
import os
import numpy as np
import cv2

import torch
from torch import nn
from torch.autograd import Variable
# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None

from misc_functions import preprocess_image, recreate_image, get_params
19/1:
import os
import numpy as np
import cv2

import torch
from torch import nn
from torch.autograd import Variable
# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None

from misc_functions import preprocess_image, recreate_image, get_params
20/1:
import copy
import cv2
import numpy as np

import torch
from torch.autograd import Variable
from torchvision import models
20/2:
def preprocess_image(cv2im, resize_im=True):
    
    # mean and std list for channels (Imagenet)
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]
    
    # Resize image
    if resize_im:
        cv2im = cv2.resize(cv2im, (224, 224))
    im_as_arr = np.float32(cv2im)
    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])
    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H
    
    # Normalize the channels
    for channel, _ in enumerate(im_as_arr):
        im_as_arr[channel] /= 255
        im_as_arr[channel] -= mean[channel]
        im_as_arr[channel] /= std[channel]
    
    # Convert to float tensor
    im_as_ten = torch.from_numpy(im_as_arr).float()
    
    # Add one more channel to the beginning. Tensor shape = 1,3,224,224
    im_as_ten.unsqueeze_(0)
    
    # Convert to Pytorch variable
    im_as_var = Variable(im_as_ten, requires_grad=True)
    return im_as_var
20/3:
def recreate_image(im_as_var):
    
    reverse_mean = [-0.485, -0.456, -0.406]
    reverse_std = [1/0.229, 1/0.224, 1/0.225]
    
    recreated_im = copy.copy(im_as_var.data.numpy()[0])
    
    for c in range(3):
        recreated_im[c] /= reverse_std[c]
        recreated_im[c] -= reverse_mean[c]
    recreated_im[recreated_im > 1] = 1
    recreated_im[recreated_im < 0] = 0
    recreated_im = np.round(recreated_im * 255)

    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)
    
    # Convert RBG to GBR
    recreated_im = recreated_im[..., ::-1]
    return recreated_im
20/4:
def get_params(example_index):
    
    example_list = [['../input_images/apple.JPEG', 948],
                    ['../input_images/eel.JPEG', 390],
                    ['../input_images/bird.JPEG', 13]]
    selected_example = example_index
    img_path = example_list[selected_example][0]
    target_class = example_list[selected_example][1]
    file_name_to_export = img_path[img_path.rfind('/')+1:img_path.rfind('.')]
    
    # Read image
    original_image = cv2.imread(img_path, 1)
    
    # Process image
    prep_img = preprocess_image(original_image)
    
    # Define model
    pretrained_model = models.alexnet(pretrained=True)
    
    return (original_image, prep_img, target_class,
            file_name_to_export, pretrained_model)
19/2:
import os
import numpy as np
import cv2

import torch
from torch import nn
from torch.autograd import Variable
# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None

from misc_functions import preprocess_image, recreate_image, get_params
21/1:
import os
import numpy as np
import cv2

import torch
from torch import nn
from torch.autograd import Variable
# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None

from misc_functions import preprocess_image, recreate_image, get_params
22/1:
import os
import numpy as np
import cv2

import torch
from torch import nn
from torch.autograd import Variable
# from torch.autograd.gradcheck import zero_gradients  # See processed_image.grad = None

from misc_functions import preprocess_image, recreate_image, get_params
22/2:
class FastGradientSignTargeted():
    """
        Fast gradient sign untargeted adversarial attack, maximizes the target class activation
        with iterative grad sign updates
    """
    def __init__(self, model, alpha):
        self.model = model
        self.model.eval()
        # Movement multiplier per iteration
        self.alpha = alpha
        # Create the folder to export images if not exists
        if not os.path.exists('../generated'):
            os.makedirs('../generated')

    def generate(self, original_image, org_class, target_class):
        # I honestly dont know a better way to create a variable with specific value
        # Targeting the specific class
        im_label_as_var = Variable(torch.from_numpy(np.asarray([target_class])))
        # Define loss functions
        ce_loss = nn.CrossEntropyLoss()
        # Process image
        processed_image = preprocess_image(original_image)
        # Start iteration
        for i in range(10):
            print('Iteration:', str(i))
            # zero_gradients(x)
            # Zero out previous gradients
            # Can also use zero_gradients(x)
            processed_image.grad = None
            # Forward pass
            out = self.model(processed_image)
            # Calculate CE loss
            pred_loss = ce_loss(out, im_label_as_var)
            # Do backward pass
            pred_loss.backward()
            # Create Noise
            # Here, processed_image.grad.data is also the same thing is the backward gradient from
            # the first layer, can use that with hooks as well
            adv_noise = self.alpha * torch.sign(processed_image.grad.data)
            # Add noise to processed image
            processed_image.data = processed_image.data - adv_noise

            # Confirming if the image is indeed adversarial with added noise
            # This is necessary (for some cases) because when we recreate image
            # the values become integers between 1 and 255 and sometimes the adversariality
            # is lost in the recreation process

            # Generate confirmation image
            recreated_image = recreate_image(processed_image)
            # Process confirmation image
            prep_confirmation_image = preprocess_image(recreated_image)
            # Forward pass
            confirmation_out = self.model(prep_confirmation_image)
            # Get prediction
            _, confirmation_prediction = confirmation_out.data.max(1)
            # Get Probability
            confirmation_confidence = \
                nn.functional.softmax(confirmation_out)[0][confirmation_prediction].data.numpy()[0]
            # Convert tensor to int
            confirmation_prediction = confirmation_prediction.numpy()[0]
            # Check if the prediction is different than the original
            if confirmation_prediction == target_class:
                print('Original image was predicted as:', org_class,
                      'with adversarial noise converted to:', confirmation_prediction,
                      'and predicted with confidence of:', confirmation_confidence)
                # Create the image for noise as: Original image - generated image
                noise_image = original_image - recreated_image
                cv2.imwrite('../generated/targeted_adv_noise_from_' + str(org_class) + '_to_' +
                            str(confirmation_prediction) + '.jpg', noise_image)
                # Write image
                cv2.imwrite('../generated/targeted_adv_img_from_' + str(org_class) + '_to_' +
                            str(confirmation_prediction) + '.jpg', recreated_image)
                break

return 1
22/3:
class FastGradientSignTargeted():
    """
        Fast gradient sign untargeted adversarial attack, maximizes the target class activation
        with iterative grad sign updates
    """
    def __init__(self, model, alpha):
        self.model = model
        self.model.eval()
        # Movement multiplier per iteration
        self.alpha = alpha
        # Create the folder to export images if not exists
        if not os.path.exists('../generated'):
            os.makedirs('../generated')

    def generate(self, original_image, org_class, target_class):
        # I honestly dont know a better way to create a variable with specific value
        # Targeting the specific class
        im_label_as_var = Variable(torch.from_numpy(np.asarray([target_class])))
        # Define loss functions
        ce_loss = nn.CrossEntropyLoss()
        # Process image
        processed_image = preprocess_image(original_image)
        # Start iteration
        for i in range(10):
            print('Iteration:', str(i))
            # zero_gradients(x)
            # Zero out previous gradients
            # Can also use zero_gradients(x)
            processed_image.grad = None
            # Forward pass
            out = self.model(processed_image)
            # Calculate CE loss
            pred_loss = ce_loss(out, im_label_as_var)
            # Do backward pass
            pred_loss.backward()
            # Create Noise
            # Here, processed_image.grad.data is also the same thing is the backward gradient from
            # the first layer, can use that with hooks as well
            adv_noise = self.alpha * torch.sign(processed_image.grad.data)
            # Add noise to processed image
            processed_image.data = processed_image.data - adv_noise

            # Confirming if the image is indeed adversarial with added noise
            # This is necessary (for some cases) because when we recreate image
            # the values become integers between 1 and 255 and sometimes the adversariality
            # is lost in the recreation process

            # Generate confirmation image
            recreated_image = recreate_image(processed_image)
            # Process confirmation image
            prep_confirmation_image = preprocess_image(recreated_image)
            # Forward pass
            confirmation_out = self.model(prep_confirmation_image)
            # Get prediction
            _, confirmation_prediction = confirmation_out.data.max(1)
            # Get Probability
            confirmation_confidence = \
                nn.functional.softmax(confirmation_out)[0][confirmation_prediction].data.numpy()[0]
            # Convert tensor to int
            confirmation_prediction = confirmation_prediction.numpy()[0]
            # Check if the prediction is different than the original
            if confirmation_prediction == target_class:
                print('Original image was predicted as:', org_class,
                      'with adversarial noise converted to:', confirmation_prediction,
                      'and predicted with confidence of:', confirmation_confidence)
                # Create the image for noise as: Original image - generated image
                noise_image = original_image - recreated_image
                cv2.imwrite('../generated/targeted_adv_noise_from_' + str(org_class) + '_to_' +
                            str(confirmation_prediction) + '.jpg', noise_image)
                # Write image
                cv2.imwrite('../generated/targeted_adv_img_from_' + str(org_class) + '_to_' +
                            str(confirmation_prediction) + '.jpg', recreated_image)
                break

    return 1
22/4:
class FastGradientSignTargeted():
    """
        Fast gradient sign untargeted adversarial attack, maximizes the target class activation
        with iterative grad sign updates
    """
    def __init__(self, model, alpha):
        self.model = model
        self.model.eval()
        # Movement multiplier per iteration
        self.alpha = alpha
        # Create the folder to export images if not exists
        if not os.path.exists('../generated'):
            os.makedirs('../generated')

    def generate(self, original_image, org_class, target_class):
        # I honestly dont know a better way to create a variable with specific value
        # Targeting the specific class
        im_label_as_var = Variable(torch.from_numpy(np.asarray([target_class])))
        # Define loss functions
        ce_loss = nn.CrossEntropyLoss()
        # Process image
        processed_image = preprocess_image(original_image)
        # Start iteration
        for i in range(10):
            print('Iteration:', str(i))
            # zero_gradients(x)
            # Zero out previous gradients
            # Can also use zero_gradients(x)
            processed_image.grad = None
            # Forward pass
            out = self.model(processed_image)
            # Calculate CE loss
            pred_loss = ce_loss(out, im_label_as_var)
            # Do backward pass
            pred_loss.backward()
            # Create Noise
            # Here, processed_image.grad.data is also the same thing is the backward gradient from
            # the first layer, can use that with hooks as well
            adv_noise = self.alpha * torch.sign(processed_image.grad.data)
            # Add noise to processed image
            processed_image.data = processed_image.data - adv_noise

            # Confirming if the image is indeed adversarial with added noise
            # This is necessary (for some cases) because when we recreate image
            # the values become integers between 1 and 255 and sometimes the adversariality
            # is lost in the recreation process

            # Generate confirmation image
            recreated_image = recreate_image(processed_image)
            # Process confirmation image
            prep_confirmation_image = preprocess_image(recreated_image)
            # Forward pass
            confirmation_out = self.model(prep_confirmation_image)
            # Get prediction
            _, confirmation_prediction = confirmation_out.data.max(1)
            # Get Probability
            confirmation_confidence = \
                nn.functional.softmax(confirmation_out)[0][confirmation_prediction].data.numpy()[0]
            # Convert tensor to int
            confirmation_prediction = confirmation_prediction.numpy()[0]
            # Check if the prediction is different than the original
            if confirmation_prediction == target_class:
                print('Original image was predicted as:', org_class,
                      'with adversarial noise converted to:', confirmation_prediction,
                      'and predicted with confidence of:', confirmation_confidence)
                # Create the image for noise as: Original image - generated image
                noise_image = original_image - recreated_image
                cv2.imwrite('../generated/targeted_adv_noise_from_' + str(org_class) + '_to_' +
                            str(confirmation_prediction) + '.jpg', noise_image)
                # Write image
                cv2.imwrite('../generated/targeted_adv_img_from_' + str(org_class) + '_to_' +
                            str(confirmation_prediction) + '.jpg', recreated_image)
                break

        return 1
22/5:
    target_example = 0  # Apple
    (original_image, prep_img, org_class, _, pretrained_model) =\
        get_params(target_example)
    target_class = 62  # Mud turtle

    FGS_untargeted = FastGradientSignTargeted(pretrained_model, 0.01)
    FGS_untargeted.generate(original_image, org_class, target_class)
23/1: import pandas as pd
23/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
23/3: df = df.drop('use [kW]', axis = 1)
23/4: df = df.drop('gen [kW]', axis = 1)
23/5: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
23/6:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
23/7: df = df.drop('Date & Time', axis = 1)
23/8: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
23/9:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
23/10: df.fillna(0).astype(bool).sum(axis=1)
23/11: df.astype(bool).sum(axis = 0)
23/12: df.describe()
23/13: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
23/14: new_df.head()
23/15: (new_df == 0).astype(int).sum(axis=0)
23/16: (new_df.Furnace <= 10).astype(int).sum(axis = 0)
23/17: (new_df['Cellar Outlets'] <= 10).astype(int).sum(axis = 0)
23/18: (new_df['Washing Machineq'] <= 10).astype(int).sum(axis = 0)
23/19: (new_df['Washing Machine'] <= 10).astype(int).sum(axis = 0)
23/20: (new_df['Washing Machine'] <= 5).astype(int).sum(axis = 0)
23/21: (new_df['Washing Machine'] <= 1).astype(int).sum(axis = 0)
23/22: (new_df['Washing Machine'] <= 0.5).astype(int).sum(axis = 0)
23/23: (new_df['Washing Machine'] <= 0.3).astype(int).sum(axis = 0)
23/24: (new_df['Washing Machine'] <= 0.2).astype(int).sum(axis = 0)
23/25:
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
25/1: import pandas as pd
25/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
25/3: df = df.drop('use [kW]', axis = 1)
25/4: df = df.drop('gen [kW]', axis = 1)
25/5: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
25/6:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
25/7: df = df.drop('Date & Time', axis = 1)
25/8: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
25/9:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
25/10: df.fillna(0).astype(bool).sum(axis=1)
25/11: df.astype(bool).sum(axis = 0)
25/12: df.describe()
25/13: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
25/14: new_df.head()
25/15: (new_df == 0).astype(int).sum(axis=0)
25/16: (new_df.Furnace <= 10).astype(int).sum(axis = 0)
25/17: (new_df['Cellar Outlets'] <= 10).astype(int).sum(axis = 0)
25/18: (new_df['Washing Machine'] <= 0.2).astype(int).sum(axis = 0)
25/19:
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
25/20:
mms = MinMaxScaler()
mms.fit(new_df)
data_transformed = mms.transform(new_df)
25/21:
Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_transformed)
    Sum_of_squared_distances.append(km.inertia_)
25/22:
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/23: data_furnace = mms.transform(new_df['Furnace'])
25/24:
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
25/25: furnace_df = new_df['Furnace']
25/26:

import numpy as np
25/27: furnace_df = np.reshape(furnace_df, (furnace_df.shape[0], 1))
25/28: furnace_df.shape()
25/29: furnace_df.shape
25/30: furnace_df = np.reshape(furnace_df, (furnace_df.shape, 1))
25/31: furnace_df = (int)new_df['Furnace']
25/32: furnace_df = new_df['Furnace']
25/33: furnace_df.shape
25/34: furnace_df = (int)furnace_df
25/35: furnace_df = (int)furnace_df[0]
25/36: furnace_df = new_df['Furnace']
25/37: furnace_df = np.asarray(furnace_df, dtype=int)
25/38: furnace_df = np.reshape(furnace_df, (furnace_df.shape, 1))
25/39: np.asarray(furnace_df, dtype=int)
25/40: np.reshape(furnace_df, (furnace_df.shape, 1))
25/41: type(furnace_df)
25/42:
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
25/43:
mms = MinMaxScaler()
mms.fit(new_df)
25/44: data_furnace = mms.transform(furnace_df.reshape(-1, 1))
25/45:
mms = MinMaxScaler()
mms.fit(furnace_df)
25/46:
mms = MinMaxScaler()
mms.fit(furnace_df.reshape(-1,1))
25/47: data_furnace = mms.transform(furnace_df.reshape(-1, 1))
25/48:
Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
25/49:
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/50:
furnace_df = new_df['Furnace']
np.asarray(furnace_df, dtype=int)
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/51:
furnace_df = new_df['Furnace']
np.asarray(furnace_df, dtype=int)
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/52:
furnace_df = new_df['Furnace']
np.asarray(furnace_df, dtype=int)
25/53:
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))
25/54: type(furnace_df)
25/55:
furnace_df = new_df['Furnace']
furnace_df = np.asarray(furnace_df, dtype=int)
25/56: type(furnace_df)
25/57:
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))
25/58:
Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/59:
cellar_df = new_df['Cellar Outlets']
cellar_df = np.asarray(cellar_df, dtype=int)
mms.fit(cellar_df.reshape(-1,1))
data = mms.transform(cellar_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/60:
wash_df = new_df['Washing Machine']
np.asarray(wash_df, dtype=int)
mms.fit(wash_df.reshape(-1,1))
data = mms.transform(wash_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/61:
wash_df = new_df['Washing Machine']
wash_df = np.asarray(wash_df, dtype=int)
mms.fit(wash_df.reshape(-1,1))
data = mms.transform(wash_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/62:
refri_df = new_df['Refrigerator']
refri_df = np.asarray(refri_df, dtype=int)
mms.fit(refri_df.reshape(-1,1))
data = mms.transform(refri_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/63:
dish_df = new_df['Dishwasher']
dish_df = np.asarray(dish_df, dtype=int)
mms.fit(dish_df.reshape(-1,1))
data = mms.transform(dish_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/64:
kitchen_df = new_df['Kitchen Lights']
kitchen_df = np.asarray(kitchen_df, dtype=int)
mms.fit(kitchen_df.reshape(-1,1))
data = mms.transform(kitchen_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/65:
bedl_df = new_df['Bedroom 1 Lights']
bedl_df = np.asarray(bedl_df, dtype=int)
mms.fit(bedl_df.reshape(-1,1))
data = mms.transform(bedl_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/66:
bedo_df = new_df['Bedroom 1 Outlets']
bedo_df = np.asarray(bedo_df, dtype=int)
mms.fit(bedo_df.reshape(-1,1))
data = mms.transform(bedo_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/67:
duct_df = new_df['Heating Duct']
duct_df = np.asarray(duct_df, dtype=int)
mms.fit(duct_df.reshape(-1,1))
data = mms.transform(duct_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/68:
mbedl_df = new_df['Master Bedroom Lights']
mbedl_df = np.asarray(mbedl_df, dtype=int)
mms.fit(mbedl_df.reshape(-1,1))
data = mms.transform(mbedl_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/69:
mbedo_df = new_df['Master Bedroom Outlets']
mbedo_df = np.asarray(mbedo_df, dtype=int)
mms.fit(mbedo_df.reshape(-1,1))
data = mms.transform(mbedo_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/70:
duct_df = new_df['Heating Duct']
duct_df = np.asarray(duct_df, dtype=int)
mms.fit(duct_df.reshape(-1,1))
data = mms.transform(duct_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
25/71:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df)

#2
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df)

#3
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df)

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df)

#5
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df)

#6
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df)

#7
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df)

#8
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df)

#9
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df)

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df)
25/72:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
25/73: furnace_df_km
25/74: furnace_df_km.length()
25/75: furnace_df_km.length
25/76: furnace_df_km.shape()
25/77: furnace_df_km.shape
25/78: cluster_df = pd.DataFrame()
25/79: columns = 'Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Outlets', 'Bedroom 1 Lights', 'Bedroom 1 Outlets', 'Master Bedroom Lights', 'Master Bedroom Outlets'
25/80: cluster_df = pd.DataFrame(columns=columns)
25/81:
cluster_df['Furnace'] = furnace_df_km
cluster_df['Cellar Outlets'] = cellar_df_km
cluster_df['Washing Machine'] = wash_df_km
cluster_df['Refrigerator'] = refri_df_km
cluster_df['Dishwasher'] = dish_df_km
cluster_df['Kitchen Outlets'] = kitchen_df_km
cluster_df['Bedroom 1 Lights'] = bedl_df_km
cluster_df['Bedroom 1 Outlets'] = bedo_df_km
cluster_df['Master Bedroom Lights'] = mbedl_df_km
cluster_df['Master Bedroom Outlets'] = mbedo_df_km
25/82: cluster_df.head()
25/83: cluster_df.shape
25/84: cluster_df['State'] = np.zeros(246639)
25/85: cluster_df['State'] = cluster_df['Furnace'].map(str) + cluster_df['Cellar Outlets'].map(str) + cluster_df['Washing Machine'].map(str) + cluster_df['Refrigerator'].map(str) + cluster_df['Dishwasher'].map(str) + cluster_df['Kitchen Outlets'].map(str) + cluster_df['Bedroom 1 Lights'].map(str) + cluster_df['Bedroom 1 Outlets'].map(str) + cluster_df['Master Bedroom Lights'].map(str) + cluster_df['Master Bedroom Outlets']
25/86: cluster_df['State'] = cluster_df['Furnace'].map(str) + cluster_df['Cellar Outlets'].map(str) + cluster_df['Washing Machine'].map(str) + cluster_df['Refrigerator'].map(str) + cluster_df['Dishwasher'].map(str) + cluster_df['Kitchen Outlets'].map(str) + cluster_df['Bedroom 1 Lights'].map(str) + cluster_df['Bedroom 1 Outlets'].map(str) + cluster_df['Master Bedroom Lights'].map(str) + cluster_df['Master Bedroom Outlets'].map(str)
25/87: cluster_df.head()
25/88: cluster_df['State'].unique
25/89: cluster_df['State'].unique()
25/90: cluster_df['State'].unique().sum()
25/91: cluster_df['State'].unique().count()
25/92: cluster_df['State']
25/93: cluster_df['State']
25/94: state_list = list(cluster_df['State'])
25/95: state_list
25/96: state_list.dtype
25/97: state_list.dtype()
25/98: dtype(state_list)
25/99: type(state_list)
25/100: type(state_list[0])
26/1: import pandas as pd
26/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
26/3: df = df.drop('use [kW]', axis = 1)
26/4: df = df.drop('gen [kW]', axis = 1)
26/5: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
26/6:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
26/7: df = df.drop('Date & Time', axis = 1)
26/8: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
26/9:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
26/10: df.fillna(0).astype(bool).sum(axis=1)
26/11: df.astype(bool).sum(axis = 0)
26/12: df.describe()
26/13: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
26/14: new_df.head()
26/15: (new_df == 0).astype(int).sum(axis=0)
26/16:
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
26/17:
furnace_df = new_df['Furnace']
furnace_df = np.asarray(furnace_df, dtype=int)
26/18:
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))
26/19:
Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/20:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
26/21:
Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/22:
cellar_df = new_df['Cellar Outlets']
cellar_df = np.asarray(cellar_df, dtype=int)
mms.fit(cellar_df.reshape(-1,1))
data = mms.transform(cellar_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/23:
wash_df = new_df['Washing Machine']
wash_df = np.asarray(wash_df, dtype=int)
mms.fit(wash_df.reshape(-1,1))
data = mms.transform(wash_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/24:
refri_df = new_df['Refrigerator']
refri_df = np.asarray(refri_df, dtype=int)
mms.fit(refri_df.reshape(-1,1))
data = mms.transform(refri_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/25:
dish_df = new_df['Dishwasher']
dish_df = np.asarray(dish_df, dtype=int)
mms.fit(dish_df.reshape(-1,1))
data = mms.transform(dish_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/26:
kitchen_df = new_df['Kitchen Lights']
kitchen_df = np.asarray(kitchen_df, dtype=int)
mms.fit(kitchen_df.reshape(-1,1))
data = mms.transform(kitchen_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/27:
bedl_df = new_df['Bedroom 1 Lights']
bedl_df = np.asarray(bedl_df, dtype=int)
mms.fit(bedl_df.reshape(-1,1))
data = mms.transform(bedl_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/28:
bedo_df = new_df['Bedroom 1 Outlets']
bedo_df = np.asarray(bedo_df, dtype=int)
mms.fit(bedo_df.reshape(-1,1))
data = mms.transform(bedo_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/29:
mbedl_df = new_df['Master Bedroom Lights']
mbedl_df = np.asarray(mbedl_df, dtype=int)
mms.fit(mbedl_df.reshape(-1,1))
data = mms.transform(mbedl_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/30:
mbedo_df = new_df['Master Bedroom Outlets']
mbedo_df = np.asarray(mbedo_df, dtype=int)
mms.fit(mbedo_df.reshape(-1,1))
data = mms.transform(mbedo_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
26/31:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
26/32: columns = 'Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Outlets', 'Bedroom 1 Lights', 'Bedroom 1 Outlets', 'Master Bedroom Lights', 'Master Bedroom Outlets'
26/33: cluster_df = pd.DataFrame(columns=columns)
26/34:
cluster_df['Furnace'] = furnace_df_km
cluster_df['Cellar Outlets'] = cellar_df_km
cluster_df['Washing Machine'] = wash_df_km
cluster_df['Refrigerator'] = refri_df_km
cluster_df['Dishwasher'] = dish_df_km
cluster_df['Kitchen Outlets'] = kitchen_df_km
cluster_df['Bedroom 1 Lights'] = bedl_df_km
cluster_df['Bedroom 1 Outlets'] = bedo_df_km
cluster_df['Master Bedroom Lights'] = mbedl_df_km
cluster_df['Master Bedroom Outlets'] = mbedo_df_km
26/35: cluster_df.head()
26/36: cluster_df.shape
26/37: cluster_df['State'] = np.zeros(246639)
26/38: cluster_df['State'] = cluster_df['Furnace'].map(str) + cluster_df['Cellar Outlets'].map(str) + cluster_df['Washing Machine'].map(str) + cluster_df['Refrigerator'].map(str) + cluster_df['Dishwasher'].map(str) + cluster_df['Kitchen Outlets'].map(str) + cluster_df['Bedroom 1 Lights'].map(str) + cluster_df['Bedroom 1 Outlets'].map(str) + cluster_df['Master Bedroom Lights'].map(str) + cluster_df['Master Bedroom Outlets'].map(str)
26/39: cluster_df.head()
26/40: state = cluster_df['State']
26/41: state.shape()
26/42: state.shape
26/43: index = np.arange(246639)
26/44: index.shape
26/45: columns = ['index', 'state']
26/46: lstm_data = pd.DataFrame(columns= columns)
26/47: lstm_data.head()
26/48:
lstm_data.index = index
lstm_data.state = state
26/49:
lstm_data['index'] = index
lstm_data['state'] = state
26/50: lstm_data.head()
26/51:
# split a univariate sequence into samples
def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps
        # check if we are beyond the sequence
        if end_ix > len(sequence)-1:
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return array(X), array(y)
26/52:
raw_seq = lstm_data['state']
# choose a number of time steps
n_steps = 10
# split into samples
X, y = split_sequence(raw_seq, n_steps)
# summarize the data
for i in range(len(X)):
    print(X[i], y[i])
26/53:
# split a univariate sequence into samples
def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps
        # check if we are beyond the sequence
        if end_ix > len(sequence)-1:
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)
26/54:
raw_seq = lstm_data['state']
# choose a number of time steps
n_steps = 10
# split into samples
X, y = split_sequence(raw_seq, n_steps)
# summarize the data
for i in range(len(X)):
    print(X[i], y[i])
26/55:
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
27/1:
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
29/1: import pandas as pd
29/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
29/3: df = df.drop('use [kW]', axis = 1)
29/4: df = df.drop('gen [kW]', axis = 1)
29/5: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
29/6:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
29/7: df = df.drop('Date & Time', axis = 1)
29/8: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
29/9:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
29/10: df.fillna(0).astype(bool).sum(axis=1)
29/11: df.astype(bool).sum(axis = 0)
29/12: df.describe()
29/13: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
29/14: new_df.head()
29/15: (new_df == 0).astype(int).sum(axis=0)
29/16:
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
29/17:
furnace_df = new_df['Furnace']
furnace_df = np.asarray(furnace_df, dtype=int)
29/18:
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))
29/19:
Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data_furnace)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/20:
cellar_df = new_df['Cellar Outlets']
cellar_df = np.asarray(cellar_df, dtype=int)
mms.fit(cellar_df.reshape(-1,1))
data = mms.transform(cellar_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/21:
wash_df = new_df['Washing Machine']
wash_df = np.asarray(wash_df, dtype=int)
mms.fit(wash_df.reshape(-1,1))
data = mms.transform(wash_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/22:
refri_df = new_df['Refrigerator']
refri_df = np.asarray(refri_df, dtype=int)
mms.fit(refri_df.reshape(-1,1))
data = mms.transform(refri_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/23:
dish_df = new_df['Dishwasher']
dish_df = np.asarray(dish_df, dtype=int)
mms.fit(dish_df.reshape(-1,1))
data = mms.transform(dish_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/24:
kitchen_df = new_df['Kitchen Lights']
kitchen_df = np.asarray(kitchen_df, dtype=int)
mms.fit(kitchen_df.reshape(-1,1))
data = mms.transform(kitchen_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/25:
bedl_df = new_df['Bedroom 1 Lights']
bedl_df = np.asarray(bedl_df, dtype=int)
mms.fit(bedl_df.reshape(-1,1))
data = mms.transform(bedl_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/26:
bedo_df = new_df['Bedroom 1 Outlets']
bedo_df = np.asarray(bedo_df, dtype=int)
mms.fit(bedo_df.reshape(-1,1))
data = mms.transform(bedo_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/27:
mbedl_df = new_df['Master Bedroom Lights']
mbedl_df = np.asarray(mbedl_df, dtype=int)
mms.fit(mbedl_df.reshape(-1,1))
data = mms.transform(mbedl_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/28:
mbedo_df = new_df['Master Bedroom Outlets']
mbedo_df = np.asarray(mbedo_df, dtype=int)
mms.fit(mbedo_df.reshape(-1,1))
data = mms.transform(mbedo_df.reshape(-1, 1))

Sum_of_squared_distances = []
K = range(1,15)
for k in K:
    km = KMeans(n_clusters=k)
    km = km.fit(data)
    Sum_of_squared_distances.append(km.inertia_)
    
plt.plot(K, Sum_of_squared_distances, 'bx-')
plt.xlabel('k')
plt.ylabel('Sum_of_squared_distances')
plt.title('Elbow Method For Optimal k')
plt.show()
29/29:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
29/30: columns = 'Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Outlets', 'Bedroom 1 Lights', 'Bedroom 1 Outlets', 'Master Bedroom Lights', 'Master Bedroom Outlets'
29/31: cluster_df = pd.DataFrame(columns=columns)
29/32:
cluster_df['Furnace'] = furnace_df_km
cluster_df['Cellar Outlets'] = cellar_df_km
cluster_df['Washing Machine'] = wash_df_km
cluster_df['Refrigerator'] = refri_df_km
cluster_df['Dishwasher'] = dish_df_km
cluster_df['Kitchen Outlets'] = kitchen_df_km
cluster_df['Bedroom 1 Lights'] = bedl_df_km
cluster_df['Bedroom 1 Outlets'] = bedo_df_km
cluster_df['Master Bedroom Lights'] = mbedl_df_km
cluster_df['Master Bedroom Outlets'] = mbedo_df_km
29/33: cluster_df.head()
29/34: cluster_df.shape
29/35: cluster_df['State'] = np.zeros(246639)
29/36: cluster_df['State'] = cluster_df['Furnace'].map(str) + cluster_df['Cellar Outlets'].map(str) + cluster_df['Washing Machine'].map(str) + cluster_df['Refrigerator'].map(str) + cluster_df['Dishwasher'].map(str) + cluster_df['Kitchen Outlets'].map(str) + cluster_df['Bedroom 1 Lights'].map(str) + cluster_df['Bedroom 1 Outlets'].map(str) + cluster_df['Master Bedroom Lights'].map(str) + cluster_df['Master Bedroom Outlets'].map(str)
29/37: cluster_df.head()
29/38: cluster_df['State']
29/39: state_list = list(cluster_df['State'])
29/40: type(state_list[0])
29/41: df.head()
29/42: state = cluster_df['State']
29/43: state.shape
29/44: index = np.arange(246639)
29/45: index.shape
29/46: columns = ['index', 'state']
29/47: lstm_data = pd.DataFrame(columns= columns)
29/48: lstm_data.head()
29/49:
lstm_data['index'] = index
lstm_data['state'] = state
29/50:
# split a univariate sequence into samples
def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps
        # check if we are beyond the sequence
        if end_ix > len(sequence)-1:
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)
29/51:
raw_seq = lstm_data['state']
# choose a number of time steps
n_steps = 10
# split into samples
X, y = split_sequence(raw_seq, n_steps)
29/52:
from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
29/53: lstm_data.to_csv()
29/54:
n_features = 1
X = X.reshape((X.shape[0], X.shape[1], n_features))
29/55: lstm_data.to_csv('lstm_data.csv')
29/56:
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
# fit model
model.fit(X, y, epochs=200, verbose=0)
# demonstrate prediction
x_input = array([70, 80, 90])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/57: lstm_data.head()
29/58:
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
# fit model
model.fit(X, y, epochs=200, verbose=0)
# demonstrate prediction
# x_input = array(['1020000201', '1120000201', ''])
# x_input = x_input.reshape((1, n_steps, n_features))
# yhat = model.predict(x_input, verbose=0)
# print(yhat)
29/59:
import math 
import numpy 
import matplotlib.pyplot as plt 
from pandas import read_csv 
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
29/60:
create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
        for i in range(len(_data_set) - _look_back - 1): 
            a = _data_set[i:(i + _look_back), 0] data_x.append(a)
            data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
29/61:
create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
29/62:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
        for i in range(len(_data_set) - _look_back - 1): 
            a = _data_set[i:(i + _look_back), 0] data_x.append(a)
            data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
29/63:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
29/64:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
29/65:
data_frame = read_csv('lstm_data.csv') 
data_set = data_frame.values data_set = data_set.astype('float32')
29/66:
data_frame = read_csv('lstm_data.csv') 
data_set = data_frame.values 
data_set = data_set.astype('float32')
29/67:
train_size = int(len(data_set) * 0.67) 
test_size = len(data_set) - train_size 
train, test = data_set[0:train_size,:],
              data_set[train_size:len(data_set), :]
29/68:
train_size = int(len(data_set) * 0.67) 
test_size = len(data_set) - train_size 
train, test = data_set[0:train_size,:],
data_set[train_size:len(data_set), :]
29/69: data_set.head()
29/70: data_set
29/71:
data_frame = read_csv('lstm_data.csv') 
data_set = data_frame.values 
data_set = data_set.astype('str')
29/72: data_set
29/73:
train_size = int(len(data_set) * 0.67) 
test_size = len(data_set) - train_size 
train, test = data_set[0:train_size,:],
data_set[train_size:len(data_set), :]
29/74:
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
# fit model
model.fit(X, y, epochs=200, verbose=0)
# demonstrate prediction
# x_input = array(['1020000201', '1120000201', ''])
# x_input = x_input.reshape((1, n_steps, n_features))
# yhat = model.predict(x_input, verbose=0)
# print(yhat)
29/75: lstm_data.to_csv('lstm_data.csv')
29/76:
n_features = 1
X = X.reshape((X.shape[0], X.shape[1], n_features))
29/77:
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
# fit model
model.fit(X, y, epochs=200, verbose=0)
# demonstrate prediction
# x_input = array(['1020000201', '1120000201', ''])
# x_input = x_input.reshape((1, n_steps, n_features))
# yhat = model.predict(x_input, verbose=0)
# print(yhat)
29/78: lstm_data['state'].head(10)
29/79:
x_input = array(['1020000201', '1120000201', '1020000201', '1120000201', '1020000201'])
x_input = x_input.reshape((1, 5, n_features))y
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/80:
x_input = array(['1020000201', '1120000201', '1020000201', '1120000201', '1020000201'])
x_input = x_input.reshape((1, 5, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/81: lstm_data['state'].head(11)
29/82:
x_input = array(['1020000201', '1120000201', '1020000201', '1120000201', '1020000201', '1020000201', '1120000201', '1020000201', '1120000201', '0000000201'])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/83:
x_input = array([1020000201, 1120000201, 1020000201, 1120000201, 1020000201, 1020000201, 1120000201, 1020000201, 1120000201, 0000000201])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/84:
x_input = array([1020000201, 1120000201, 1020000201, 1120000201, 1020000201, 1020000201, 1120000201, 1020000201, 1120000201, 1120000201])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/85:
x_input = array([1020000201, 1120000201, 1020000201, 1120000201, 1020000201, 1020000201, 1120000201, 1020000201, 1120000201, 1120000201])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/86:
x_input = array([1020000201, 1120000201, 1020000201, 1120000201, 1020000201, 1020000201, 1120000201, 1020000201, 1120000201, 1120000201])
x_input = x_input.reshape((1, n_steps, n_features))
yhat = model.predict(x_input, verbose=0)
print(yhat)
29/87:
train_size = int(len(data_set) * 0.67) 
test_size = len(data_set) - train_size 
train, test = data_set[0:train_size,:],
data_set[train_size:len(data_set), :]
30/1:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
30/2:
data_frame = pd.read_csv('lstm_data.csv')
data_set = data_frame.values
30/3: data_set
30/4: ds = data_set.astype('float32')
30/5: ds
30/6:
train_size = int(len(data_set) * 0.67) 
test_size = len(data_set) - train_size 
train, test = data_set[0:train_size,:],
              data_set[train_size:len(data_set), :]
30/7:
train_size = int(len(data_set) * 0.67) 
test_size = len(data_set) - train_size 
train, test = data_set[0:train_size,:], data_set[train_size:len(data_set), :]
30/8:
train_size = int(len(ds) * 0.67) 
test_size = len(ds) - train_size 
train, test = ds[0:train_size,:], ds[train_size:len(ds), :]
30/9:
train_size1 = int(len(data_set) * 0.67) 
test_size1 = len(data_set) - train_size 
train1, test1 = data_set[0:train_size1,:], data_set[train_size1:len(data_set), :]
30/10:
train_size2 = int(len(ds) * 0.67) 
test_size2 = len(ds) - train_size 
train2, test2 = ds[0:train_size2,:], ds[train_size2:len(ds), :]
30/11:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
30/12:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return numpy.array(data_x), numpy.array(data_y)
30/13:
look_back = 1 
train_x1, train_y1 = create_data_set(train1, look_back) 
test_x1, test_y1 = create_data_set(test1, look_back) 
train_x1 = numpy.reshape(train_x1,
                        (train_x1.shape[0], 1, train_x1.shape[1])) 
test_x1 = numpy.reshape(test_x1, 
                       (test_x1.shape[0], 1, test_x1.shape[1]))
30/14:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return np.array(data_x), np.array(data_y)
30/15:
look_back = 1 
train_x1, train_y1 = create_data_set(train1, look_back) 
test_x1, test_y1 = create_data_set(test1, look_back) 
train_x1 = np.reshape(train_x1,
                        (train_x1.shape[0], 1, train_x1.shape[1])) 
test_x1 = np.reshape(test_x1, 
                       (test_x1.shape[0], 1, test_x1.shape[1]))
30/16:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
30/17:
train_x2, train_y2 = create_data_set(train2, look_back) 
test_x2, test_y2 = create_data_set(test2, look_back) 
train_x2 = np.reshape(train_x2,
                        (train_x2.shape[0], 1, train_x2.shape[1])) 
test_x2 = np.reshape(test_x2, 
                       (test_x2.shape[0], 1, test_x2.shape[1]))
30/18:
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_error', optimizer='adam') model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
30/19:
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
30/20:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
31/1: import pandas as pd
31/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
31/3: df = df.drop('use [kW]', axis = 1)
31/4: df = df.drop('gen [kW]', axis = 1)
31/5: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
31/6:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
31/7: df = df.drop('Date & Time', axis = 1)
31/8: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
31/9:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
31/10: df.fillna(0).astype(bool).sum(axis=1)
31/11: df.astype(bool).sum(axis = 0)
31/12: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
31/13:
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
31/14:
furnace_df = new_df['Furnace']
furnace_df = np.asarray(furnace_df, dtype=int)
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))

cellar_df = new_df['Cellar Outlets']
cellar_df = np.asarray(cellar_df, dtype=int)
mms.fit(cellar_df.reshape(-1,1))
data2 = mms.transform(cellar_df.reshape(-1, 1))

wash_df = new_df['Washing Machine']
wash_df = np.asarray(wash_df, dtype=int)
mms.fit(wash_df.reshape(-1,1))
data3 = mms.transform(wash_df.reshape(-1, 1))

refri_df = new_df['Refrigerator']
refri_df = np.asarray(refri_df, dtype=int)
mms.fit(refri_df.reshape(-1,1))
data4 = mms.transform(refri_df.reshape(-1, 1))

dish_df = new_df['Dishwasher']
dish_df = np.asarray(dish_df, dtype=int)
mms.fit(dish_df.reshape(-1,1))
data5 = mms.transform(dish_df.reshape(-1, 1))

kitchen_df = new_df['Kitchen Lights']
kitchen_df = np.asarray(kitchen_df, dtype=int)
mms.fit(kitchen_df.reshape(-1,1))
data6 = mms.transform(kitchen_df.reshape(-1, 1))

bedl_df = new_df['Bedroom 1 Lights']
bedl_df = np.asarray(bedl_df, dtype=int)
mms.fit(bedl_df.reshape(-1,1))
data7 = mms.transform(bedl_df.reshape(-1, 1))

bedo_df = new_df['Bedroom 1 Outlets']
bedo_df = np.asarray(bedo_df, dtype=int)
mms.fit(bedo_df.reshape(-1,1))
data8 = mms.transform(bedo_df.reshape(-1, 1))

mbedl_df = new_df['Master Bedroom Lights']
mbedl_df = np.asarray(mbedl_df, dtype=int)
mms.fit(mbedl_df.reshape(-1,1))
data9 = mms.transform(mbedl_df.reshape(-1, 1))

mbedo_df = new_df['Master Bedroom Outlets']
mbedo_df = np.asarray(mbedo_df, dtype=int)
mms.fit(mbedo_df.reshape(-1,1))
data10 = mms.transform(mbedo_df.reshape(-1, 1))
31/15:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=4, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=3, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
31/16:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
31/17:
#1
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
furnace_df_km = km.fit_predict(furnace_df.reshape(-1, 1))

#2
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
cellar_df_km = km.fit_predict(cellar_df.reshape(-1, 1))

#3
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
wash_df_km = km.fit_predict(wash_df.reshape(-1, 1))

#4
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
refri_df_km = km.fit_predict(refri_df.reshape(-1, 1))

#5
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
dish_df_km = km.fit_predict(dish_df.reshape(-1, 1))

#6
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
kitchen_df_km = km.fit_predict(kitchen_df.reshape(-1, 1))

#7
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedl_df_km = km.fit_predict(bedl_df.reshape(-1, 1))

#8
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
bedo_df_km = km.fit_predict(bedo_df.reshape(-1, 1))

#9
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedl_df_km = km.fit_predict(mbedl_df.reshape(-1, 1))

#10
km = KMeans(
    n_clusters=2, init='random',
    n_init=10, max_iter=300, 
    tol=1e-04, random_state=0
)
mbedo_df_km = km.fit_predict(mbedo_df.reshape(-1, 1))
31/18: columns = 'Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Outlets', 'Bedroom 1 Lights', 'Bedroom 1 Outlets', 'Master Bedroom Lights', 'Master Bedroom Outlets'
31/19: cluster_df = pd.DataFrame(columns=columns)
31/20:
cluster_df['Furnace'] = furnace_df_km
cluster_df['Cellar Outlets'] = cellar_df_km
cluster_df['Washing Machine'] = wash_df_km
cluster_df['Refrigerator'] = refri_df_km
cluster_df['Dishwasher'] = dish_df_km
cluster_df['Kitchen Outlets'] = kitchen_df_km
cluster_df['Bedroom 1 Lights'] = bedl_df_km
cluster_df['Bedroom 1 Outlets'] = bedo_df_km
cluster_df['Master Bedroom Lights'] = mbedl_df_km
cluster_df['Master Bedroom Outlets'] = mbedo_df_km
31/21: cluster_df.head()
31/22: cluster_df['State'] = np.zeros(246639)
31/23: cluster_df['State'] = cluster_df['Furnace'].map(str) + cluster_df['Cellar Outlets'].map(str) + cluster_df['Washing Machine'].map(str) + cluster_df['Refrigerator'].map(str) + cluster_df['Dishwasher'].map(str) + cluster_df['Kitchen Outlets'].map(str) + cluster_df['Bedroom 1 Lights'].map(str) + cluster_df['Bedroom 1 Outlets'].map(str) + cluster_df['Master Bedroom Lights'].map(str) + cluster_df['Master Bedroom Outlets'].map(str)
31/24: cluster_df.head()
31/25: columns = ['index', 'state']
31/26: lstm_data_binary = pd.DataFrame(columns= columns)
31/27: lstm_data.head()
31/28: lstm_data_binary.head()
31/29:
state = cluster_df['State']
index = np.arange(246639)
31/30: lstm_data_binary.head()
31/31:
state = cluster_df['State']
index = np.arange(246639)
31/32: columns = ['index', 'state']
31/33: lstm_data_binary = pd.DataFrame(columns= columns)
31/34: lstm_data_binary.head()
31/35: state
31/36:
lstm_data['index'] = index
lstm_data['state'] = state
31/37: lstm_data_binary.head()
31/38:
lstm_data_binary['index'] = index
lstm_data_binary['state'] = state
31/39: lstm_data_binary.head()
31/40: lstm_data_binary.to_csv('lstm_data_binary.csv')
30/21:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_error', optimizer='adam') 
model.fit(train_x2, train_y2, epochs=100, batch_size=1, verbose=2)
30/22:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='loss_mean_squared_logarithmic_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
30/23:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
30/24:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
30/25:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model.fit(train_x2, train_y2, epochs=100, batch_size=1, verbose=2)
34/1:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
34/2:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
34/3:
data_frame = pd.read_csv('lstm_data.csv')
data_set = data_frame.values
34/4: data_set
34/5: ds = data_set.astype('float32')
34/6: ds
34/7:
train_size1 = int(len(data_set) * 0.67) 
test_size1 = len(data_set) - train_size 
train1, test1 = data_set[0:train_size1,:], data_set[train_size1:len(data_set), :]
34/8:
train_size2 = int(len(ds) * 0.67) 
test_size2 = len(ds) - train_size 
train2, test2 = ds[0:train_size2,:], ds[train_size2:len(ds), :]
35/1:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
35/2:
data_frame = pd.read_csv('lstm_data.csv')
data_set = data_frame.values
35/3: data_set
35/4: ds = data_set.astype('float32')
35/5: ds
35/6:
train_size1 = int(len(data_set) * 0.67) 
test_size1 = len(data_set) - train_size1 
train1, test1 = data_set[0:train_size1,:], data_set[train_size1:len(data_set), :]
35/7:
train_size2 = int(len(ds) * 0.67) 
test_size2 = len(ds) - train_size2 
train2, test2 = ds[0:train_size2,:], ds[train_size2:len(ds), :]
35/8:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return np.array(data_x), np.array(data_y)
35/9:
look_back = 1 
train_x1, train_y1 = create_data_set(train1, look_back) 
test_x1, test_y1 = create_data_set(test1, look_back) 
train_x1 = np.reshape(train_x1,
                        (train_x1.shape[0], 1, train_x1.shape[1])) 
test_x1 = np.reshape(test_x1, 
                       (test_x1.shape[0], 1, test_x1.shape[1]))
35/10:
train_x2, train_y2 = create_data_set(train2, look_back) 
test_x2, test_y2 = create_data_set(test2, look_back) 
train_x2 = np.reshape(train_x2,
                        (train_x2.shape[0], 1, train_x2.shape[1])) 
test_x2 = np.reshape(test_x2, 
                       (test_x2.shape[0], 1, test_x2.shape[1]))
35/11:
model = Sequential() 
model.add(LSTM(4, input_shape=(1, look_back))) 
model.add(Dense(1)) 
model.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model.fit(train_x1, train_y1, epochs=100, batch_size=1, verbose=2)
41/1:
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt
41/2:
epsilons = [0, .05, .1, .15, .2, .25, .3]
pretrained_model = "data/lenet_mnist_model.pth"
use_cuda=True
41/3:
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
41/4:
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([
            transforms.ToTensor(),
            ])),
        batch_size=1, shuffle=True)
41/5:
print("CUDA Available: ",torch.cuda.is_available())
device = torch.device("cuda" if (use_cuda and torch.cuda.is_available()) else "cpu")
41/6: model = Net().to(device)
41/7: model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))
41/8: model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))
41/9: model.eval()
41/10:
def fgsm_attack(image, epsilon, data_grad):
    sign_data_grad = data_grad.sign()
    perturbed_image = image + epsilon*sign_data_grad
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image
41/11:
def test( model, device, test_loader, epsilon ):
    correct = 0
    adv_examples = []
    for data, target in test_loader:

        data, target = data.to(device), target.to(device)

        data.requires_grad = True

        output = model(data)
        init_pred = output.max(1, keepdim=True)[1] 

        if init_pred.item() != target.item():
            continue

        loss = F.nll_loss(output, target)

        model.zero_grad()

        loss.backward()

        data_grad = data.grad.data

        perturbed_data = fgsm_attack(data, epsilon, data_grad)

        output = model(perturbed_data)

        final_pred = output.max(1, keepdim=True)[1]
        if final_pred.item() == target.item():
            correct += 1
 
            if (epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )
        else:
            if len(adv_examples) < 5:
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )

    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))

    return final_acc, adv_examples
41/12:
accuracies = []
examples = []

for eps in epsilons:
    acc, ex = test(model, device, test_loader, eps)
    accuracies.append(acc)
    examples.append(ex)
42/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
44/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
44/2: print(torch.cuda.current_device())
44/3: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model & Attacks/LPR Model'
44/4: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model & Attacks/LPR Dataset'
44/5: Image(filename=Image_path+'LPR_2.png')
45/1: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR Dataset'
45/2: Image(filename=Image_path+'LPR_2.png')
45/3:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
45/4: print(torch.cuda.current_device())
45/5: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR Dataset'
45/6: Image(filename=Image_path+'LPR_2.png')
45/7: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR Dataset/'
45/8: Image(filename=Image_path+'LPR_2.png')
45/9: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR_Dataset/'
45/10: Image(filename=Image_path+'LPR_2.png')
45/11:
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#print(torch.cuda.get_device_name(device))
#device = torch.cuda.current_device(
#device
#cpu_tensor = torch.rand(10)
# moving same tensor to GPU
#gpu_tensor = cpu_tensor.to(device)

#print(cpu_tensor, cpu_tensor.dtype, type(cpu_tensor), cpu_tensor.type())
#print(gpu_tensor, gpu_tensor.dtype, type(gpu_tensor), gpu_tensor.type())
45/12:
def bn(channels):
    return BatchNorm2d(channels)
"""
Taking 2 convolutional layers in a conv Block
"""
def conv_layers(in_channels,out_channels,kernel_size,device):
    layers = []
    conv_1 = Conv2d(in_channels,out_channels,kernel_size,padding = 1).to(device)
    conv_2 = Conv2d(out_channels,out_channels,kernel_size,padding = 1).to(device)
    batch_norm = BatchNorm2d(out_channels).to(device)
    layers+=[conv_1,ReLU(inplace=True),batch_norm]
    layers+=[conv_2,ReLU(inplace=True),batch_norm]
    layers+=[MaxPool2d((2,2))]
    return layers

def linear_layers(in_features,device):
    layers = []
        
    softmax = Softmax()
    for _ in range(8):
        linear_1 = Linear(in_features,128).to(device)
        linear_2 = Linear(128,36).to(device)
        softmax = Softmax()
    
        layers.append([linear_1,linear_2,softmax])
    return layers
45/13:
#torch.squeeze?
print(torch.cuda.is_available())
45/14:
#print(device)
class Flatten(torch.nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)
45/15: torch.stack?
45/16:
class LPR_2(torch.nn.Module):
    def __init__(self,training_data=None,training_labels=None,device = 'cpu'):
        super(LPR_2,self).__init__()
        self.conv_layers = conv_layers(3,16,(3,3),device)
        self.conv_layers+=conv_layers(16,32,(3,3),device)
        self.conv_layers+=conv_layers(32,64,(3,3),device)
        self.linear_layers = linear_layers(4800,device)
        self.charac_layers = []
        #print(self.linear_layers[0])
        #print(len(self.conv_layers+self.linear_layers[0]),len(self.conv_layers),len(self.linear_layers[0]))
        #print(type(self.linear_layers[0]))
        #sel
        #self.test_obj = self.conv_layers + self.linear_layers[0]
        #print(torch.nn.Sequential(*self.test_obj))
        print(device)
        """
        if device=='cuda':
            for i in range(8):
                meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
                print(meta_model)
                meta_model = meta_model.cuda(device)
                self.charac_layers.append(meta_model)
           # print(self.charac_layers[i])
        else:
        """
        for i in range(8):
            meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
            #print(meta_model)
            self.charac_layers.append(meta_model)
        
        self.charac_layers = torch.nn.ModuleList(self.charac_layers)
           
            
                
    def forward(self,x):
        char_probs = []
        for i in range(8):
            char_probs.append(self.charac_layers[i](x))
        return torch.stack(char_probs,dim = 1)
45/17:
"""
trial_model = LPR_2(device=device)
#trial_model = trial_model
a = Variable(torch.rand((1,3,200,40))).to(device)
print(a.type())
b = trial_model(a)

print(b.shape,b.type())
"""
# Testing the model for single instance
45/18:
training_data_file_path = Image_path+'train_images.npy'
testing_data_file_path = Image_path+'test_images.npy'
training_labels_file = Image_path+'train_labels.csv'
testing_labels_file = Image_path+'test_labels.csv'
45/19:
train_data = np.load(training_data_file_path)
test_data = np.load(testing_data_file_path)
train_labels = pd.read_csv(training_labels_file)
test_labels = pd.read_csv(testing_labels_file)
45/20: print test_data.shape,train_data.shape
45/21: print(test_data.shape,train_data.shape)
45/22:
train_data_rolled = np.moveaxis(train_data,[-1],[1])
test_data_rolled = np.moveaxis(test_data,[-1],[1])
45/23:
train_labels['lp_char_list'] = train_labels['lp'].apply(lambda x: list(x))
train_labels.head()
45/24:
def plate_equalizer(lp_list):
    list_len = len(lp_list)
    add_chars = 8 - list_len
    if add_chars:
        new_list=[]
        new_list+=lp_list[:-4]
        new_list+=add_chars*['#']
        new_list+=lp_list[-4:]
        return new_list
    else:
        return lp_list
plate_equalizer(['I','V','E','S','C','O'])
45/25:
train_labels['equalized_lp_list'] = train_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
train_labels.head()
45/26:
train_labels['lp_len'] = train_labels['equalized_lp_list'].apply(lambda x: len(x))
train_labels[train_labels['lp_len']!=8]
45/27:
vocab_list=[]
def list_add(vocab_list,x):
    vocab_list+=x
train_labels['equalized_lp_list'].apply(lambda x : list_add(vocab_list,x))
len(vocab_list)
45/28:
le = LabelEncoder()
le.fit(vocab_list)
45/29:
train_labels['encoded_lp'] = train_labels['equalized_lp_list'].apply(lambda x: le.transform(x))
train_labels.head()
45/30:
test_labels['lp_char_list'] = test_labels['lp'].apply(lambda x:list(x))
test_labels['equalized_lp_list'] = test_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
test_labels['lp_len'] = test_labels['equalized_lp_list'].apply(lambda x: len(x))
test_labels.head()
45/31:
test_labels['encoded_lp'] = test_labels['equalized_lp_list'].apply(lambda x : le.transform(x))
test_labels.head()
45/32:
train_labels_np = np.stack(train_labels['encoded_lp'].tolist(),axis = 0)
#train_labels_tensor = torch.from_numpy(train_labels_np).long().to(device)
#print train_labels_tensor.type()
45/33: loss_function = CrossEntropyLoss()
45/34: epochs = 100
45/35:
X_train,X_val,Y_train,Y_val = train_test_split(train_data_rolled,train_labels_np,test_size = 0.1,random_state=42)
print X_train.shape,X_val.shape
print Y_train.shape,Y_val.shape
45/36:
X_train,X_val,Y_train,Y_val = train_test_split(train_data_rolled,train_labels_np,test_size = 0.1,random_state=42)
print(X_train.shape,X_val.shape)
print(Y_train.shape,Y_val.shape)
45/37:
model = LPR_2(device=device)
optim = Adam(list(model.parameters()),lr = 0.001)
train_test_split = 0.8
45/38:
def get_batch(train_data,train_labels,batch_size = 32):
    start = 0
    end = batch_size
    while(start<=train_data.shape[0]):
        yield(torch.from_numpy(train_data[start:end]).float().to(device),torch.from_numpy(train_labels[start:end]).long().to(device))
        start+=batch_size
        end+=batch_size
45/39:
for data,labels in get_batch(X_train,Y_train,10000):
    print data.shape, labels.shape, data.type(),labels.type()
45/40:
for data,labels in get_batch(X_train,Y_train,10000):
    print(data.shape, labels.shape, data.type(),labels.type())
45/41:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print "-----For Epoch:{}----".format(epoch+1)
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        match = preds==val_label
        #print(match.shape)
        #accuracy = min(match.float().mean())
        #print "for validation batch:{}-->accuracy:{}".format(i+1,accuracy)
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print "Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy)
45/42:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        match = preds==val_label
        #print(match.shape)
        #accuracy = min(match.float().mean())
        #print "for validation batch:{}-->accuracy:{}".format(i+1,accuracy)
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
45/43: dtype(val_label)
45/44: val_label.dtype
45/45: preds.dtype
45/46:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        torch.cuda.tensor(preds)
        match = preds==val_label
        #print(match.shape)
        #accuracy = min(match.float().mean())
        #print "for validation batch:{}-->accuracy:{}".format(i+1,accuracy)
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
45/47:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        torch.tensor(preds)
        match = preds==val_label
        #print(match.shape)
        #accuracy = min(match.float().mean())
        #print "for validation batch:{}-->accuracy:{}".format(i+1,accuracy)
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
45/48: torch.cuda.empty_cache()
45/49:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        torch.tensor(preds)
        match = preds==val_label
        #print(match.shape)
        #accuracy = min(match.float().mean())
        #print "for validation batch:{}-->accuracy:{}".format(i+1,accuracy)
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
45/50:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        torch.tensor(preds)
        match = preds==val_label
        #print(match.shape)
        #accuracy = min(match.float().mean())
        #print "for validation batch:{}-->accuracy:{}".format(i+1,accuracy)
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
45/51:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = torch.tensor(np.argmax(val_outputs.detach().cpu().numpy(),axis = -1))
        match = preds==val_label
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
45/52: torch.cuda.empty_cache()
45/53:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = torch.tensor(np.argmax(val_outputs.detach().cpu().numpy(),axis = -1))
        match = preds==val_label
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
47/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
48/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
48/2: print(torch.cuda.current_device())
48/3: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR_Dataset/'
48/4: Image(filename=Image_path+'LPR_2.png')
48/5: device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
48/6:
def bn(channels):
    return BatchNorm2d(channels)
"""
Taking 2 convolutional layers in a conv Block
"""
def conv_layers(in_channels,out_channels,kernel_size,device):
    layers = []
    conv_1 = Conv2d(in_channels,out_channels,kernel_size,padding = 1).to(device)
    conv_2 = Conv2d(out_channels,out_channels,kernel_size,padding = 1).to(device)
    batch_norm = BatchNorm2d(out_channels).to(device)
    layers+=[conv_1,ReLU(inplace=True),batch_norm]
    layers+=[conv_2,ReLU(inplace=True),batch_norm]
    layers+=[MaxPool2d((2,2))]
    return layers

def linear_layers(in_features,device):
    layers = []
        
    softmax = Softmax()
    for _ in range(8):
        linear_1 = Linear(in_features,128).to(device)
        linear_2 = Linear(128,36).to(device)
        softmax = Softmax()
    
        layers.append([linear_1,linear_2,softmax])
    return layers
48/7: print(torch.cuda.is_available())
48/8:
#print(device)
class Flatten(torch.nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)
48/9: torch.stack?
48/10:
class LPR_2(torch.nn.Module):
    def __init__(self,training_data=None,training_labels=None,device = 'cpu'):
        super(LPR_2,self).__init__()
        self.conv_layers = conv_layers(3,16,(3,3),device)
        self.conv_layers+=conv_layers(16,32,(3,3),device)
        self.conv_layers+=conv_layers(32,64,(3,3),device)
        self.linear_layers = linear_layers(4800,device)
        self.charac_layers = []
        #print(self.linear_layers[0])
        #print(len(self.conv_layers+self.linear_layers[0]),len(self.conv_layers),len(self.linear_layers[0]))
        #print(type(self.linear_layers[0]))
        #sel
        #self.test_obj = self.conv_layers + self.linear_layers[0]
        #print(torch.nn.Sequential(*self.test_obj))
        print(device)
        """
        if device=='cuda':
            for i in range(8):
                meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
                print(meta_model)
                meta_model = meta_model.cuda(device)
                self.charac_layers.append(meta_model)
           # print(self.charac_layers[i])
        else:
        """
        for i in range(8):
            meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
            #print(meta_model)
            self.charac_layers.append(meta_model)
        
        self.charac_layers = torch.nn.ModuleList(self.charac_layers)
           
            
                
    def forward(self,x):
        char_probs = []
        for i in range(8):
            char_probs.append(self.charac_layers[i](x))
        return torch.stack(char_probs,dim = 1)
48/11:
"""
trial_model = LPR_2(device=device)
#trial_model = trial_model
a = Variable(torch.rand((1,3,200,40))).to(device)
print(a.type())
b = trial_model(a)

print(b.shape,b.type())
"""
# Testing the model for single instance
48/12:
training_data_file_path = Image_path+'train_images.npy'
testing_data_file_path = Image_path+'test_images.npy'
training_labels_file = Image_path+'train_labels.csv'
testing_labels_file = Image_path+'test_labels.csv'
48/13:
train_data = np.load(training_data_file_path)
test_data = np.load(testing_data_file_path)
train_labels = pd.read_csv(training_labels_file)
test_labels = pd.read_csv(testing_labels_file)
48/14: print(test_data.shape,train_data.shape)
48/15:
train_data_rolled = np.moveaxis(train_data,[-1],[1])
test_data_rolled = np.moveaxis(test_data,[-1],[1])
48/16:
train_labels['lp_char_list'] = train_labels['lp'].apply(lambda x: list(x))
train_labels.head()
48/17:
def plate_equalizer(lp_list):
    list_len = len(lp_list)
    add_chars = 8 - list_len
    if add_chars:
        new_list=[]
        new_list+=lp_list[:-4]
        new_list+=add_chars*['#']
        new_list+=lp_list[-4:]
        return new_list
    else:
        return lp_list
plate_equalizer(['I','V','E','S','C','O'])
48/18:
train_labels['equalized_lp_list'] = train_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
train_labels.head()
48/19:
train_labels['lp_len'] = train_labels['equalized_lp_list'].apply(lambda x: len(x))
train_labels[train_labels['lp_len']!=8]
48/20:
vocab_list=[]
def list_add(vocab_list,x):
    vocab_list+=x
train_labels['equalized_lp_list'].apply(lambda x : list_add(vocab_list,x))
len(vocab_list)
48/21:
le = LabelEncoder()
le.fit(vocab_list)
48/22:
train_labels['encoded_lp'] = train_labels['equalized_lp_list'].apply(lambda x: le.transform(x))
train_labels.head()
48/23:
test_labels['lp_char_list'] = test_labels['lp'].apply(lambda x:list(x))
test_labels['equalized_lp_list'] = test_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
test_labels['lp_len'] = test_labels['equalized_lp_list'].apply(lambda x: len(x))
test_labels.head()
48/24:
test_labels['encoded_lp'] = test_labels['equalized_lp_list'].apply(lambda x : le.transform(x))
test_labels.head()
48/25: train_labels_np = np.stack(train_labels['encoded_lp'].tolist(),axis = 0)
48/26: loss_function = CrossEntropyLoss()
48/27: epochs = 100
48/28:
X_train,X_val,Y_train,Y_val = train_test_split(train_data_rolled,train_labels_np,test_size = 0.1,random_state=42)
print(X_train.shape,X_val.shape)
print(Y_train.shape,Y_val.shape)
48/29:
model = LPR_2(device=device)
optim = Adam(list(model.parameters()),lr = 0.001)
train_test_split = 0.8
48/30:
def get_batch(train_data,train_labels,batch_size = 32):
    start = 0
    end = batch_size
    while(start<=train_data.shape[0]):
        yield(torch.from_numpy(train_data[start:end]).float().to(device),torch.from_numpy(train_labels[start:end]).long().to(device))
        start+=batch_size
        end+=batch_size
48/31:
for data,labels in get_batch(X_train,Y_train,10000):
    print(data.shape, labels.shape, data.type(),labels.type())
48/32: val_label.dtype
48/33: torch.cuda.empty_cache()
48/34:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = torch.tensor(np.argmax(val_outputs.detach().cpu().numpy(),axis = -1))
        match = preds==val_label
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
48/35: preds.dtype
48/36: val_label.dtype
50/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
50/2: print(torch.cuda.current_device())
50/3: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR_Dataset/'
50/4: Image(filename=Image_path+'LPR_2.png')
50/5: device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
50/6:
def bn(channels):
    return BatchNorm2d(channels)
"""
Taking 2 convolutional layers in a conv Block
"""
def conv_layers(in_channels,out_channels,kernel_size,device):
    layers = []
    conv_1 = Conv2d(in_channels,out_channels,kernel_size,padding = 1).to(device)
    conv_2 = Conv2d(out_channels,out_channels,kernel_size,padding = 1).to(device)
    batch_norm = BatchNorm2d(out_channels).to(device)
    layers+=[conv_1,ReLU(inplace=True),batch_norm]
    layers+=[conv_2,ReLU(inplace=True),batch_norm]
    layers+=[MaxPool2d((2,2))]
    return layers

def linear_layers(in_features,device):
    layers = []
        
    softmax = Softmax()
    for _ in range(8):
        linear_1 = Linear(in_features,128).to(device)
        linear_2 = Linear(128,36).to(device)
        softmax = Softmax()
    
        layers.append([linear_1,linear_2,softmax])
    return layers
50/7: print(torch.cuda.is_available())
50/8:
#print(device)
class Flatten(torch.nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)
50/9: torch.stack?
50/10:
class LPR_2(torch.nn.Module):
    def __init__(self,training_data=None,training_labels=None,device = 'cpu'):
        super(LPR_2,self).__init__()
        self.conv_layers = conv_layers(3,16,(3,3),device)
        self.conv_layers+=conv_layers(16,32,(3,3),device)
        self.conv_layers+=conv_layers(32,64,(3,3),device)
        self.linear_layers = linear_layers(4800,device)
        self.charac_layers = []
        #print(self.linear_layers[0])
        #print(len(self.conv_layers+self.linear_layers[0]),len(self.conv_layers),len(self.linear_layers[0]))
        #print(type(self.linear_layers[0]))
        #sel
        #self.test_obj = self.conv_layers + self.linear_layers[0]
        #print(torch.nn.Sequential(*self.test_obj))
        print(device)
        """
        if device=='cuda':
            for i in range(8):
                meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
                print(meta_model)
                meta_model = meta_model.cuda(device)
                self.charac_layers.append(meta_model)
           # print(self.charac_layers[i])
        else:
        """
        for i in range(8):
            meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
            #print(meta_model)
            self.charac_layers.append(meta_model)
        
        self.charac_layers = torch.nn.ModuleList(self.charac_layers)
           
            
                
    def forward(self,x):
        char_probs = []
        for i in range(8):
            char_probs.append(self.charac_layers[i](x))
        return torch.stack(char_probs,dim = 1)
50/11:
"""
trial_model = LPR_2(device=device)
#trial_model = trial_model
a = Variable(torch.rand((1,3,200,40))).to(device)
print(a.type())
b = trial_model(a)

print(b.shape,b.type())
"""
# Testing the model for single instance
50/12:
training_data_file_path = Image_path+'train_images.npy'
testing_data_file_path = Image_path+'test_images.npy'
training_labels_file = Image_path+'train_labels.csv'
testing_labels_file = Image_path+'test_labels.csv'
50/13:
train_data = np.load(training_data_file_path)
test_data = np.load(testing_data_file_path)
train_labels = pd.read_csv(training_labels_file)
test_labels = pd.read_csv(testing_labels_file)
50/14: print(test_data.shape,train_data.shape)
50/15:
train_data_rolled = np.moveaxis(train_data,[-1],[1])
test_data_rolled = np.moveaxis(test_data,[-1],[1])
50/16:
train_labels['lp_char_list'] = train_labels['lp'].apply(lambda x: list(x))
train_labels.head()
50/17:
def plate_equalizer(lp_list):
    list_len = len(lp_list)
    add_chars = 8 - list_len
    if add_chars:
        new_list=[]
        new_list+=lp_list[:-4]
        new_list+=add_chars*['#']
        new_list+=lp_list[-4:]
        return new_list
    else:
        return lp_list
plate_equalizer(['I','V','E','S','C','O'])
50/18:
train_labels['equalized_lp_list'] = train_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
train_labels.head()
50/19:
train_labels['lp_len'] = train_labels['equalized_lp_list'].apply(lambda x: len(x))
train_labels[train_labels['lp_len']!=8]
50/20:
train_labels['equalized_lp_list'] = train_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
train_labels.head()
50/21:
train_labels['lp_len'] = train_labels['equalized_lp_list'].apply(lambda x: len(x))
train_labels[train_labels['lp_len']!=8]
50/22:
vocab_list=[]
def list_add(vocab_list,x):
    vocab_list+=x
train_labels['equalized_lp_list'].apply(lambda x : list_add(vocab_list,x))
len(vocab_list)
50/23:
le = LabelEncoder()
le.fit(vocab_list)
50/24:
train_labels['encoded_lp'] = train_labels['equalized_lp_list'].apply(lambda x: le.transform(x))
train_labels.head()
50/25:
test_labels['lp_char_list'] = test_labels['lp'].apply(lambda x:list(x))
test_labels['equalized_lp_list'] = test_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
test_labels['lp_len'] = test_labels['equalized_lp_list'].apply(lambda x: len(x))
test_labels.head()
50/26:
test_labels['encoded_lp'] = test_labels['equalized_lp_list'].apply(lambda x : le.transform(x))
test_labels.head()
50/27: train_labels_np = np.stack(train_labels['encoded_lp'].tolist(),axis = 0)
50/28: loss_function = CrossEntropyLoss()
50/29: epochs = 100
50/30:
X_train,X_val,Y_train,Y_val = train_test_split(train_data_rolled,train_labels_np,test_size = 0.1,random_state=42)
print(X_train.shape,X_val.shape)
print(Y_train.shape,Y_val.shape)
50/31:
model = LPR_2(device=device)
optim = Adam(list(model.parameters()),lr = 0.001)
train_test_split = 0.8
50/32:
def get_batch(train_data,train_labels,batch_size = 32):
    start = 0
    end = batch_size
    while(start<=train_data.shape[0]):
        yield(torch.from_numpy(train_data[start:end]).float().to(device),torch.from_numpy(train_labels[start:end]).long().to(device))
        start+=batch_size
        end+=batch_size
50/33:
for data,labels in get_batch(X_train,Y_train,10000):
    print(data.shape, labels.shape, data.type(),labels.type())
50/34: torch.cuda.empty_cache()
50/35:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        val_label_np = val_label.detach().cpu().numpy()
        match = preds==val_label
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
52/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
52/2: print(torch.cuda.current_device())
52/3: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR_Dataset/'
52/4: Image(filename=Image_path+'LPR_2.png')
52/5: device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
52/6:
def bn(channels):
    return BatchNorm2d(channels)
"""
Taking 2 convolutional layers in a conv Block
"""
def conv_layers(in_channels,out_channels,kernel_size,device):
    layers = []
    conv_1 = Conv2d(in_channels,out_channels,kernel_size,padding = 1).to(device)
    conv_2 = Conv2d(out_channels,out_channels,kernel_size,padding = 1).to(device)
    batch_norm = BatchNorm2d(out_channels).to(device)
    layers+=[conv_1,ReLU(inplace=True),batch_norm]
    layers+=[conv_2,ReLU(inplace=True),batch_norm]
    layers+=[MaxPool2d((2,2))]
    return layers

def linear_layers(in_features,device):
    layers = []
        
    softmax = Softmax()
    for _ in range(8):
        linear_1 = Linear(in_features,128).to(device)
        linear_2 = Linear(128,36).to(device)
        softmax = Softmax()
    
        layers.append([linear_1,linear_2,softmax])
    return layers
52/7: print(torch.cuda.is_available())
52/8:
#print(device)
class Flatten(torch.nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)
52/9: torch.stack?
52/10:
class LPR_2(torch.nn.Module):
    def __init__(self,training_data=None,training_labels=None,device = 'cpu'):
        super(LPR_2,self).__init__()
        self.conv_layers = conv_layers(3,16,(3,3),device)
        self.conv_layers+=conv_layers(16,32,(3,3),device)
        self.conv_layers+=conv_layers(32,64,(3,3),device)
        self.linear_layers = linear_layers(4800,device)
        self.charac_layers = []
        #print(self.linear_layers[0])
        #print(len(self.conv_layers+self.linear_layers[0]),len(self.conv_layers),len(self.linear_layers[0]))
        #print(type(self.linear_layers[0]))
        #sel
        #self.test_obj = self.conv_layers + self.linear_layers[0]
        #print(torch.nn.Sequential(*self.test_obj))
        print(device)
        """
        if device=='cuda':
            for i in range(8):
                meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
                print(meta_model)
                meta_model = meta_model.cuda(device)
                self.charac_layers.append(meta_model)
           # print(self.charac_layers[i])
        else:
        """
        for i in range(8):
            meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
            #print(meta_model)
            self.charac_layers.append(meta_model)
        
        self.charac_layers = torch.nn.ModuleList(self.charac_layers)
           
            
                
    def forward(self,x):
        char_probs = []
        for i in range(8):
            char_probs.append(self.charac_layers[i](x))
        return torch.stack(char_probs,dim = 1)
52/11:
"""
trial_model = LPR_2(device=device)
#trial_model = trial_model
a = Variable(torch.rand((1,3,200,40))).to(device)
print(a.type())
b = trial_model(a)

print(b.shape,b.type())
"""
# Testing the model for single instance
52/12:
training_data_file_path = Image_path+'train_images.npy'
testing_data_file_path = Image_path+'test_images.npy'
training_labels_file = Image_path+'train_labels.csv'
testing_labels_file = Image_path+'test_labels.csv'
52/13:
train_data = np.load(training_data_file_path)
test_data = np.load(testing_data_file_path)
train_labels = pd.read_csv(training_labels_file)
test_labels = pd.read_csv(testing_labels_file)
52/14: print(test_data.shape,train_data.shape)
52/15:
train_data_rolled = np.moveaxis(train_data,[-1],[1])
test_data_rolled = np.moveaxis(test_data,[-1],[1])
52/16:
train_labels['lp_char_list'] = train_labels['lp'].apply(lambda x: list(x))
train_labels.head()
52/17:
def plate_equalizer(lp_list):
    list_len = len(lp_list)
    add_chars = 8 - list_len
    if add_chars:
        new_list=[]
        new_list+=lp_list[:-4]
        new_list+=add_chars*['#']
        new_list+=lp_list[-4:]
        return new_list
    else:
        return lp_list
plate_equalizer(['I','V','E','S','C','O'])
52/18:
train_labels['equalized_lp_list'] = train_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
train_labels.head()
52/19:
train_labels['lp_len'] = train_labels['equalized_lp_list'].apply(lambda x: len(x))
train_labels[train_labels['lp_len']!=8]
52/20:
vocab_list=[]
def list_add(vocab_list,x):
    vocab_list+=x
train_labels['equalized_lp_list'].apply(lambda x : list_add(vocab_list,x))
len(vocab_list)
52/21:
le = LabelEncoder()
le.fit(vocab_list)
52/22:
train_labels['encoded_lp'] = train_labels['equalized_lp_list'].apply(lambda x: le.transform(x))
train_labels.head()
52/23:
test_labels['lp_char_list'] = test_labels['lp'].apply(lambda x:list(x))
test_labels['equalized_lp_list'] = test_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
test_labels['lp_len'] = test_labels['equalized_lp_list'].apply(lambda x: len(x))
test_labels.head()
52/24:
test_labels['encoded_lp'] = test_labels['equalized_lp_list'].apply(lambda x : le.transform(x))
test_labels.head()
52/25: train_labels_np = np.stack(train_labels['encoded_lp'].tolist(),axis = 0)
52/26: loss_function = CrossEntropyLoss()
52/27: epochs = 100
52/28:
X_train,X_val,Y_train,Y_val = train_test_split(train_data_rolled,train_labels_np,test_size = 0.1,random_state=42)
print(X_train.shape,X_val.shape)
print(Y_train.shape,Y_val.shape)
52/29:
model = LPR_2(device=device)
optim = Adam(list(model.parameters()),lr = 0.001)
train_test_split = 0.8
52/30:
def get_batch(train_data,train_labels,batch_size = 32):
    start = 0
    end = batch_size
    while(start<=train_data.shape[0]):
        yield(torch.from_numpy(train_data[start:end]).float().to(device),torch.from_numpy(train_labels[start:end]).long().to(device))
        start+=batch_size
        end+=batch_size
52/31:
for data,labels in get_batch(X_train,Y_train,10000):
    print(data.shape, labels.shape, data.type(),labels.type())
52/32: torch.cuda.empty_cache()
52/33:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = torch.tensor(np.argmax(val_outputs.detach().cpu().numpy(),axis = -1))
        val_label_np = torch.tensor(val_label.detach().cpu().numpy())
        match = preds==val_label
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
53/1:
import numpy as np
import torch
import cv2
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from torch.nn import Conv2d,Linear,BatchNorm2d,MaxPool2d,ReLU, Softmax, CrossEntropyLoss
from torch.autograd import Variable
#from torch.nn.functional import softmax
from IPython.display import Image
from skimage.io import imshow
from torch.optim import Adam
import torch.nn as nn
from sklearn.preprocessing import LabelEncoder
import os
from torch.optim import Adam
from sklearn.model_selection import train_test_split
53/2: print(torch.cuda.current_device())
53/3: Image_path = '/home/siddhantb/Adversarial Attacks/LPR Model and Attacks/LPR_Dataset/'
53/4: Image(filename=Image_path+'LPR_2.png')
53/5: device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
53/6:
def bn(channels):
    return BatchNorm2d(channels)
"""
Taking 2 convolutional layers in a conv Block
"""
def conv_layers(in_channels,out_channels,kernel_size,device):
    layers = []
    conv_1 = Conv2d(in_channels,out_channels,kernel_size,padding = 1).to(device)
    conv_2 = Conv2d(out_channels,out_channels,kernel_size,padding = 1).to(device)
    batch_norm = BatchNorm2d(out_channels).to(device)
    layers+=[conv_1,ReLU(inplace=True),batch_norm]
    layers+=[conv_2,ReLU(inplace=True),batch_norm]
    layers+=[MaxPool2d((2,2))]
    return layers

def linear_layers(in_features,device):
    layers = []
        
    softmax = Softmax()
    for _ in range(8):
        linear_1 = Linear(in_features,128).to(device)
        linear_2 = Linear(128,36).to(device)
        softmax = Softmax()
    
        layers.append([linear_1,linear_2,softmax])
    return layers
53/7: print(torch.cuda.is_available())
53/8:
#print(device)
class Flatten(torch.nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)
53/9: torch.stack?
53/10:
class LPR_2(torch.nn.Module):
    def __init__(self,training_data=None,training_labels=None,device = 'cpu'):
        super(LPR_2,self).__init__()
        self.conv_layers = conv_layers(3,16,(3,3),device)
        self.conv_layers+=conv_layers(16,32,(3,3),device)
        self.conv_layers+=conv_layers(32,64,(3,3),device)
        self.linear_layers = linear_layers(4800,device)
        self.charac_layers = []
        #print(self.linear_layers[0])
        #print(len(self.conv_layers+self.linear_layers[0]),len(self.conv_layers),len(self.linear_layers[0]))
        #print(type(self.linear_layers[0]))
        #sel
        #self.test_obj = self.conv_layers + self.linear_layers[0]
        #print(torch.nn.Sequential(*self.test_obj))
        print(device)
        """
        if device=='cuda':
            for i in range(8):
                meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
                print(meta_model)
                meta_model = meta_model.cuda(device)
                self.charac_layers.append(meta_model)
           # print(self.charac_layers[i])
        else:
        """
        for i in range(8):
            meta_model = torch.nn.Sequential(*(self.conv_layers+[Flatten()]+self.linear_layers[i]))
            #print(meta_model)
            self.charac_layers.append(meta_model)
        
        self.charac_layers = torch.nn.ModuleList(self.charac_layers)
           
            
                
    def forward(self,x):
        char_probs = []
        for i in range(8):
            char_probs.append(self.charac_layers[i](x))
        return torch.stack(char_probs,dim = 1)
53/11:
"""
trial_model = LPR_2(device=device)
#trial_model = trial_model
a = Variable(torch.rand((1,3,200,40))).to(device)
print(a.type())
b = trial_model(a)

print(b.shape,b.type())
"""
# Testing the model for single instance
53/12:
training_data_file_path = Image_path+'train_images.npy'
testing_data_file_path = Image_path+'test_images.npy'
training_labels_file = Image_path+'train_labels.csv'
testing_labels_file = Image_path+'test_labels.csv'
53/13:
train_data = np.load(training_data_file_path)
test_data = np.load(testing_data_file_path)
train_labels = pd.read_csv(training_labels_file)
test_labels = pd.read_csv(testing_labels_file)
53/14: print(test_data.shape,train_data.shape)
53/15:
train_data_rolled = np.moveaxis(train_data,[-1],[1])
test_data_rolled = np.moveaxis(test_data,[-1],[1])
53/16:
train_labels['lp_char_list'] = train_labels['lp'].apply(lambda x: list(x))
train_labels.head()
53/17:
def plate_equalizer(lp_list):
    list_len = len(lp_list)
    add_chars = 8 - list_len
    if add_chars:
        new_list=[]
        new_list+=lp_list[:-4]
        new_list+=add_chars*['#']
        new_list+=lp_list[-4:]
        return new_list
    else:
        return lp_list
plate_equalizer(['I','V','E','S','C','O'])
53/18:
train_labels['equalized_lp_list'] = train_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
train_labels.head()
53/19:
train_labels['lp_len'] = train_labels['equalized_lp_list'].apply(lambda x: len(x))
train_labels[train_labels['lp_len']!=8]
53/20:
vocab_list=[]
def list_add(vocab_list,x):
    vocab_list+=x
train_labels['equalized_lp_list'].apply(lambda x : list_add(vocab_list,x))
len(vocab_list)
53/21:
le = LabelEncoder()
le.fit(vocab_list)
53/22:
train_labels['encoded_lp'] = train_labels['equalized_lp_list'].apply(lambda x: le.transform(x))
train_labels.head()
53/23:
test_labels['lp_char_list'] = test_labels['lp'].apply(lambda x:list(x))
test_labels['equalized_lp_list'] = test_labels['lp_char_list'].apply(lambda x :plate_equalizer(x))
test_labels['lp_len'] = test_labels['equalized_lp_list'].apply(lambda x: len(x))
test_labels.head()
53/24:
test_labels['encoded_lp'] = test_labels['equalized_lp_list'].apply(lambda x : le.transform(x))
test_labels.head()
53/25: train_labels_np = np.stack(train_labels['encoded_lp'].tolist(),axis = 0)
53/26: loss_function = CrossEntropyLoss()
53/27: epochs = 100
53/28:
X_train,X_val,Y_train,Y_val = train_test_split(train_data_rolled,train_labels_np,test_size = 0.1,random_state=42)
print(X_train.shape,X_val.shape)
print(Y_train.shape,Y_val.shape)
53/29:
model = LPR_2(device=device)
optim = Adam(list(model.parameters()),lr = 0.001)
train_test_split = 0.8
53/30:
def get_batch(train_data,train_labels,batch_size = 32):
    start = 0
    end = batch_size
    while(start<=train_data.shape[0]):
        yield(torch.from_numpy(train_data[start:end]).float().to(device),torch.from_numpy(train_labels[start:end]).long().to(device))
        start+=batch_size
        end+=batch_size
53/31:
for data,labels in get_batch(X_train,Y_train,10000):
    print(data.shape, labels.shape, data.type(),labels.type())
53/32: torch.cuda.empty_cache()
53/33:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        val_label_np = val_label.detach().cpu().numpy()
        match = preds==val_label
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
53/34:
for epoch in range(epochs):
    training_loss = 0
    val_loss = 0
    val_matrix = []
    for data, label in get_batch(X_train,Y_train,128):
        
        optim.zero_grad()
        outputs = model(data)
        #outputs = torch.max(outputs,dim = -1)
        outputs = outputs.view(-1,36)
        label = torch.squeeze(label.view(-1,1))
        #print(outputs.shape,label.shape)
        loss = loss_function(outputs,label)
        loss.backward()
        optim.step()
        #print "Training for "
        training_loss+=loss.item()
    
    print("-----For Epoch:{}----".format(epoch+1))
    
    for val_data,val_label in get_batch(X_val,Y_val,128):
        val_outputs = model(val_data)
        val_outputs_temp = val_outputs.view(-1,36)
        val_label_temp = torch.squeeze(val_label.view(-1,1))
        loss_val = loss_function(val_outputs_temp,val_label_temp)
        val_loss+=loss_val.item()
        preds = np.argmax(val_outputs.detach().cpu().numpy(),axis = -1)
        val_label_np = val_label.detach().cpu().numpy()
        match = preds==val_label_np
        val_matrix.append(match)
        
    val_matrix = np.vstack(val_matrix)
    accuracy = np.min(val_matrix.mean(axis = 0))
    print("Val Loss :{} , Training Loss: {}, Val Acc : {}".format(val_loss/X_val.shape[0],training_loss/X_train.shape[0],accuracy))
59/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
59/2:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from AdvBoxCustom.adversary import Adversary
from AdvBoxCustom.attacks.gradient_method import FGSMT
from AdvBoxCustom.attacks.gradient_method import FGSM
from AdvBoxCustom.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
59/3:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from AdvBoxCustom.adversary import Adversary
from AdvBoxCustom.attacks.gradient_method import FGSMT
from AdvBoxCustom.attacks.gradient_method import FGSM
from AdvBoxCustom.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
59/4:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
60/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
61/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
# from advbox.adversary import Adversary
# from advbox.attacks.gradient_method import FGSMT
# from advbox.attacks.gradient_method import FGSM
# from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
62/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models

# from advbox.adversary import Adversary
# from advbox.attacks.gradient_method import FGSMT
# from advbox.attacks.gradient_method import FGSM
# from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
63/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models

# from advbox.adversary import Adversary
# from advbox.attacks.gradient_method import FGSMT
# from advbox.attacks.gradient_method import FGSM
# from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
64/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
65/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
66/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
67/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
67/2:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
68/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
69/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
70/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
70/2:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
70/3:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
71/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
71/2: image_path = '../cropped_panda.jpg'
71/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
72/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
72/2:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
from tools import show_images_diff
72/3:
#
image_path="tutorials/cropped_panda.jpg"
72/4:
# Define what device we are using
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
71/4:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
73/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
73/2: image_path = '../cropped_panda.jpg'
73/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
73/4:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
74/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
74/2: image_path = '../cropped_panda.jpg'
74/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
75/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
75/2: image_path = '../cropped_panda.jpg'
75/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
76/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
76/2: image_path = '../cropped_panda.jpg'
76/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
76/4:
adv = adv.transpose(1, 2, 0)
adv = (adv * std) + mean
adv = adv * 256.0
adv = np.clip(adv, 0, 255).astype(np.uint8)
76/5: show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
76/6: image_path = '../License Plate Sample.jpg'
76/7:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
76/8:
adv = adv.transpose(1, 2, 0)
adv = (adv * std) + mean
adv = adv * 256.0
adv = np.clip(adv, 0, 255).astype(np.uint8)
76/9: show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
77/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
77/2: image_path = '../License Plate Sample.jpg'
77/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#DeepFool 
attack = DeepFoolAttack(m)
attack_config = {"iterations": 100, "overshoot": 0.02}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("deepfool attack done")
77/4:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#DeepFool 
attack = DeepFoolAttack(m)
attack_config = {"iterations": 100, "overshoot": 0.02}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("deepfool attack done")
78/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
78/2: image_path = '../License Plate Sample.jpg'
78/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#DeepFool 
attack = DeepFoolAttack(m)
attack_config = {"iterations": 100, "overshoot": 0.02}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("deepfool attack done")
78/4:
adv = adv.transpose(1, 2, 0)
adv = (adv * std) + mean
adv = adv * 256.0
adv = np.clip(adv, 0, 255).astype(np.uint8)
78/5: show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
80/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.saliency import JSMA
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
80/2: image_path = '../License Plate Sample.jpg'
80/3:
# Define what device we are using
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#JSMA max_iter  theta max_perturbations_per_pixel
attack = JSMA(m)
attack_config = {
        "max_iter": 2000,
        "theta": 0.3,
        "max_perturbations_per_pixel": 7,
        "fast":True,
        "two_pix":False
}


inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("jsma attack done")
80/4:
adv = adv.transpose(1, 2, 0)
adv = (adv * std) + mean
adv = adv * 256.0
adv = np.clip(adv, 0, 255).astype(np.uint8)
80/5: show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
81/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.lbfgs import LBFGS
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
81/2: image_path = '../License Plate Sample.jpg'
81/3:
# Define what device we are using
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#JSMA max_iter  theta max_perturbations_per_pixel
attack = LBFGS(m)
attack_config = {
        "max_iter": 2000,
        "theta": 0.3,
        "max_perturbations_per_pixel": 7,
        "fast":True,
        "two_pix":False
}


inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("lbfgs attack done")
81/4:
# Define what device we are using
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#JSMA max_iter  theta max_perturbations_per_pixel
attack = LBFGS(m)
attack_config = {}


inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("lbfgs attack done")
81/5:
# Define what device we are using
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
adv=None
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)

#JSMA max_iter  theta max_perturbations_per_pixel
attack = LBFGS(m)


inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

#
tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary)

if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("lbfgs attack done")
82/1:
import torch
import torch.nn as nn
device = "cuda" if torch.cuda.is_available() else "cpu"
82/2:
from torchvision.models import resnet101
from advertorch.utils import predict_from_logits
from advertorch.utils import NormalizeByChannelMeanStd

normalize = NormalizeByChannelMeanStd(
    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
model = resnet101(pretrained=True)
model.eval()
model = nn.Sequential(normalize, model)
model = model.to(device)
82/3:
from advertorch_examples.utils import ImageNetClassNameLookup
from advertorch_examples.utils import get_panda_image
from advertorch_examples.utils import bhwc2bchw
from advertorch_examples.utils import bchw2bhwc


np_img = get_panda_image()
img = torch.tensor(bhwc2bchw(np_img))[None, :, :, :].float().to(device)
label = torch.tensor([388, ]).long().to(device)
imagenet_label2classname = ImageNetClassNameLookup()
82/4:
from advertorch.attacks import LinfPGDAttack

adversary = LinfPGDAttack(
    model, eps=1. / 255, eps_iter=0.25 / 255, nb_iter=10,
    rand_init=False, targeted=False)

advimg = adversary.perturb(img, label)
82/5:
def tensor2npimg(tensor):
    return bchw2bhwc(tensor[0].cpu().numpy())

np_advimg = tensor2npimg(advimg)
np_perturb = tensor2npimg(advimg - img)

pred = imagenet_label2classname(predict_from_logits(model(img)))
advpred = imagenet_label2classname(predict_from_logits(model(advimg)))

import matplotlib.pyplot as plt
%matplotlib inline

plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.imshow(np_img)
plt.axis("off")
plt.title("original image\n prediction: {}".format(pred))
plt.subplot(1, 3, 2)
plt.imshow(np_perturb * 127 + 0.5)
plt.axis("off")
plt.title("the perturbation,\n enhanced 127 times".format(pred))
plt.subplot(1, 3, 3)
plt.imshow(np_advimg)
plt.axis("off")
plt.title("perturbed image\n prediction: {}".format(advpred))
plt.show()
85/1:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
85/2:
data_frame = pd.read_csv('lstm_data.csv')
data_set = data_frame.values
85/3: data_set
85/4: ds = data_set.astype('float32')
85/5: ds
85/6:
train_size1 = int(len(data_set) * 0.67) 
test_size1 = len(data_set) - train_size1 
train1, test1 = data_set[0:train_size1,:], data_set[train_size1:len(data_set), :]
85/7:
train_size2 = int(len(ds) * 0.67) 
test_size2 = len(ds) - train_size2 
train2, test2 = ds[0:train_size2,:], ds[train_size2:len(ds), :]
85/8:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return np.array(data_x), np.array(data_y)
85/9:
look_back = 1 
train_x1, train_y1 = create_data_set(train1, look_back) 
test_x1, test_y1 = create_data_set(test1, look_back) 
train_x1 = np.reshape(train_x1,
                        (train_x1.shape[0], 1, train_x1.shape[1])) 
test_x1 = np.reshape(test_x1, 
                       (test_x1.shape[0], 1, test_x1.shape[1]))
85/10:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
86/1:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
86/2:
data_frame = pd.read_csv('lstm_data.csv')
data_set = data_frame.values
86/3: data_set
86/4: ds = data_set.astype('float32')
86/5: ds
86/6:
train_size1 = int(len(data_set) * 0.67) 
test_size1 = len(data_set) - train_size1 
train1, test1 = data_set[0:train_size1,:], data_set[train_size1:len(data_set), :]
86/7:
train_size2 = int(len(ds) * 0.67) 
test_size2 = len(ds) - train_size2 
train2, test2 = ds[0:train_size2,:], ds[train_size2:len(ds), :]
86/8:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return np.array(data_x), np.array(data_y)
86/9:
look_back = 1 
train_x1, train_y1 = create_data_set(train1, look_back) 
test_x1, test_y1 = create_data_set(test1, look_back) 
train_x1 = np.reshape(train_x1,
                        (train_x1.shape[0], 1, train_x1.shape[1])) 
test_x1 = np.reshape(test_x1, 
                       (test_x1.shape[0], 1, test_x1.shape[1]))
86/10:
train_x2, train_y2 = create_data_set(train2, look_back) 
test_x2, test_y2 = create_data_set(test2, look_back) 
train_x2 = np.reshape(train_x2,
                        (train_x2.shape[0], 1, train_x2.shape[1])) 
test_x2 = np.reshape(test_x2, 
                       (test_x2.shape[0], 1, test_x2.shape[1]))
86/11:
model1a = Sequential() 
model1a.add(LSTM(4, input_shape=(1, look_back))) 
model1a.add(Dense(1))
model1a.add(Activation('softmax'))
model1a.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1a.fit(train_x1, train_y1, epochs=10, batch_size=1, verbose=2, validation_data = (test_x1, test_y1))
86/12:
model1a = Sequential() 
model1a.add(LSTM(4, input_shape=(1, look_back))) 
model1a.add(Dense(1))
model1a.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1a.fit(train_x1, train_y1, epochs=10, batch_size=1, verbose=2, validation_data = (test_x1, test_y1))
87/1:
model1a = Sequential() 
model1a.add(LSTM(4, input_shape=(1, look_back))) 
model1a.add(Dense(1))
model1a.add(Activation('softmax'))
model1a.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1a.fit(train_x1, train_y1, epochs=10, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/1:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
88/2:
data_frame = pd.read_csv('lstm_data.csv')
data_set = data_frame.values
88/3: data_set
88/4: ds = data_set.astype('float32')
88/5: ds
88/6:
train_size1 = int(len(data_set) * 0.67) 
test_size1 = len(data_set) - train_size1 
train1, test1 = data_set[0:train_size1,:], data_set[train_size1:len(data_set), :]
88/7:
train_size2 = int(len(ds) * 0.67) 
test_size2 = len(ds) - train_size2 
train2, test2 = ds[0:train_size2,:], ds[train_size2:len(ds), :]
88/8:
def create_data_set(_data_set, _look_back=1): 
    data_x, data_y = [], [] 
    for i in range(len(_data_set) - _look_back - 1): 
        a = _data_set[i:(i + _look_back), 0] 
        data_x.append(a)
        data_y.append(_data_set[i + _look_back, 0]) 
    return np.array(data_x), np.array(data_y)
88/9:
look_back = 1 
train_x1, train_y1 = create_data_set(train1, look_back) 
test_x1, test_y1 = create_data_set(test1, look_back) 
train_x1 = np.reshape(train_x1,
                        (train_x1.shape[0], 1, train_x1.shape[1])) 
test_x1 = np.reshape(test_x1, 
                       (test_x1.shape[0], 1, test_x1.shape[1]))
88/10:
train_x2, train_y2 = create_data_set(train2, look_back) 
test_x2, test_y2 = create_data_set(test2, look_back) 
train_x2 = np.reshape(train_x2,
                        (train_x2.shape[0], 1, train_x2.shape[1])) 
test_x2 = np.reshape(test_x2, 
                       (test_x2.shape[0], 1, test_x2.shape[1]))
88/11:
model1a = Sequential() 
model1a.add(LSTM(4, input_shape=(1, look_back))) 
model1a.add(Dense(1))
model1a.add(Activation('softmax'))
model1a.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1a.fit(train_x1, train_y1, epochs=10, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/12:
model1a = Sequential() 
model1a.add(LSTM(4, input_shape=(1, look_back))) 
model1a.add(Dense(1))
model1a.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1a.fit(train_x1, train_y1, epochs=10, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/13:
model1b = Sequential() 
model1b.add(LSTM(4, input_shape=(1, look_back))) 
model1b.add(Dense(1)) 
model1b.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1b.fit(train_x2, train_y2, epochs=10, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/14:
model1b = Sequential() 
model1b.add(LSTM(4, input_shape=(1, look_back))) 
model1b.add(Dense(1)) 
model1b.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/15:
model2b = Sequential() 
model2b.add(LSTM(10, input_shape=(1, look_back))) 
model2b.add(Dense(1)) 
model2b.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model2b.fit(train_x2, train_y2, epochs=10, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/16:
model1b = Sequential() 
model1b.add(LSTM(4, input_shape=(1, look_back))) 
model1b.add(Dense(1)) 
model1b.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model1b.fit(train_x2, train_y2, epochs=10, batch_size=100, verbose=2, validation_data = (test_x2, test_y2))
88/17:
model2b = Sequential() 
model2b.add(LSTM(10, input_shape=(1, look_back))) 
model2b.add(Dense(1)) 
model2b.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model2b.fit(train_x2, train_y2, epochs=10, batch_size=100, verbose=2, validation_data = (test_x2, test_y2))
88/18:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(Dropout(0.2))
model3b.add(LSTM(10, return_sequences = True))
model3b.add(Dropout(0.2))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam') 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/19:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(LSTM(10, return_sequences = True))model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/20:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(LSTM(10, return_sequences = True))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/21:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(LSTM(5, return_sequences = True))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/22: from keras.layers import Dropout
88/23:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(Dropout(0.2))
model3b.add(LSTM(5, return_sequences = True))
model3b.add(Dropout(0.2))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/24:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(Dropout(0.2))
# model3b.add(LSTM(5, return_sequences = True))
# model3b.add(Dropout(0.2))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/25:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)))
model3b.add(Dropout(0.2))
model3b.add(LSTM(5, return_sequences = True))
model3b.add(Dropout(0.2))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/26:
model3b = Sequential() 
model3b.add(LSTM(10, input_shape=(1, look_back)), return_sequences = True)
model3b.add(Dropout(0.2))
model3b.add(LSTM(5, return_sequences = True))
model3b.add(Dropout(0.2))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
88/27:
model3b = Sequential() 
model3b.add(LSTM(100, input_shape=(1, look_back), return_sequences = True))
model3b.add(Dropout(0.2))
model3b.add(LSTM(5, return_sequences = True))
model3b.add(Dropout(0.2))
model3b.add(Dense(1)) 
model3b.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=['accuracy']) 
model3b.fit(train_x2, train_y2, epochs=100, batch_size=100, verbose=2, validation_data = (test_x1, test_y1))
89/1:
import matplotlib as plt
import numpy as np
import pandas as pd
import math
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM 
from keras.layers import Dropout
from sklearn.preprocessing import MinMaxScaler 
from sklearn.metrics import mean_squared_error
89/2: data_frame = pd.read_csv('lstm_data.csv')
89/3: data_frame.head()
89/4: data_frame.drop('Unnamed: 0', axis = 0)
89/5: data_frame.drop(['Unnamed: 0'], axis = 0)
89/6: data_frame.drop(['Unnamed: 0'], axis = 1)
89/7: df_processed = data_frame.iloc[:, 1:2].values
89/8: df_processed.head()
89/9: df_processed
89/10: df_processed[:5]
89/11: length(df_processed)
89/12: df_processed.length()
89/13: df_processed.size
89/14: data_frame.size()
89/15: data_frame.size
89/16: data_frame = pd.read_csv('lstm_data_binary.csv')
89/17: data_frame.head()
89/18: data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
89/19: data_frame.count()
89/20: data_frame.shape[0]
89/21: data_frame.shape[1]
89/22: scaler = MinMaxScaler(feature_range= (0,1))
89/23: data_frame_scaled = scaler.fit_transform(data_frame)
89/24: data_frame_scaled.head()
89/25: data_frame_scaled.iloc[:5]
89/26: data_frame_scaled.count()
89/27: data_frame_scaled.size
89/28: data_frame_scaled
89/29: data_frame1 = data_frame.drop(['index'], axis = 1)
89/30: data_frame1_scaled = scaler.fit_transform(data_frame1)
89/31: data_frame1_scaled
89/32: data_frame1_scaled.size
89/33:
features_set = []  
labels = []  
for i in range(57, 246639):  
    features_set.append(data_frame1_scaled[i-57:i, 0])
    labels.append(data_frame1_scaled[i, 0])
89/34: features_set, labels = np.array(features_set), np.array(labels)
89/35: features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))
89/36:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set.shape[1], 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/37: from sklearn.model_selection import train_test_split
89/38: row_count = data_frame1_scaled.shape[0]
89/39: row_count
89/40: split_point = int(row_count*2/3)
89/41: split_point
89/42: train_data, test_data = data_frame1_scaled[:split_point], data_frame1_scaled[split_point:]
89/43:
features_set_train = []  
labels_train = []  
for i in range(57, 164426):  
    features_set.append(train_data[i-57:i, 0])
    labels.append(train_data[i, 0])
89/44:
features_set_train = []  
labels_train = []  
for i in range(57, 164426):  
    features_set_train = append(train_data[i-57:i, 0])
    labels_train.append(train_data[i, 0])
89/45:
features_set_train = []  
labels_train = []  
for i in range(57, 164426):  
    features_set_train.append(train_data[i-57:i, 0])
    labels_train.append(train_data[i, 0])
89/46: features_set_train, labels_train = np.array(features_set), np.array(labels)
89/47: features_set_train = np.reshape(features_set_train, (features_set_train.shape[0], features_set_train.shape[1], 1))
89/48:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set.shape[1], 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/49:
model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')
model.fit(features_set_train, labels_train, epochs = 10, batch_size = 50)
89/50:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_train.shape[1], 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/51:
model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')
model.fit(features_set_train, labels_train, epochs = 10, batch_size = 100)
89/52: features_set_train, labels_train = np.array(features_set_train), np.array(labels_train)
89/53: features_set_train = np.reshape(features_set_train, (features_set_train.shape[0], features_set_train.shape[1], 1))
89/54:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_train.shape[1], 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/55:
model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')
model.fit(features_set_train, labels_train, epochs = 10, batch_size = 100)
89/56: train_data.size
89/57:
features_set_train = []  
labels_train = []  
for i in range(0, 164426, 57):  
    features_set_train.append(train_data[i-57:i, 0])
    labels_train.append(train_data[i, 0])
89/58: features_set_train.size
89/59: len(features_set_train)
89/60: len(labels_train)
89/61: features_set_train, labels_train = np.array(features_set_train), np.array(labels_train)
89/62: features_set_train.shape()
89/63: features_set_train.shape
89/64: features_set_train.shape[1]
89/65: features_set_train.shape[0]
89/66: features_set_train = np.reshape(features_set_train, (features_set_train.shape[0], 1, 1))
89/67: features_set_train.shape
89/68:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_train.shape[0], 1, 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/69:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_train.shape[0], 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/70:
model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')
model.fit(features_set_train, labels_train, epochs = 10)
89/71: features_set_train.shape[0]
89/72: model
89/73: model()
89/74:
model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')
model.fit(features_set_train, labels_train, epochs = 10, batch_size = 100)
89/75:
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_train.shape[1], 1))) 
model.add(Dropout(0.2)) 
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units = 1))
89/76:
model.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error')
model.fit(features_set_train, labels_train, epochs = 10, batch_size = 100)
92/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
%matplotlib inline
92/2: data_frame = pd.read_csv('lstm_data_binary.csv')
92/3:
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
92/4: row_count = data_frame1.shape[0]
92/5: split_point = int(row_count*2/3)
92/6: train_data, test_data = data_frame1[:split_point], data_frame1[split_point:]
92/7:
h1 = 32
output_dim = 1
num_layers = 2
learning_rate = 1e-3
num_epochs = 100
dtype = torch.float
92/8: lstm_input_size = 57
89/77: features_set_train
89/78: features_set_train[0]
89/79: features_set_train[1]
89/80: features_set_train[1][0]
89/81: features_set_train[1][0].shape
89/82: train_data
89/83: train_data.shape
89/84: train_data
89/85: train_data[0]
89/86: train_data
89/87: train_data[:,0]
89/88: train_data[:,0].shape
89/89: train_data[:,0].shape
89/90: tmp = np.array(train_data[:,0])
89/91: tmp
89/92: tmp.shape
89/93:
features_set_train = []  
labels_train = []  
for j in range(0, len(tmp), 57):  
    features_set_train.append([tmp[i] for i in range(j+57)])
    
    labels_train.append(tmp[j+57])
89/94:
features_set_train = []  
labels_train = []  
for j in range(0, len(tmp)-57, 57):  
    features_set_train.append([tmp[i] for i in range(j+57)])
    
    labels_train.append(tmp[j+57])
89/95: features_set_train = np.array(features_set_train)
89/96: features_set_train.shape
89/97: features_set_train
89/98: features_set_train
89/99: features_set_train[0]
89/100: features_set_train[0].shape
89/101:
features_set_train = []  
labels_train = []  
for j in range(0, len(tmp)-57, 57):  
    features_set_train.append(np.array([tmp[i] for i in range(j+57)]))
    
    labels_train.append(tmp[j+57])
89/102: features_set_train = np.array(features_set_train)
89/103: features_set_train[0]
89/104: features_set_train.shape
89/105: features_set_train[0].shape
89/106: features_set_train.shape
89/107: features_set_train = features_set_train.reshape(features_set_train.shape[0], features_set_train[0].shape[0])
89/108: labels_train
89/109: labels_train.shape
89/110:
for i in features_set_train:
    print(i.shape)
89/111:
features_set_train = []  
labels_train = []  
for j in range(0, len(tmp)-57, 57):  
    features_set_train.append(np.array([tmp[i] for i in range(j,j+57)]))
    
    labels_train.append(tmp[j+57])
89/112:
for i in features_set_train:
    print(i.shape)
89/113: features_set_train.shape
89/114: features_set_train = np.array(features_set_train)
89/115: features_set_train = features_set_train.reshape(features_set_train.shape[0], features_set_train[0].shape[0])
89/116: features_set_train.shape
89/117: len(labels_train)
92/9: tmp = np.array(train_data[:,0])
92/10: data_frame1_scaled = scaler.fit_transform(data_frame1)
92/11: from sklearn.preprocessing import MinMaxScaler
92/12: data_frame1_scaled = scaler.fit_transform(data_frame1)
92/13:
scaler = MinMaxScaler(feature_range= (0,1))
data_frame1_scaled = scaler.fit_transform(data_frame1)
92/14: train_data, test_data = data_frame1[:split_point], data_frame1[split_point:]
92/15: tmp = np.array(train_data[:,0])
92/16: train_data, test_data = data_frame1_scaled[:split_point], data_frame1_scaled[split_point:]
92/17: tmp = np.array(train_data[:,0])
92/18:
features_set_train = []  
labels_train = []  
for j in range(0, len(tmp)-57, 57):  
    features_set_train.append(np.array([tmp[i] for i in range(j,j+57)]))
    labels_train.append(tmp[j+57])
92/19: features_set_train = np.array(features_set_train)
92/20: features_set_train = features_set_train.reshape(features_set_train.shape[0], features_set_train[0].shape[0])
92/21: features_set_train.shape
92/22: labels_train.shape
92/23: labels_train = np.array(labels_train)
92/24: labels_train.shape
92/25: tmp = np.array(test_data[:,0])
92/26: tmp.shape
92/27: tmp1 = np.array(test_data[:,0])
92/28: tmp1.shape
92/29:
features_set_test = []  
labels_test = []  
for j in range(0, len(tmp1)-57, 57):  
    features_set_test.append(np.array([tmp1[i] for i in range(j,j+57)]))
    labels_test.append(tmp1[j+57])
92/30:
features_set_test = np.array(features_set_test)
labels_test = np.array(labels_test)
92/31: features_set_test.shape
92/32: labels_test.shape
92/33:
X_train = torch.from_numpy(features_set_train).type(torch.Tensor)
X_test = torch.from_numpy(features_set_test).type(torch.Tensor)
Y_train = torch.from_numpy(labels_train).type(torch.Tensor)
Y_test = torch.from_numpy(labels_test).type(torch.Tensor)
92/34:
class LSTM(nn.Module):

    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,
                    num_layers=2):
        super(LSTM, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.batch_size = batch_size
        self.num_layers = num_layers

        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)

        self.linear = nn.Linear(self.hidden_dim, output_dim)

    def init_hidden(self):
        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),
                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))

    def forward(self, input):
        # Forward pass through LSTM layer
        # shape of lstm_out: [input_size, batch_size, hidden_dim]
        # shape of self.hidden: (a, b), where a and b both 
        # have shape (num_layers, batch_size, hidden_dim).
        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))
        
        # Only take the output from the final timetep
        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction
        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))
        return y_pred.view(-1)
92/35:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
92/36:
lstm_input_size = 1
num_train = 64
92/37:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
92/38:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, Y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
93/1:
import torch
import torch.nn as nn
from generate_data import *
import matplotlib.pyplot as plt
93/2:
#####################
# Set parameters
#####################

# Data params
noise_var = 0
num_datapoints = 100
test_size = 0.2
num_train = int((1-test_size) * num_datapoints)

# Network params
input_size = 20
# If `per_element` is True, then LSTM reads in one timestep at a time.
per_element = True
if per_element:
    lstm_input_size = 1
else:
    lstm_input_size = input_size
# size of hidden layers
h1 = 32
output_dim = 1
num_layers = 2
learning_rate = 1e-3
num_epochs = 500
dtype = torch.float
93/3:
import torch
import torch.nn as nn
from generate_data import *
import matplotlib.pyplot as plt
93/4:
#####################
# Set parameters
#####################

# Data params
noise_var = 0
num_datapoints = 100
test_size = 0.2
num_train = int((1-test_size) * num_datapoints)

# Network params
input_size = 20
# If `per_element` is True, then LSTM reads in one timestep at a time.
per_element = True
if per_element:
    lstm_input_size = 1
else:
    lstm_input_size = input_size
# size of hidden layers
h1 = 32
output_dim = 1
num_layers = 2
learning_rate = 1e-3
num_epochs = 500
dtype = torch.float
93/5:
#####################
# Generate data
#####################
data = ARData(num_datapoints, num_prev=input_size, test_size=test_size, noise_var=noise_var, coeffs=fixed_ar_coefficients[input_size])

# make training and test sets in torch
X_train = torch.from_numpy(data.X_train).type(torch.Tensor)
X_test = torch.from_numpy(data.X_test).type(torch.Tensor)
y_train = torch.from_numpy(data.y_train).type(torch.Tensor).view(-1)
y_test = torch.from_numpy(data.y_test).type(torch.Tensor).view(-1)

X_train = X_train.view([input_size, -1, 1])
X_test = X_test.view([input_size, -1, 1])
93/6: X_train.shape
93/7: X_test.shape
93/8: y_train.shape
92/39: X_train.shape
92/40: Y_train.shape
92/41: X_train = X_train.view(57, 2884, 1)
92/42: X_test.shape
92/43: X_test = X_test.view(57, 1442, 1)
92/44: X_test.shape
92/45: Y_test.shape
92/46:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
92/47:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, Y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
92/48:
lstm_input_size = 57
num_train = 64
92/49:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
92/50:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, Y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
93/9:
#####################
# Build model
#####################

# Here we define our model as a class
class LSTM(nn.Module):

    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,
                    num_layers=2):
        super(LSTM, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.batch_size = batch_size
        self.num_layers = num_layers

        # Define the LSTM layer
        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)

        # Define the output layer
        self.linear = nn.Linear(self.hidden_dim, output_dim)

    def init_hidden(self):
        # This is what we'll initialise our hidden state as
        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),
                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))

    def forward(self, input):
        # Forward pass through LSTM layer
        # shape of lstm_out: [input_size, batch_size, hidden_dim]
        # shape of self.hidden: (a, b), where a and b both 
        # have shape (num_layers, batch_size, hidden_dim).
        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))
        
        # Only take the output from the final timetep
        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction
        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))
        return y_pred.view(-1)
93/10:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)

#####################
# Train model
#####################

hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()

#####################
# Plot preds and performance
#####################

plt.plot(y_pred.detach().numpy(), label="Preds")
plt.plot(y_train.detach().numpy(), label="Data")
plt.legend()
plt.show()

plt.plot(hist, label="Training loss")
plt.legend()
plt.show()
95/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
%matplotlib inline
95/2: data_frame = pd.read_csv('lstm_data_binary.csv')
95/3:
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
95/4: data_frame1.head()
95/5: data_frame1_values = data_frame1.values
95/6: data_frame1_values
95/7: data_frame1_values.dtype
95/8:
noise_var = 0

# Network params
input_size = 57
# If `per_element` is True, then LSTM reads in one timestep at a time.
per_element = False
if per_element:
    lstm_input_size = 1
else:
    lstm_input_size = input_size
# size of hidden layers
h1 = 32
output_dim = 1
num_layers = 2
learning_rate = 1e-3
num_epochs = 500
dtype = torch.float
95/9: row_count = data_frame1_values.shape[0]
95/10: row_count
95/11: split_point = int(row_count*2/3)
95/12: train_data, test_data = data_frame1_values[:split_point], data_frame1_values[split_point:]
95/13: tmp = np.array(train_data[:,0])
95/14: tmp.shape
95/15:
X_train = []  
y_train = []  
for j in range(0, len(tmp)-57, 57):  
    X_train.append(np.array([tmp[i] for i in range(j,j+57)]))
    y_train.append(tmp[j+57])
95/16:
X_train = np.array(X_train)
y_train = np.array(y_train)
95/17: X_train.shape
95/18: y_train.shape
95/19: tmp1 = np.array(test_data[:,0])
95/20:
X_test = []
y_test = []
for j in range(0, len(tmp1) - 57, 57):
    X_test.append(np.array([tmp1[i] for i in range(j, h + 57)]))
    y_test.append(tmp[j+57])
95/21:
X_test = []
y_test = []
for j in range(0, len(tmp1) - 57, 57):
    X_test.append(np.array([tmp1[i] for i in range(j, h + 57)]))
    y_test.append(tmp1[j+57])
95/22:
X_test = []
y_test = []
for j in range(0, len(tmp1) - 57, 57):
    X_test.append(np.array([tmp1[i] for i in range(j, j + 57)]))
    y_test.append(tmp1[j+57])
95/23: print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
95/24:
X_test = np.array(X_test)
y_test = np.array(y_test)
95/25: print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
95/26:
X_train = torch.from_numpy(X_train).type(torch.Tensor)
X_test = torch.from_numpy(X_test).type(torch.Tensor)
y_train = torch.from_numpy(y_train).type(torch.Tensor)
y_test = torch.from_numpy(y_test).type(torch.Tensor)
95/27: print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
93/11: print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
95/28:
X_train = X_train.view(57, 2884, 1)
X_test = X_test.view(57, 1442, 1)
95/29: print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
95/30:
class LSTM(nn.Module):

    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,
                    num_layers=2):
        super(LSTM, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.batch_size = batch_size
        self.num_layers = num_layers

        # Define the LSTM layer
        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)

        # Define the output layer
        self.linear = nn.Linear(self.hidden_dim, output_dim)

    def init_hidden(self):
        # This is what we'll initialise our hidden state as
        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),
                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))

    def forward(self, input):
        # Forward pass through LSTM layer
        # shape of lstm_out: [input_size, batch_size, hidden_dim]
        # shape of self.hidden: (a, b), where a and b both 
        # have shape (num_layers, batch_size, hidden_dim).
        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))
        
        # Only take the output from the final timetep
        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction
        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))
        return y_pred.view(-1)
93/12: num_train
95/31: num_train = 2884
95/32:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
95/33:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
95/34: lstm_input_size
93/13:
#####################
# Generate data
#####################
data = ARData(num_datapoints, num_prev=input_size, test_size=test_size, noise_var=noise_var, coeffs=fixed_ar_coefficients[input_size])

# make training and test sets in torch
X_train = torch.from_numpy(data.X_train).type(torch.Tensor)
X_test = torch.from_numpy(data.X_test).type(torch.Tensor)
y_train = torch.from_numpy(data.y_train).type(torch.Tensor).view(-1)
y_test = torch.from_numpy(data.y_test).type(torch.Tensor).view(-1)
93/14: print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
95/35:
# Network params
input_size = 57
# If `per_element` is True, then LSTM reads in one timestep at a time.
per_element = True
if per_element:
    lstm_input_size = 1
else:
    lstm_input_size = input_size
# size of hidden layers
h1 = 32
output_dim = 1
num_layers = 2
learning_rate = 1e-3
num_epochs = 500
dtype = torch.float
95/36:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
95/37:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
95/38:
plt.plot(y_pred.detach().numpy(), label="Preds")
plt.plot(y_train.detach().numpy(), label="Data")
plt.legend()
plt.show()

plt.plot(hist, label="Training loss")
plt.legend()
plt.show()
95/39:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.SmoothL1Loss()

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
95/40:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
95/41:
# Network params
input_size = 57
# If `per_element` is True, then LSTM reads in one timestep at a time.
per_element = True
if per_element:
    lstm_input_size = 1
else:
    lstm_input_size = input_size
# size of hidden layers
h1 = 32
output_dim = 1
num_layers = 2
learning_rate = 1e-2
num_epochs = 500
dtype = torch.float
95/42:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
95/43:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
95/44:
plt.plot(y_pred.detach().numpy(), label="Preds")
plt.plot(y_train.detach().numpy(), label="Data")
plt.legend()
plt.show()

plt.plot(hist, label="Training loss")
plt.legend()
plt.show()
95/45:
# Network params
input_size = 57
# If `per_element` is True, then LSTM reads in one timestep at a time.
per_element = True
if per_element:
    lstm_input_size = 1
else:
    lstm_input_size = input_size
# size of hidden layers
h1 = 50
output_dim = 1
num_layers = 3
learning_rate = 1e-2
num_epochs = 500
dtype = torch.float
95/46:
model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)

loss_fn = torch.nn.MSELoss(size_average=False)

optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)
95/47:
hist = np.zeros(num_epochs)

for t in range(num_epochs):
    # Initialise hidden state
    # Don't do this if you want your LSTM to be stateful
    model.hidden = model.init_hidden()
    
    # Forward pass
    y_pred = model(X_train)

    loss = loss_fn(y_pred, y_train)
    if t % 100 == 0:
        print("Epoch ", t, "MSE: ", loss.item())
    hist[t] = loss.item()

    # Zero out gradient, else they will accumulate between epochs
    optimiser.zero_grad()

    # Backward pass
    loss.backward()

    # Update parameters
    optimiser.step()
95/48:
plt.plot(y_pred.detach().numpy(), label="Preds")
plt.plot(y_train.detach().numpy(), label="Data")
plt.legend()
plt.show()

plt.plot(hist, label="Training loss")
plt.legend()
plt.show()
97/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
97/2: image_path = '../../2017-IWT4S-HDR_LP-dataset/crop_h1/I00000.png'
97/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb   
orig = cv2.imread(image_path)[..., ::-1]
#224*224
orig = cv2.resize(orig, (224, 224))
img = orig.copy().astype(np.float32)

#
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
img /= 255.0
img = (img - mean) / std

#pytorchCHW  
#[224,224,3]->[3,224,224]
img = img.transpose(2, 0, 1)

img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


# Initialize the network
#Alexnet
model = models.alexnet(pretrained=True).to(device).eval()

#print(model)

# 
for param in model.parameters():
    param.requires_grad = False

# advbox demo
m = PytorchModel(
    model, None,(-3, 3),
    channel_axis=1)
attack = FGSMT(m)

# epsilons
attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

inputs=img
labels = None

print(inputs.shape)

adversary = Adversary(inputs, labels)

tlabel = 538
adversary.set_target(is_targeted_attack=True, target_label=tlabel)


adversary = attack(adversary, **attack_config)


if adversary.is_successful():
    print(
        'attack success, adversarial_label=%d'
        % (adversary.adversarial_label))

    adv=adversary.adversarial_example[0]

else:
    print('attack failed')


print("fgsm attack done")
97/4:
adv = adv.transpose(1, 2, 0)
adv = (adv * std) + mean
adv = adv * 256.0
adv = np.clip(adv, 0, 255).astype(np.uint8)
97/5: show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
97/6:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
97/7: image_path = '../../2017-IWT4S-HDR_LP-dataset/crop_h1'
97/8:
def load_images_from_folder(image_path):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder,filename))
        if img is not None:
            images.append(img)
    return images
97/9: load_images_from_folder(image_path)
97/10:
def load_images_from_folder(image_path):
    images = []
    for filename in os.listdir(image_path):
        img = cv2.imread(os.path.join(image_path,filename))
        if img is not None:
            images.append(img)
    return images
97/11: load_images_from_folder(image_path)
97/12:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for filename in os.listdir(image_path):
        orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

# orig = cv2.imread(image_path)[..., ::-1]
#224*224
        orig = cv2.resize(orig, (224, 224))
        img = orig.copy().astype(np.float32)

        #
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        img /= 255.0
        img = (img - mean) / std

        #pytorchCHW  
        #[224,224,3]->[3,224,224]
        img = img.transpose(2, 0, 1)

        img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


        # Initialize the network
        #Alexnet
        model = models.alexnet(pretrained=True).to(device).eval()

        #print(model)

        # 
        for param in model.parameters():
            param.requires_grad = False

        # advbox demo
        m = PytorchModel(
            model, None,(-3, 3),
            channel_axis=1)
        attack = FGSMT(m)

        # epsilons
        attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

        inputs=img
        labels = None

        print(inputs.shape)

        adversary = Adversary(inputs, labels)

        tlabel = 538
        adversary.set_target(is_targeted_attack=True, target_label=tlabel)


        adversary = attack(adversary, **attack_config)


        if adversary.is_successful():
            print(
                'attack success, adversarial_label=%d'
                % (adversary.adversarial_label))

            adv=adversary.adversarial_example[0]

        else:
            print('attack failed')


        print("fgsm attack done")
97/13: perturb_images(image_path)
97/14:
adv = adv.transpose(1, 2, 0)
adv = (adv * std) + mean
adv = adv * 256.0
adv = np.clip(adv, 0, 255).astype(np.uint8)
97/15:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for filename in os.listdir(image_path):
        orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

# orig = cv2.imread(image_path)[..., ::-1]
#224*224
        orig = cv2.resize(orig, (224, 224))
        img = orig.copy().astype(np.float32)

        #
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        img /= 255.0
        img = (img - mean) / std

        #pytorchCHW  
        #[224,224,3]->[3,224,224]
        img = img.transpose(2, 0, 1)

        img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


        # Initialize the network
        #Alexnet
        model = models.alexnet(pretrained=True).to(device).eval()

        #print(model)

        # 
        for param in model.parameters():
            param.requires_grad = False

        # advbox demo
        m = PytorchModel(
            model, None,(-3, 3),
            channel_axis=1)
        attack = FGSMT(m)

        # epsilons
        attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

        inputs=img
        labels = None

        print(inputs.shape)

        adversary = Adversary(inputs, labels)

        tlabel = 538
        adversary.set_target(is_targeted_attack=True, target_label=tlabel)


        adversary = attack(adversary, **attack_config)


        if adversary.is_successful():
            print(
                'attack success, adversarial_label=%d'
                % (adversary.adversarial_label))

            adv=adversary.adversarial_example[0]

        else:
            print('attack failed')


        print("fgsm attack done")
        
        adv = adv.transpose(1, 2, 0)
        adv = (adv * std) + mean
        adv = adv * 256.0
        adv = np.clip(adv, 0, 255).astype(np.uint8)
        
        show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
97/16: perturb_images(image_path)
97/17: adv_image_path = '../../2017-IWT4S-HDR_LP-dataset Adv/crop_h1'
97/18:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for filename in os.listdir(image_path):
        orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

# orig = cv2.imread(image_path)[..., ::-1]
#224*224
        orig = cv2.resize(orig, (224, 224))
        img = orig.copy().astype(np.float32)

        #
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        img /= 255.0
        img = (img - mean) / std

        #pytorchCHW  
        #[224,224,3]->[3,224,224]
        img = img.transpose(2, 0, 1)

        img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


        # Initialize the network
        #Alexnet
        model = models.alexnet(pretrained=True).to(device).eval()

        #print(model)

        # 
        for param in model.parameters():
            param.requires_grad = False

        # advbox demo
        m = PytorchModel(
            model, None,(-3, 3),
            channel_axis=1)
        attack = FGSMT(m)

        # epsilons
        attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

        inputs=img
        labels = None

        print(inputs.shape)

        adversary = Adversary(inputs, labels)

        tlabel = 538
        adversary.set_target(is_targeted_attack=True, target_label=tlabel)


        adversary = attack(adversary, **attack_config)


        if adversary.is_successful():
            print(
                'attack success, adversarial_label=%d'
                % (adversary.adversarial_label))

            adv=adversary.adversarial_example[0]

        else:
            print('attack failed')


        print("fgsm attack done")
        
        adv = adv.transpose(1, 2, 0)
        adv = (adv * std) + mean
        adv = adv * 256.0
        adv = np.clip(adv, 0, 255).astype(np.uint8)
        
        show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
        
        cv2.imwrite(os.path.join(adv_image_path, adv))
97/19: perturb_images(image_path)
97/20:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for i in range(20):
        for filename in os.listdir(image_path):
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)

            cv2.imwrite(adv_image_path + i, adv)
            i = i + 1
97/21: perturb_images(image_path)
97/22:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for i in range(20):
        for filename in os.listdir(image_path):
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)

            cv2.imwrite(adv_image_path + 'i', adv)
            i = i + 1
97/23: perturb_images(image_path)
97/24:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for i in range(20):
        for filename in os.listdir(image_path):
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)

            cv2.imwrite(os.path.join(adv_image_path,'i'), adv)
            i = i + 1
97/25: perturb_images(image_path)
97/26:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for i in range(20):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname)
97/27: perturb_images(image_path)
97/28:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
    for i in range(20):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
97/29: perturb_images(image_path)
97/30:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
97/31: perturb_images(image_path)
98/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
98/2: image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
98/3: adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l01'
98/4:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
98/5: perturb_images(image_path)
98/6: perturb_images(image_path)
99/1:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l02/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l02'
106/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
106/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l02/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l02'
106/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
106/4: perturb_images(image_path)
107/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
107/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l03/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l03'
107/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
107/4: perturb_images(image_path)
108/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
108/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l04/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l04'
108/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
108/4: perturb_images(image_path)
109/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
109/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s02_l01/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s02_l01'
109/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
109/4: perturb_images(image_path)
110/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
110/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s02_l02/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s02_l02'
110/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
110/4: perturb_images(image_path)
111/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
111/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s03_l01/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s03_l01'
111/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
111/4: perturb_images(image_path)
112/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
112/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s03_l02/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s03_l02'
112/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
112/4: perturb_images(image_path)
113/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
113/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s04_l01/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s04_l01'
113/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
113/4: perturb_images(image_path)
114/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
114/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s04_l02/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s04_l02'
114/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

            show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
114/4: perturb_images(image_path)
123/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
123/2: image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
123/3: adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l01'
123/4:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
123/5: perturb_images(image_path)
124/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
124/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l02/'
adv_image_path = '../../../2017-IWT4S-CarsReId_LP-dataset Attacked/s01_l02'
124/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
124/4: perturb_images(image_path)
141/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
141/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
adv_image_path = '../../../DeepFool Attack/s01_l01'
141/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb   
            orig = cv2.imread(image_path)[..., ::-1]
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
141/4: perturb_images(image_path)
144/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
144/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
adv_image_path = '../../../DeepFool Attack/s01_l01'
144/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb  
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
144/4: perturb_images(image_path)
151/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
151/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
adv_image_path = '../../../DeepFool Attack/s01_l01'
151/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb  
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
151/4: perturb_images(image_path)
153/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
153/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l02/'
adv_image_path = '../../../DeepFool Attack/s01_l02'
153/3:
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb   
            
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
153/4: perturb_images(image_path)
155/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.saliency import JSMA
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
155/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
adv_image_path = '../../../JSMA Attack/s01_l01'
155/3:
# Define what device we are using
logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
#cv2bgr bgr -> rgb   
            
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #JSMA max_iter  theta max_perturbations_per_pixel
            attack = JSMA(m)
            attack_config = {
                    "max_iter": 2000,
                    "theta": 0.3,
                    "max_perturbations_per_pixel": 7,
                    "fast":True,
                    "two_pix":False
            }


            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("jsma attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
155/4: # show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
155/5: perturb_images(image_path)
159/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
%matplotlib inline
159/2: data_frame = pd.read_csv('lstm_data_binary.csv')
159/3:
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
159/4: data_frame1.head()
159/5: data_frame1.shape
159/6: data_frame1.head()
159/7:
for i in data_frame1["state"]:
    print (i)
159/8:
for i in data_frame1["state"]:
    print (len(i))
159/9:
for i in data_frame1["state"]:
    print (len(str(i)))
162/1: import pytorch
162/2: import torch
162/3: import torchvision
162/4: import sklearn
164/1:
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import gym
import time
161/1:
import torch
import torch.nn as nn
import torch.nn.functional as F
import gym
import numpy as np
165/1:
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import gym
import time
165/2:
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import gym
import time
165/3:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return res

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm
166/1:
import numpy as np
import torch

np.random.seed(2)

T = 20
L = 1000
N = 100

x = np.empty((N, L), 'int64')
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
data = np.sin(x / 1.0 / T).astype('float64')
torch.save(data, open('traindata.pt', 'wb'))
166/2:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
166/3:
import numpy as np
import torch
import torch.nn as nn

np.random.seed(2)

T = 20
L = 1000
N = 100

x = np.empty((N, L), 'int64')
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
data = np.sin(x / 1.0 / T).astype('float64')
torch.save(data, open('traindata.pt', 'wb'))
166/4:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
166/5:
from __future__ import print_function
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
166/6:
np.random.seed(2)

T = 20
L = 1000
N = 100

x = np.empty((N, L), 'int64')
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
data = np.sin(x / 1.0 / T).astype('float64')
166/7: data
166/8: data.shape
166/9: data
166/10: data
166/11: data.shape
166/12:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
166/13:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
166/14:
input = torch.from_numpy(data[3:, :-1])
target = torch.from_numpy(data[3:, 1:])
test_input = torch.from_numpy(data[:3, :-1])
test_target = torch.from_numpy(data[:3, 1:])
166/15: input.shape
166/16: target.shape
166/17: test_input.shape
166/18: test_target.shape
166/19: data
166/20:
# draw the result
plt.figure(figsize=(30,10))
plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
plt.xlabel('x', fontsize=20)
plt.ylabel('y', fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
def draw(yi, color):
    plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
draw(y[0], 'r')
draw(y[1], 'g')
draw(y[2], 'b')
plt.savefig('predict%d.pdf'%i)
plt.close()
166/21:
input = torch.from_numpy(data[3:, :-1])
target = torch.from_numpy(data[3:, 1:])
test_input = torch.from_numpy(data[:3, :-1])
test_target = torch.from_numpy(data[:3, 1:])
166/22:
# build the model
seq = Sequence()
seq.double()
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
166/23:
#begin to train
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
165/4:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import gym
import time
165/5: # HyperParameters
165/6:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return res

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/7:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print 'reward',R_human, R_energy
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        self.state = randomGenerateState(self.numD)
        # self.prev 
        
    def render(self) :
        pass
165/8:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        self.state = randomGenerateState(self.numD)
        # self.prev 
        
    def render(self) :
        pass
165/9:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/10:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/11:
# Run DQN

start = time.time()
dqn = DQN()
dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/12: env = iotenvBinary(10)
165/13:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import gym
import time
165/14:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return res

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/15:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        self.state = randomGenerateState(self.numD)
        # self.prev 
        
    def render(self) :
        pass
165/16: env = iotenvBinary(10)
165/17:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
env = gym.make('CartPole-v0')
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 3
N_STATES = 10
ENV_SHAPE = 0
165/18:
# Run DQN

start = time.time()
dqn = DQN()
dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/19:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/24:
# draw the result
plt.figure(figsize=(30,10))
plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
plt.xlabel('x', fontsize=20)
plt.ylabel('y', fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
def draw(yi, color):
    #plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
draw(y[0], 'r')
draw(y[1], 'g')
draw(y[2], 'b')
plt.savefig('predict%d.pdf'%i)
plt.close()
166/25: data.shape
166/26: data
166/27:
# draw the result
plt.figure(figsize=(30,10))
plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
plt.xlabel('x', fontsize=20)
plt.ylabel('y', fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
def draw(yi, color):
    #plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
draw(y[0], 'r')
draw(y[1], 'g')
draw(y[2], 'b')
plt.close()
166/28:
# draw the result
plt.figure(figsize=(30,10))
plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
plt.xlabel('x', fontsize=20)
plt.ylabel('y', fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
def draw(yi, color):
    #plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
draw(y[0], 'r')
draw(y[1], 'g')
draw(y[2], 'b')
plt.show()
166/29:
from __future__ import print_function
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
166/30:
# draw the result
plt.figure(figsize=(30,10))
plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
plt.xlabel('x', fontsize=20)
plt.ylabel('y', fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
def draw(yi, color):
    #plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
draw(y[0], 'r')
draw(y[1], 'g')
draw(y[2], 'b')
plt.show()
166/31:
# draw the result
plt.figure(figsize=(30,10))
plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
plt.xlabel('x', fontsize=20)
plt.ylabel('y', fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
def draw(yi, color):
    plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
draw(y[0], 'r')
draw(y[1], 'g')
draw(y[2], 'b')
plt.show()
166/32: y[0]
166/33: y[0].shape
166/34: np.arange(input.size(1)
166/35: np.arange(input.size(1))
166/36: y[1].shape
166/37: y[2].shape
166/38: test_input
166/39: data.shape
165/20:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/21:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/22:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
env = gym.make('CartPole-v0')
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 10
ENV_SHAPE = 0
165/23:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/40:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
166/41:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
166/42:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
165/24:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
env = gym.make('CartPole-v0')
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 50
ENV_SHAPE = 0
165/25:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/26:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
env = gym.make('CartPole-v0')
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 10
ENV_SHAPE = 0
165/27:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/43:
np.random.seed(2)

T = 20
L = 1000
N = 100
gpu = torch.cuda.is_available()
166/44: gpu
165/28:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
env = gym.make('CartPole-v0')
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/29:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/45:
x = np.empty((N, L), 'int64')
x
166/46:
x = np.empty((N, L), 'int64')
x.shape
166/47:
x = np.empty((N, L), 'int64')
x.shape
165/30: env = iotenvBinary(10)
165/31:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
env = gym.make('CartPole-v0')
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/32:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/33:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/34:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/48:
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
x.shape
166/49:
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
x
165/35:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/36:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/37: env = iotenvBinary(10)
165/38:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/39:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/40:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/41:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/50: data_frame1.shape
166/51: data_frame1.head()
166/52: y.shape
165/42: randomGenerateState(10)
165/43:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(S)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/44:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(S)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/45:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/46:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/47: env = iotenvBinary(10)
165/48:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/49:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/50:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/51:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/52:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return np.array(list(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/53: randomGenerateState(10)
165/54:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/55: env = iotenvBinary(10)
165/56:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/57:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/58:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/59:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/53:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        print (i)
        break
165/60:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return float(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/61: randomGenerateState(10)
165/62:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/63: env = iotenvBinary(10)
165/64:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/65:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/66:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/67:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/54: list("1010000001")
166/55:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(i)
        i = [int(i) for i in range(i)]
        break
165/68:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.as_tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/69: randomGenerateState(10)
166/56:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(i)
        i = [int(k) for k in range(i)]
        break
166/57:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(i)
        i = [int(k) for k in range(len(i))]
        break
165/70:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.as_tensor(np.array(list(res)))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/71: randomGenerateState(10)
166/58: list(1010000001)
166/59: list("1010000001")
166/60:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(k) for k in range(len(i))]
        break
166/61:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(k) for k in range(len(i))]
        print(i)
        break
165/72:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.as_tensor(float(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/73: randomGenerateState(10)
166/62:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        print(i)
        break
165/74:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/75: env = iotenvBinary(10)
165/76:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/77:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/78:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/79:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/63:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
166/64: device_states = []
166/65:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
166/66: device_states
166/67: len(device_states)
166/68: device_states = np.array(device_states)
166/69: device_states.shape
166/70: device_states = device_states.transpose()
166/71: device_states.shape
166/72:
np.random.seed(2)

L = 203875
N = 10
gpu = torch.cuda.is_available()
166/73:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
166/74:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
166/75:
np.random.seed(2)

L = 203875
N = 10
gpu = torch.cuda.is_available()
165/80:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(float(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/81: randomGenerateState(10)
166/76:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
166/77: input.shape
165/82:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
166/78: target.shape
165/83: env = iotenvBinary(10)
165/84:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
166/79: test_input
165/85:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/86:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/87:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/80: test_input.shape
166/81: test_target.shape
165/88:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 1)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/89:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/90:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/91:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/82:
# build the model
seq = Sequence()
seq.double()
if gpu:
    seq.cuda()
166/83:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
166/84:
train_loss = []
test_loss = []
165/92:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
#         x = torch.unsqueeze(torch.FloatTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/93:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/85:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        loss = criterion(out, target)
        tr_loss += loss.item()
        loss.backward()
        return loss
    optimizer.step(closure)
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
166/86:
if gpu:
    input.cuda()
    target.cuda()
    test_input.cuda()
    test_target.cuda()
166/87:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        loss = criterion(out, target)
        tr_loss += loss.item()
        loss.backward()
        return loss
    optimizer.step(closure)
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
165/94:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/95:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
166/88: optimizer.cuda()
166/89:
train_loss = []
test_loss = []
166/90:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        loss = criterion(out, target)
        tr_loss += loss.item()
        loss.backward()
        return loss
    optimizer.step(closure)
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
166/91:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    loss = criterion(out, target)
    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
166/92:
if gpu:
    input.cuda()
    target.cuda()
    test_input.cuda()
    test_target.cuda()
166/93:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    loss = criterion(out, target)
    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
166/94:
# build the model
seq = Sequence()
seq.double()
if gpu:
    seq.cuda()
166/95:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    loss = criterion(out, target)
    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
166/96:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
166/97:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
167/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
167/2:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
167/3: data_frame1.head()
167/4: list("1010000001")
167/5: device_states = []
167/6:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
167/7: device_states = np.array(device_states)
167/8: device_states = device_states.transpose()
167/9:
np.random.seed(2)

L = 203875
N = 10
gpu = torch.cuda.is_available()
167/10:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
167/11: data.shape
167/12: device_states.shape
167/13:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
167/14:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
167/15: input.shape
167/16: target.shape
167/17: test_input.shape
167/18: test_target.shape
167/19:
# build the model
seq = Sequence()
seq.double()
167/20:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
167/21:
train_loss = []
test_loss = []
167/22:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    loss = criterion(out, target)
    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
165/96:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(int(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/97: randomGenerateState(10)
165/98:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/99: env = iotenvBinary(10)
165/100:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/101:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        print(x.size(1), self.fc1.weight.size(1))
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/102:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/103:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
167/23:
# build the model
seq = Sequence()
seq.float()
167/24:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
167/25:
train_loss = []
test_loss = []
167/26:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    loss = criterion(out, target)
    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
167/27:
# build the model
seq = Sequence()
seq.float()
167/28:
# build the model
seq = Sequence()
seq.double()
167/29:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.double())
    loss = criterion(out, target)
    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
167/30:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.double())
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
165/104:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/105:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/106:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/107:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(long(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/108: randomGenerateState(10)
165/109: long("123")
165/110: int("123")
165/111:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(int(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/112: randomGenerateState(10)
165/113:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/114: env = iotenvBinary(10)
165/115:
# HyperParameters
BATCH_SIZE = 32
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/116:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/117:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/118:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/119:
# HyperParameters
BATCH_SIZE = 2
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/120:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/121:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/122:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/123:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(float(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/124: randomGenerateState(10)
165/125:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/126: env = iotenvBinary(10)
165/127:
# HyperParameters
BATCH_SIZE = 2
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/128:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/129:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/130:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/131:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(int(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
165/132: randomGenerateState(10)
165/133:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
165/134: env = iotenvBinary(10)
165/135:
# HyperParameters
BATCH_SIZE = 2
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
165/136:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
165/137:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/138:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/139:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.LongTensor(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/140:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/141: a = randomGenerateState(10)
165/142: a
165/143: torch.unsqueeze(torch.LongTensor(a), 0)
165/144: torch.unsqueeze(torch.LongTensor(a), 1)
165/145: torch.squeeze(torch.LongTensor(a), 1)
165/146:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(int(x), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/147:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/148:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(x, 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/149:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
165/150:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.tensor(int(x)), 0)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
165/151:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
168/1:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.LongTensor(x), 1)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
168/2:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import gym
import time
168/3:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(int(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
168/4: a = randomGenerateState(10)
168/5:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
168/6: env = iotenvBinary(10)
168/7:
# HyperParameters
BATCH_SIZE = 2
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
168/8:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
168/9:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.LongTensor(x), 1)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
168/10:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
174/1:
# for i in data_frame1["state"]:    
#     if len(str(i)) == 10:
175/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
175/2:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
176/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
177/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
177/2: !pip istall torch
177/3: !pip install torch
177/4:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
177/5: !pip install matplotlib
180/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
180/2: torch.cuda.is_available()
180/3:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
180/4: data_frame1.head()
180/5: list("1010000001")
180/6: device_states = []
180/7:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
180/8: device_states = np.array(device_states)
180/9: device_states = device_states.transpose()
180/10: device_states.shape
180/11:
np.random.seed(2)

L = 203875
N = 10
180/12:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
180/13:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
180/14:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
180/15: input.shape
180/16: target.shape
180/17: test_input.shape
180/18: test_target.shape
180/19:
# build the model
seq = Sequence()
seq.double()
180/20:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
180/21:
train_loss = []
test_loss = []
180/22:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.double())
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/23:
# build the model
seq = Sequence()
seq.double()
seq = seq.to("cuda")
180/24:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.001)
180/25:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/26:
train_loss = []
test_loss = []
180/27:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
180/28: input.shape
180/29:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/30:
train_loss = []
test_loss = []
180/31:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.double())
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/32:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/33:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.double())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/34:
# build the model
seq = Sequence()
seq.double()
seq = seq.to("cuda")
180/35:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/36:
train_loss = []
test_loss = []
180/37:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.double())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/38:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/39: type(input)
180/40: type(input)
180/41:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
180/42: type(input)
180/43: input
180/44:
input = input.to("cuda", dtype= torch.cuda.DoubleTensor)
target = target.to("cuda", dtype= torch.cuda.DoubleTensor)
test_input = test_input.to("cuda", dtype= torch.cuda.DoubleTensor)
test_target = test_target.to("cuda", dtype= torch.cuda.DoubleTensor)
180/45:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
180/46:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq(input.long())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/47:
# build the model
seq = Sequence()
seq = seq.to("cuda")
180/48:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/49:
train_loss = []
test_loss = []
180/50:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/51:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/52:
input = torch.tensor(input, dtype=torch.long, device="cuda")
target = torch.tensor(target, dtype=torch.long, device="cuda")
test_input = torch.tensor(test_input, dtype=torch.long, device="cuda")
test_target = torch.tensor(test_target, dtype=torch.long, device="cuda")
180/53: input
180/54:
# build the model
seq = Sequence()
seq = seq.to("cuda")
180/55:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/56:
train_loss = []
test_loss = []
180/57:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/58:
# build the model
seq = Sequence()
seq = seq.to("cuda")
seq = seq.double()
180/59:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/60:
train_loss = []
test_loss = []
180/61:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/62:
# build the model
seq = Sequence()
seq = seq.to("cuda")
seq = seq.long()
180/63:
# build the model
seq = Sequence()
seq = seq.double()
seq = seq.to("cuda")
180/64:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/65:
train_loss = []
test_loss = []
180/66:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/67:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.double())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/68:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.cuda.double())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/69:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.cuda())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/70:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
pytorch.set_default_tensor_type('torch.DoubleTensor')
180/71:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
%matplotlib inline
torch.set_default_tensor_type('torch.DoubleTensor')
180/72:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
torch.set_default_tensor_type('torch.DoubleTensor')
180/73:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
180/74: data_frame1.head()
180/75: device_states = []
180/76:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
180/77: device_states = np.array(device_states)
180/78: device_states = device_states.transpose()
180/79: device_states.shape
180/80:
np.random.seed(2)

L = 203875
N = 10
180/81:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
180/82:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
180/83:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
180/84:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
180/85:
# build the model
seq = Sequence()
seq = seq.double()
seq = seq.to("cuda")
180/86:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/87:
train_loss = []
test_loss = []
180/88:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.cuda())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/89:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
torch.set_default_tensor_type('torch.LongTensor')
180/90:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
torch.set_default_tensor_type('torch.DoubleTensor')
180/91:
# build the model
seq = Sequence()
seq = seq.to("cuda")
180/92:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/93:
train_loss = []
test_loss = []
180/94:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.cuda())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/95: input = input.type(dtype=torch.cuda.LongTensor)
180/96:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/97:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/98:
# build the model
seq = Sequence()
seq = seq.to("cuda")
180/99:
input = input.type(dtype=torch.cuda.LongTensor)
seq = seq.type(dst_type=torch.cuda.LongTensor)
180/100:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/101:
input = input.type(dtype=torch.cuda.FloatTensor)
seq = seq.type(dst_type=torch.cuda.FloatTensor)
180/102:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/103:
# build the model
seq = Sequence()
seq = seq.to("cuda")
180/104:
# build the model
seq = Sequence()
seq = seq.type(dst_type=torch.cuda.FloatTensor)
seq = seq.to("cuda")
180/105:
input = input.type(dtype=torch.cuda.FloatTensor)
input = input.cuda()
180/106:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/107:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.double())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/108:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
torch.set_default_tensor_type('torch.cuda.DoubleTensor')
180/109:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
180/110: data_frame1.head()
180/111: device_states = []
180/112:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
180/113: device_states = np.array(device_states)
180/114: device_states = device_states.transpose()
180/115: device_states.shape
180/116:
np.random.seed(2)

L = 203875
N = 10
180/117:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
180/118:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
180/119:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
180/120:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
180/121:
# build the model
seq = Sequence()
seq = seq.type(dst_type=torch.cuda.FloatTensor)
seq = seq.to("cuda")
180/122:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/123:
train_loss = []
test_loss = []
180/124:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.double())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/125:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/126:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    out = seq( input.long())
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
180/127:
# build the model
seq = Sequence()
seq = seq.to("cuda")
180/128:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
180/129:
train_loss = []
test_loss = []
180/130:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.double()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
181/2:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
181/3: data_frame1.head()
181/4: device_states = []
181/5:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
181/6: device_states = np.array(device_states)
181/7: device_states = device_states.transpose()
181/8: device_states.shape
181/9:
np.random.seed(2)

L = 203875
N = 10
181/10:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
181/11:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
181/12:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
181/13:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
181/14:
# build the model
seq = Sequence()
seq = seq.to("cuda")
181/15:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
181/16:
train_loss = []
test_loss = []
181/17:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.double()
    out = seq( input)
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/18:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    input = input.double()
    
    out = seq( input)
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/19:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    input = input.long()
    
    out = seq(input)
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/20:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.cuda.DoubleTensor)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.cuda.DoubleTensor)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.cuda.DoubleTensor)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.cuda.DoubleTensor)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
181/21:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
181/22:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
181/23:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
181/24:
# build the model
seq = Sequence()
seq  = seq.double()
seq = seq.to("cuda")
181/25:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
181/26:
train_loss = []
test_loss = []
181/27:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    input = input.long()
    
    out = seq(input)
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/28:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq(input)
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/29:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
181/30:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
181/31:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
181/32:
input = input.to("cuda")
target = target.to("cuda")
test_input = test_input.to("cuda")
test_target = test_target.to("cuda")
181/33:
# build the model
seq = Sequence()
seq  = seq.double()
seq = seq.to("cuda")
181/34:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
181/35:
train_loss = []
test_loss = []
181/36:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq(input)
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/37:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( long(input) )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/38:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input.type(dtype=torch.LongTensor) )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/39:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input.type(dtype=torch.cuda.LongTensor) )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
181/40:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
181/41:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
181/42: data_frame1.head()
181/43: device_states = []
181/44:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
182/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
182/2:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
182/3: data_frame1.head()
182/4: device_states = []
182/5:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
182/6: device_states = np.array(device_states)
182/7: device_states = device_states.transpose()
182/8: device_states.shape
182/9:
np.random.seed(2)

L = 203875
N = 10
182/10:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        
#         h_t = h_t.cuda()
#         c_t = c_t.cuda()
#         h_t2 = h_t2.cuda()
#         c_t2 = c_t2.cuda()

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
182/11:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
182/12:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
182/13:
# build the model
seq = Sequence()
seq  = seq.double()
# seq = seq.to("cuda")
182/14:
# build the model
seq = Sequence()
seq  = seq.double()
# seq = seq.to("cuda")
182/15:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
182/16:
train_loss = []
test_loss = []
182/17:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
182/18:
# build the model
seq = Sequence()
# seq = seq.to("cuda")
182/19:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
182/20:
train_loss = []
test_loss = []
182/21:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
182/22:
# build the model
seq = Sequence()
# seq = seq.to("cuda")
182/23:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
182/24:
train_loss = []
test_loss = []
182/25:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
182/26:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input.float() )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
182/27:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
182/28:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
182/29: data_frame1.head()
182/30: device_states = []
182/31:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
182/32: device_states = np.array(device_states)
182/33: device_states = device_states.transpose()
182/34: device_states.shape
182/35:
np.random.seed(2)

L = 203875
N = 10
182/36:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        
#         h_t = h_t.cuda()
#         c_t = c_t.cuda()
#         h_t2 = h_t2.cuda()
#         c_t2 = c_t2.cuda()

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
182/37:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
182/38:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
182/39:
# build the model
seq = Sequence()
seq.double()

# seq = seq.to("cuda")
182/40:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
182/41:
train_loss = []
test_loss = []
182/42:
#begin to train
for i in range(10):
    tr_loss = 0
    print('STEP: ', i)
    
    optimizer.zero_grad()
    #input = input.long()
    
    out = seq( input )
    
    print("here")
    
    loss = criterion(out, target.double())
    print('train loss:', loss.item())

    tr_loss += loss.item()
    loss.backward()
    
    optimizer.step()
    
    train_loss.append(tr_loss)
    
    # begin to predict, no need to track gradient here
    
    with torch.no_grad():
        te_loss = 0
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        test_loss.append(te_loss)
        y = pred.detach().numpy()
183/1:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
183/2:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
183/3:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
183/4: data_frame1.head()
183/5: device_states = []
183/6:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
183/7: device_states = np.array(device_states)
183/8: device_states = device_states.transpose()
183/9: device_states.shape
183/10:
np.random.seed(2)

L = 203875
N = 10
183/11:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
183/12:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
183/13:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
183/14:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
183/15:
# build the model
seq = Sequence()
seq.double()

# seq = seq.to("cuda")
183/16:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.Adam(seq.parameters(), lr=0.01)
183/17:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
183/18:
train_loss = []
test_loss = []
183/19:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    # draw the result
    plt.figure(figsize=(30,10))
    plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
    plt.xlabel('x', fontsize=20)
    plt.ylabel('y', fontsize=20)
    plt.xticks(fontsize=20)
    plt.yticks(fontsize=20)
    def draw(yi, color):
        plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
        plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
    draw(y[0], 'r')
    draw(y[1], 'g')
    draw(y[2], 'b')
    plt.savefig('predict%d.pdf'%i)
    plt.close()
183/20:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
183/21: input.type
183/22: input.type()
183/23:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input.double())
        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
183/24:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input.double())
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
184/2:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
184/3: data_frame1.head()
184/4: device_states = []
184/5:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
184/6: device_states = np.array(device_states)
184/7: device_states = device_states.transpose()
184/8: device_states.shape
184/9:
np.random.seed(2)

L = 203875
N = 10
184/10:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/11:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
184/12:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
184/13:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
184/14:
# build the model
seq = Sequence()
seq.double()

# seq = seq.to("cuda")
184/15:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/16: gpu
184/17:
if gpu:
    seq = seq.cuda()
    input = input.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/18:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input.double())
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/19:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double)

        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/20:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
184/21:
input = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
184/22:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
184/23:
# build the model
seq = Sequence()
seq.double()

# seq = seq.to("cuda")
184/24:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/25:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/26:
if gpu:
    seq = seq.cuda()
    input = input.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/27:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input.double())
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/28:
if gpu:
    seq = seq.cuda()
    input = input.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/29: type(input)
184/30: type(input.double())
184/31: torch.cuda.DoubleTensor()
184/32: torch.cuda.DoubleTensor(input)
184/33: type(input.type(dtype=torch.cuda.DoubleTensor))
184/34: input.type(dtype=torch.cuda.DoubleTensor)
184/35: input.type
184/36: input.type()
184/37:
# build the model
seq = Sequence()

# seq = seq.to("cuda")
184/38: seq.type
184/39: seq.type()
184/40: input = input.type(dtype=torch.cuda.FloatTensor)
184/41: input.type()
184/42:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input.double())
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/43:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/44:
if gpu:
    seq = seq.cuda()
    input = input.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/45: input.type()
184/46: input = input.type(dtype=torch.cuda.FloatTensor)
184/47: input.type()
184/48:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/49:
# build the model
seq = Sequence()
seq = seq.cuda()

# seq = seq.to("cuda")
184/50:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/51:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/52:
if gpu:
    input = input.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/53: input.type()
184/54: input = input.type(dtype=torch.cuda.FloatTensor)
184/55: input.type()
184/56:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/57:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        if gpu:
            input = input.to("cuda")
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/58:
for i in range(15):
    print('STEP: ', i)
    def closure():
        optimizer.zero_grad()
        if gpu:
            input = input.to("cuda")
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure)
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/59:
for i in range(15):
    print('STEP: ', i)
    def closure(input):
        optimizer.zero_grad()
        if gpu:
            input = input.to("cuda")
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure(input))
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/60: next(seq.parameters()).is_cuda
184/61:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/62: next(model.parameters()).is_cuda
184/63: next(seq.parameters()).is_cuda
184/64:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/65:
if gpu:
    input = input.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/66: input.is_cuda
184/67:
for i in range(15):
    print('STEP: ', i)
    def closure(input):
        optimizer.zero_grad()
        
        out = seq(input)
        
        print("here")
        
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    optimizer.step(closure(input))
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
184/68: seq(input)
184/69:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
184/70:
# build the model
seq = Sequence()
seq = seq.cuda()

# seq = seq.to("cuda")
184/71:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/72: next(seq.parameters()).is_cuda
184/73:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/74:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/75: input1.is_cuda
184/76: seq(input1)
184/77: input1 = input1.type(torch.cuda.LongTensor)
184/78: input1.type()
184/79: seq(input1)
184/80:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
184/81: input1.is_cuda
184/82: input1.type()
184/83:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/84: input1.type()
184/85: seq(input1)
184/86: input1
184/87: input1[0]
184/88: input1
184/89: input1[0].type()
184/90:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.double)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.double)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.double)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.double)

        
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            
            print(input_t.type())
            print(h_t.type())
            print(c_t.type())
            
            
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/91:
# build the model
seq = Sequence()
seq = seq.cuda()

# seq = seq.to("cuda")
184/92:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/93: next(seq.parameters()).is_cuda
184/94: seq(input1)
184/95:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.LongTensor)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.LongTensor)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.LongTensor)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.LongTensor)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            
            print(input_t.type())
            print(h_t.type())
            print(c_t.type())
            
            
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/96:
# build the model
seq = Sequence()
seq = seq.cuda()

# seq = seq.to("cuda")
184/97:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/98: next(seq.parameters()).is_cuda
184/99:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/100:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/101: seq(input1)
184/102:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.long)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.long)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.long)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.long)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            
            print(input_t.type())
            print(h_t.type())
            print(c_t.type())
            
            
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/103:
# build the model
seq = Sequence()
seq = seq.cuda()

# seq = seq.to("cuda")
184/104:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/105: next(seq.parameters()).is_cuda
184/106:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/107:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/108: seq(input1)
184/109: seq(input1)
184/110: next(seq.parameters())
184/111: next(seq.parameters()).type()
184/112:
# build the model
seq = Sequence()
seq = seq.long()
seq = seq.cuda()

# seq = seq.to("cuda")
184/113:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
184/114:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            
            print(input_t.type())
            print(h_t.type())
            print(c_t.type())
            
            
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/115:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
184/116:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
184/117:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
184/118:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
184/119:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/120: next(seq.parameters()).type()
184/121:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/122:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/123: seq(input1)
184/124:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            
            print(input_t.type())
            print(h_t.type())
            print(c_t.type())
            
            
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
184/125:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
184/126:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
184/127:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
184/128:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
184/129:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
184/130: next(seq.parameters()).type()
184/131:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
184/132:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
184/133: seq(input1)
184/134: input1 = input1.type(torch.cuda.FloatTensor)
184/135: seq(input1)
185/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
185/2:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
185/3: data_frame1.head()
185/4: device_states = []
185/5:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
185/6: device_states = np.array(device_states)
185/7: device_states = device_states.transpose()
185/8: device_states.shape
185/9:
np.random.seed(2)

L = 203875
N = 10
185/10:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
185/11:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
185/12:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
185/13:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
185/14:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
185/15:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
185/16:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
185/17: seq.state_dict
185/18: seq.state_dict()
185/19: test_input
185/20: test_input.shape
185/21: device_states = []
185/22:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
185/23: device_states = np.array(device_states)
185/24: device_states.shape
185/25:
np.random.seed(2)

L = 10
N = 203875
185/26:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
185/27:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
185/28:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])
185/29: input1.shape
185/30: target.shape
185/31: target.shape
185/32: test_input.shape
185/33: test_target.shape
185/34:
# input1 = torch.from_numpy(device_states[3:, :-1])
# target = torch.from_numpy(device_states[3:, 1:])
# test_input = torch.from_numpy(device_states[:3, :-1])
# test_target = torch.from_numpy(device_states[:3, 1:])

input1 = torch.from_numpy(device_states[142710:, :])
target = torch.from_numpy(device_states[142710:, :])
test_input = torch.from_numpy(device_states[:142710, :])
test_target = torch.from_numpy(device_states[:142710, :])
185/35: input1.shape
185/36: target.shape
185/37: test_input.shape
185/38: test_target.shape
185/39:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
185/40:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
185/41:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
185/42: next(seq.parameters()).type()
185/43:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
185/44:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
185/45: test_input.shape
185/46:
for i in range(15):
    print('STEP: ', i)
    
    def closure(input1):
        optimizer.zero_grad()
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
                
        loss = criterion(out, target.double())
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure(input1))
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/47:
for i in range(15):
    print('STEP: ', i)
    
    def closure(input1):
        optimizer.zero_grad()
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
                
        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure(input1))
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/48:
for i in range(15):
    print('STEP: ', i)
    
    def closure(input1):
        optimizer.zero_grad()
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure(input1))
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/49:
for i in range(15):
    print('STEP: ', i)
    
    def closure(input1,target):
        optimizer.zero_grad()
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure(input1, target))
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/50:
for i in range(15):
    print('STEP: ', i)
    
    def closure(input1,target):
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure(input1, target))
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/51:
for i in range(15):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target.double())
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/52:
for i in range(15):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/53:
for i in range(1):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = input1.type(torch.cuda.FloatTensor)
        pred = seq(test_input.double(), future=future)
        
        
        test_target = test_target.type(torch.cuda.FloatTensor)

        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/54:
for i in range(1):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = test_input.type(torch.cuda.FloatTensor)
        pred = seq(test_input, future=future)
        
        
        test_target = test_target.type(torch.cuda.FloatTensor)

        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
185/55:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
185/56: device_states = []
185/57:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
185/58: device_states = np.transpose(device_states)
185/59: device_states.shape
185/60:
np.random.seed(2)

L = 10
N = 203875
185/61:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
185/62:
np.random.seed(2)

L = 203875
N = 10
185/63:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
185/64:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
185/65:
# input1 = torch.from_numpy(device_states[3:, :-1])
# target = torch.from_numpy(device_states[3:, 1:])
# test_input = torch.from_numpy(device_states[:3, :-1])
# test_target = torch.from_numpy(device_states[:3, 1:])

input1 = torch.from_numpy(device_states[142710:, :])
target = torch.from_numpy(device_states[142710:, :])
test_input = torch.from_numpy(device_states[:142710, :])
test_target = torch.from_numpy(device_states[:142710, :])
185/66:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
185/67: input1.shape
185/68: target.shape
185/69: test_input.shape
185/70: test_target.shape
185/71:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
185/72:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
185/73: next(seq.parameters()).type()
185/74:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
185/75:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
185/76: test_input.shape
185/77:
for i in range(1):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = test_input.type(torch.cuda.FloatTensor)
        pred = seq(test_input, future=future)
        
        
        test_target = test_target.type(torch.cuda.FloatTensor)

        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
188/1:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
188/2:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
188/3: data_frame1.head()
188/4: device_states = []
188/5:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
188/6: device_states = np.array(device_states)
188/7: device_states = np.transpose(device_states)
188/8: device_states.shape
188/9:
np.random.seed(2)

L = 203875
N = 10
188/10:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
188/11:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
188/12:
input1 = torch.from_numpy(device_states[3:, :-1])
target = torch.from_numpy(device_states[3:, 1:])
test_input = torch.from_numpy(device_states[:3, :-1])
test_target = torch.from_numpy(device_states[:3, 1:])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/13: input1.shape
188/14: target.shape
188/15: test_input.shape
188/16: test_target.shape
188/17:
# input = input.to("cuda")
# target = target.to("cuda")
# test_input = test_input.to("cuda")
# test_target = test_target.to("cuda")
188/18:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
188/19:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
188/20: next(seq.parameters()).type()
188/21:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
188/22:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
188/23: test_input.shape
188/24:
for i in range(1):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = test_input.type(torch.cuda.FloatTensor)
        pred = seq(test_input, future=future)
        
        
        test_target = test_target.type(torch.cuda.FloatTensor)

        loss = criterion(pred[:, :-future], test_target)
        print('test loss:', loss.item())
        y = pred.detach().numpy()
    
    torch.save(seq.state_dict(), "checkpoint_epoch_{}".format(i))
188/25: y
188/26: pred
188/27: pred.shape
188/28: z = [[2,3], [4,5]]
188/29: z[:]
188/30: z[:][0]
188/31: z[0,:]
188/32: z[:][:0]
188/33: z[][:0]
188/34: z[:0]
188/35: z[:,0]
188/36: z = np.array([[2,3], [4,5]])
188/37: z[:,0]
188/38:
from __future__ import print_function
import torch
import pandas as pd
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline
#torch.set_default_tensor_type('torch.cuda.DoubleTensor')
188/39:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
188/40: data_frame1.head()
188/41: z = np.array([[2,3], [4,5]])
188/42: z[:,0]
188/43: device_states = []
188/44:
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
188/45: device_states = np.array(device_states)
188/46: device_states = np.transpose(device_states)
188/47: device_states.shape
188/48:
np.random.seed(2)

L = 10
N = 203875
188/49:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
188/50:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
188/51:
input1 = torch.from_numpy(device_states[67958:, :-1])
target = torch.from_numpy(device_states[67958:, 1:])
test_input = torch.from_numpy(device_states[:67958, :-1])
test_target = torch.from_numpy(device_states[:67958, 1:])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/52: input1.shape
188/53: target.shape
188/54: test_input.shape
188/55: test_target.shape
189/1:
import numpy as np
import pandas as pd
import os
import time
import gc
import random
from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import torch
from torch import nn
from torch.utils import data
from torch.nn import functional as F
189/2:
import numpy as np
import pandas as pd
import os
import time
import gc
import random
import torch
from torch import nn
from torch.utils import data
from torch.nn import functional as F
189/3:
def seed_everything(seed=1234):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
seed_everything()
189/4:
class LSTM_net(nn.Module):
    
    def __init__(self, ip, n_hidden=256, n_layers=2, drop_prob=0.5, lr=0.001):
        super().__init__()
        self.drop_prob = drop_prob
        self.n_layers = n_layers
        self.n_hidden = n_hidden
        self.lr = lr
        
        
        
        ## TODO: define the LSTM
        self.lstm = nn.LSTM(1, n_hidden, n_layers, 
                            dropout=drop_prob, batch_first=True)
        
        ## TODO: define a dropout layer
        self.dropout = nn.Dropout(drop_prob)
        
        ## TODO: define the final, fully-connected output layer
        self.fc = nn.Linear(n_hidden, 1)
      
    
    def forward(self, x, hidden):
        ''' Forward pass through the network. 
            These inputs are x, and the hidden/cell state `hidden`. '''
                
        ## TODO: Get the outputs and the new hidden state from the lstm
        r_output, hidden = self.lstm(x, hidden)
        
        ## TODO: pass through a dropout layer
        out = self.dropout(r_output)
        
        # Stack up LSTM outputs using view
        # you may need to use contiguous to reshape the output
        out = out.contiguous().view(-1, self.n_hidden)
        
        ## TODO: put x through the fully-connected layer
        out = self.fc(out)
        
        # return the final output and the hidden state
        return out, hidden
    
    
    def init_hidden(self, batch_size):
        ''' Initializes hidden state '''
        # Create two new tensors with sizes n_layers x batch_size x n_hidden,
        # initialized to zero, for hidden state and cell state of LSTM
        weight = next(self.parameters()).data
        
        if (train_on_gpu):
            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),
                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())
        else:
            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),
                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())
        
        return hidden
189/5:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
189/6: data_frame1.head()
189/7:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
189/8:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
device_states = np.transpose(device_states)
189/9: device_states.shape
189/10: device_states[0]
189/11:
class LSTMClassifier(nn.Module):

    def __init__(self, in_dim, hidden_dim, num_layers, dropout, bidirectional, num_classes, batch_size):
        super(LSTMClassifier, self).__init__()
        self.in_dim = in_dim
        self.hidden_dim = hidden_dim
        self.batch_size = batch_size
        self.bidirectional = bidirectional
        self.num_dir = 2 if bidirectional else 1
        self.num_layers = num_layers
        self.dropout = dropout

        self.lstm = nn.LSTM(input_size=self.in_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, dropout=self.dropout/2, bidirectional=self.bidirectional,
                            batch_first=True)
        self.gru = nn.GRU(self.hidden_dim * 2, self.hidden_dim, bidirectional=self.bidirectional, batch_first=True)


        self.fc = nn.Sequential(
            nn.Linear(4096, int(hidden_dim)),
            nn.SELU(True),
            nn.Dropout(p=dropout),
            nn.Linear(int(hidden_dim), num_classes),
        )

    def forward(self, x):

        x = x.permute(2, 0, 1)
        lstm_out, _ = self.lstm(x)
        gru_out, _ = self.gru(lstm_out)
        avg_pool_l = torch.mean(lstm_out.permute(1, 0, 2), 1)
        max_pool_l, _ = torch.max(lstm_out.permute(1, 0, 2), 1)
        
        avg_pool_g = torch.mean(gru_out.permute(1, 0, 2), 1)
        max_pool_g, _ = torch.max(gru_out.permute(1, 0, 2), 1)

        x = torch.cat((avg_pool_g, max_pool_g, avg_pool_l, max_pool_l), 1)
        y = self.fc(x)
        
        return y
188/56:
np.random.seed(2)

T = 20
L = 1000
N = 100
188/57:
x = np.empty((N, L), 'int64')
x.shape
188/58:
x = np.empty((N, L), 'int64')
x
188/59:
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
x.shape
188/60:
x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)
x
188/61: input1 = torch.from_numpy(data[3:, :-1])
188/62: input1 = torch.from_numpy(x[3:, :-1])
188/63:
input1 = torch.from_numpy(x[3:, :-1])
input1.shape
188/64: target = torch.from_numpy(data[3:, 1:])
188/65: target = torch.from_numpy(x[3:, 1:])
188/66:
target = torch.from_numpy(x[3:, 1:])
target.shape
188/67:
test_input = torch.from_numpy(x[:3, :-1])
test_input
188/68:
test_input = torch.from_numpy(x[:3, :-1])
test_input.shape
188/69: test_target = torch.from_numpy(x[:3, 1:])
188/70: test_target.shape
188/71: z = np.array([1,2,3,4,6,7])
188/72: z[:3, :-1]
188/73: z = np.array([[1,2,3],[4,6,7]])
188/74: z[:3, :-1]
188/75: z[:3, 1:]
188/76:
input1 = torch.from_numpy(device_states[67958:, :-1])
target = torch.from_numpy(device_states[67958:, 1:])
test_input = torch.from_numpy(device_states[:67958, :-1])
test_target = torch.from_numpy(device_states[:67958, 1:])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/77: input1.shape
188/78: device_states.shape
188/79: device_states = np.transpose(device_states)
188/80: device_states.shape
188/81:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
188/82:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
188/83:
input1 = torch.from_numpy(x[3:, :-1])
input1.shape
188/84:
input1 = torch.from_numpy(device_states[67958:, :-1])
target = torch.from_numpy(device_states[67958:, 1:])
test_input = torch.from_numpy(device_states[:67958, :-1])
test_target = torch.from_numpy(device_states[:67958, 1:])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/85: input1.shape
188/86: input1.shape
188/87: target.shape
188/88: test_input.shape
188/89: test_target.shape
188/90:
input1 = torch.from_numpy(device_states[67958:, :])
target = torch.from_numpy(device_states[67958:, :])
test_input = torch.from_numpy(device_states[:67958, :])
test_target = torch.from_numpy(device_states[:67958, :])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/91: input1.shape
188/92: target.shape
188/93: test_input.shape
188/94: test_target.shape
188/95:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
188/96:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
188/97:
# build the model
seq = Sequence()
seq = seq.float()
seq = seq.cuda()

# seq = seq.to("cuda")
188/98:
criterion = nn.MSELoss()
# use LBFGS as optimizer since we can load the whole data to train
optimizer = optim.LBFGS(seq.parameters(), lr=0.8)
188/99: next(seq.parameters()).type()
188/100:
train_loss = []
test_loss = []
gpu = torch.cuda.is_available()
188/101:
if gpu:
    input1 = input1.to("cuda")
    target = target.to("cuda")
    test_input = test_input.to("cuda")
    test_target = test_target.to("cuda")
188/102: test_input.shape
188/103:
for i in range(1):
    print('STEP: ', i)
    
    def closure():
        optimizer.zero_grad()
        global input1
        input1 = input1.type(torch.cuda.FloatTensor)
        out = seq(input1)
        
        global target
        target = target.type(torch.cuda.FloatTensor)

        loss = criterion(out, target)
        train_loss.append(loss.item())
        print('loss:', loss.item())
        loss.backward()
        return loss
    
    optimizer.step(closure)
    
    torch.save(seq.state_dict(), "./checkpoints/checkpoint_epoch_{}".format(i))
    # begin to predict, no need to track gradient here
    with torch.no_grad():
        future = 1000
        test_input = test_input.type(torch.cuda.FloatTensor)
        pred = seq(test_input, future=future)
        
        
        test_target = test_target.type(torch.cuda.FloatTensor)

        loss = criterion(pred[:, :-future], test_target)
        test_loss.append(loss.item())
        print('test loss:', loss.item())
        y = y.cpu()
        y = pred.detach().numpy()
188/104: pred.shape
188/105: pred
188/106: device_states = np.transpose(device_states)
188/107: device_states.shape
188/108:
class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 51)
        self.lstm2 = nn.LSTMCell(51, 51)
        self.linear = nn.Linear(51, 1)

    def forward(self, input1, future = 0):
        outputs = []
        h_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t = torch.zeros(input1.size(0), 51, dtype=torch.float)
        h_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)
        c_t2 = torch.zeros(input1.size(0), 51, dtype=torch.float)

        
        h_t = h_t.cuda()
        c_t = c_t.cuda()
        h_t2 = h_t2.cuda()
        c_t2 = c_t2.cuda()
        
        for i, input_t in enumerate(input1.chunk(input1.size(1), dim=1)):
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
            
        for i in range(future):# if we should predict the future
            h_t, c_t = self.lstm1(output, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.stack(outputs, 1).squeeze(2)
        return outputs
188/109:
# set random seed to 0
np.random.seed(0)
torch.manual_seed(0)
# load data and make training set
188/110:
input1 = torch.from_numpy(device_states[67958:, :])
target = torch.from_numpy(device_states[67958:, :])
test_input = torch.from_numpy(device_states[:67958, :])
test_target = torch.from_numpy(device_states[:67958, :])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/111: input1.shape
188/112: target.shape
188/113: test_input.shape
188/114: test_target.shape
188/115:
input1 = torch.from_numpy(device_states[:, 67958:])
target = torch.from_numpy(device_states[:, 67958:])
test_input = torch.from_numpy(device_states[:67958, :])
test_target = torch.from_numpy(device_states[:67958, :])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/116: input1.shape
188/117: target.shape
188/118: test_input.shape
188/119: test_target.shape
188/120:
input1 = torch.from_numpy(device_states[:, 67958:])
target = torch.from_numpy(device_states[:, 67958:])
test_input = torch.from_numpy(device_states[:, :67958])
test_target = torch.from_numpy(device_states[:, :67958])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/121: input1.shape
188/122: target.shape
188/123: test_input.shape
188/124: test_target.shape
188/125: input1
188/126: target
188/127:
input1 = torch.from_numpy(device_states[:, 67958:-1])
target = torch.from_numpy(device_states[:, 67958:])
test_input = torch.from_numpy(device_states[:, :67958])
test_target = torch.from_numpy(device_states[:, :67958])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
188/128: input1
188/129: target
188/130:
input1 = torch.from_numpy(device_states[:, 67958:, -1])
target = torch.from_numpy(device_states[:, 67958:])
test_input = torch.from_numpy(device_states[:, :67958])
test_target = torch.from_numpy(device_states[:, :67958])

# input1 = torch.from_numpy(device_states[142710:, :])
# target = torch.from_numpy(device_states[142710:, :])
# test_input = torch.from_numpy(device_states[:142710, :])
# test_target = torch.from_numpy(device_states[:142710, :])
189/12:
import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
191/1:
import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
191/2:
plt.figure(figsize=(8,5))

# how many time steps/data pts are in one batch of data
seq_length = 20

# generate evenly spaced data pts
time_steps = np.linspace(0, np.pi, seq_length + 1)
data = np.sin(time_steps)
data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension

x = data[:-1] # all but the last piece of data
y = data[1:] # all but the first

# display the data
plt.plot(time_steps[1:], x, 'r.', label='input, x') # x
plt.plot(time_steps[1:], y, 'b.', label='target, y') # y

plt.legend(loc='best')
plt.show()
191/3:
data_framea = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
191/4:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
191/5:
plt.figure(figsize=(8,5))

# how many time steps/data pts are in one batch of data
seq_length = 20

# generate evenly spaced data pts
time_steps = np.linspace(0, np.pi, seq_length + 1)
data = np.sin(time_steps)
data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension

x = data[:-1] # all but the last piece of data
y = data[1:] # all but the first

# display the data
plt.plot(time_steps[1:], x, 'r.', label='input, x') # x
plt.plot(time_steps[1:], y, 'b.', label='target, y') # y

plt.legend(loc='best')
plt.show()
191/6:
data_framea = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
191/7:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
191/8: data_frame1.head()
191/9:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
device_states = np.transpose(device_states)
191/10: device_states.shape
191/11: x.shape
191/12: x
191/13: x.shape
191/14:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
191/15: device_states.shape
191/16: device_states[0].shape
191/17: device_states.shape
191/18:
class LSTMClassifier(nn.Module):

    def __init__(self, in_dim, hidden_dim, num_layers, dropout, bidirectional, num_classes, batch_size):
        super(LSTMClassifier, self).__init__()
        self.in_dim = in_dim
        self.hidden_dim = hidden_dim
        self.batch_size = batch_size
        self.bidirectional = bidirectional
        self.num_dir = 2 if bidirectional else 1
        self.num_layers = num_layers
        self.dropout = dropout

        self.lstm = nn.LSTM(input_size=self.in_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, dropout=self.dropout/2, bidirectional=self.bidirectional,
                            batch_first=True)
        self.gru = nn.GRU(self.hidden_dim * 2, self.hidden_dim, bidirectional=self.bidirectional, batch_first=True)


        self.fc = nn.Sequential(
            nn.Linear(4096, int(hidden_dim)),
            nn.SELU(True),
            nn.Dropout(p=dropout),
            nn.Linear(int(hidden_dim), num_classes),
        )

    def forward(self, x):

        x = x.permute(2, 0, 1)
        lstm_out, _ = self.lstm(x)
        gru_out, _ = self.gru(lstm_out)
        avg_pool_l = torch.mean(lstm_out.permute(1, 0, 2), 1)
        max_pool_l, _ = torch.max(lstm_out.permute(1, 0, 2), 1)
        
        avg_pool_g = torch.mean(gru_out.permute(1, 0, 2), 1)
        max_pool_g, _ = torch.max(gru_out.permute(1, 0, 2), 1)

        x = torch.cat((avg_pool_g, max_pool_g, avg_pool_l, max_pool_l), 1)
        y = self.fc(x)
        
        return y
191/19:
class RNN(nn.Module):
    def __init__(self, input_size, output_size, hidden_dim, n_layers):
        super(RNN, self).__init__()
        
        self.hidden_dim=hidden_dim

        # define an RNN with specified parameters
        # batch_first means that the first dim of the input and output will be the batch_size
        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)
        
        # last, fully-connected layer
        self.fc = nn.Linear(hidden_dim, output_size)

    def forward(self, x, hidden):
        # x (batch_size, seq_length, input_size)
        # hidden (n_layers, batch_size, hidden_dim)
        # r_out (batch_size, time_step, hidden_size)
        batch_size = x.size(0)
        
        # get RNN outputs
        r_out, hidden = self.rnn(x, hidden)
        # shape output to be (batch_size*seq_length, hidden_dim)
        r_out = r_out.view(-1, self.hidden_dim)  
        
        # get final output 
        output = self.fc(r_out)
        
        return output, hidden
191/20:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
test_rnn.cuda()
191/21:
# generate evenly spaced, test data pts
time_steps = np.linspace(0, np.pi, seq_length)
data = np.sin(time_steps)
data.resize((seq_length, 1))

test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension
print('Input size: ', test_input.size())

# test out rnn sizes
test_out, test_h = test_rnn(test_input, None)
print('Output size: ', test_out.size())
print('Hidden state size: ', test_h.size())
191/22:
# generate evenly spaced, test data pts
device_states.shape
191/23:
test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension
print('Input size: ', test_input.size())
191/24:
test_input = torch.Tensor(device_states).unsqueeze(0) # give it a batch_size of 1 as first dimension
print('Input size: ', test_input.size())
191/25:
# test out rnn sizes
test_out, test_h = test_rnn(test_input, None)
print('Output size: ', test_out.size())
print('Hidden state size: ', test_h.size())
191/26:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
191/27:
# test out rnn sizes
test_out, test_h = test_rnn(test_input, None)
print('Output size: ', test_out.size())
print('Hidden state size: ', test_h.size())
191/28:

# decide on hyperparameters
input_size=10 
output_size=10
hidden_dim=32
n_layers=1

# instantiate an RNN
rnn = RNN(input_size, output_size, hidden_dim, n_layers)
print(rnn)
191/29:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
191/30:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
%matplotlib inline
191/31:
inp = device_states[:-1]
tar = device_states[1:]
191/32:
# Creating data indices for training and validation splits:
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
191/33:
# Creating data indices for training and validation splits:
validation_split = 0.3
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
191/34:
# Creating data indices for training and validation splits:
validation_split = 0.3
batch_size = 100
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
191/35:
class RNN(nn.Module):
    def __init__(self, input_size, output_size, hidden_dim, n_layers):
        super(RNN, self).__init__()
        
        self.hidden_dim=hidden_dim

        # define an RNN with specified parameters
        # batch_first means that the first dim of the input and output will be the batch_size
        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)
        
        # last, fully-connected layer
        self.fc = nn.Linear(hidden_dim, output_size)

    def forward(self, x, hidden):
        # x (batch_size, seq_length, input_size)
        # hidden (n_layers, batch_size, hidden_dim)
        # r_out (batch_size, time_step, hidden_size)
        batch_size = x.size(0)
        
        # get RNN outputs
        r_out, hidden = self.rnn(x, hidden)
        # shape output to be (batch_size*seq_length, hidden_dim)
        r_out = r_out.view(-1, self.hidden_dim)  
        
        # get final output 
        output = self.fc(r_out)
        
        return output, hidden
191/36:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
191/37:
# generate evenly spaced, test data pts
device_states.shape
191/38: device_states.shape
191/39: next(iter(train_loader))
191/40: next(iter(train_loader)).shape
191/41:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    for data in train_loader:
        # defining the training data 

        x = data[:-1]
        y = data[1:]
        
        # convert data into Tensors
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
            plt.plot(time_steps[1:], x, 'r.') # input
            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions
            plt.show()
    
    return rnn
191/42:
n_steps = 75
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/43:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    for data in train_loader:
        # defining the training data 

        x = data[:-1]
        y = data[1:]
        
        # convert data into Tensors
        
        x_tensor = x_tensor.type("torch.FloatTensor")
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
            plt.plot(time_steps[1:], x, 'r.') # input
            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions
            plt.show()
    
    return rnn
191/44:
n_steps = 75
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/45:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    for data in train_loader:
        # defining the training data 

        x = data[:-1]
        y = data[1:]
        
        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        x_tensor = x_tensor.type("torch.FloatTensor")

        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
            plt.plot(time_steps[1:], x, 'r.') # input
            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions
            plt.show()
    
    return rnn
191/46:
n_steps = 75
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/47:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    for data in train_loader:
        # defining the training data 

        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
            plt.plot(time_steps[1:], x, 'r.') # input
            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions
            plt.show()
    
    return rnn
191/48:
n_steps = 75
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/49:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    batch_i = 0
    for data in train_loader:
        # defining the training data 
        batch_i += 1
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
            plt.plot(time_steps[1:], x, 'r.') # input
            plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions
            plt.show()
    
    return rnn
191/50:
n_steps = 75
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/51:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    batch_i = 0
    for data in train_loader:
        # defining the training data 
        batch_i += 1
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
    
    return rnn
191/52:
n_steps = 75
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/53:
n_steps = 1
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
191/54: trained_rnn
191/55: trained_rnn([0,1,1,1,1,1,0,0,0, 1])
191/56:
hidden = None
for data in validation_loader:
    x = data[:-1]
    y = data[1:]
    
    x = x.type("torch.FloatTensor")
    y = y.type("torch.FloatTensor")

    # convert data into Tensors

    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
    y_tensor = torch.Tensor(y)

    # outputs from the rnn
    prediction, hidden = trained_rnn(x_tensor, hidden)

    print(prediction)
192/1:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
%matplotlib inline
192/2:
plt.figure(figsize=(8,5))

# how many time steps/data pts are in one batch of data
seq_length = 20

# generate evenly spaced data pts
time_steps = np.linspace(0, np.pi, seq_length + 1)
data = np.sin(time_steps)
data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension

x = data[:-1] # all but the last piece of data
y = data[1:] # all but the first
192/3:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
192/4: data_frame1.head()
192/5:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
192/6:
# Creating data indices for training and validation splits:
validation_split = 0.3
batch_size = 100
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
192/7:
class RNN(nn.Module):
    def __init__(self, input_size, output_size, hidden_dim, n_layers):
        super(RNN, self).__init__()
        
        self.hidden_dim=hidden_dim

        # define an RNN with specified parameters
        # batch_first means that the first dim of the input and output will be the batch_size
        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)
        
        # last, fully-connected layer
        self.fc = nn.Linear(hidden_dim, output_size)

    def forward(self, x, hidden):
        # x (batch_size, seq_length, input_size)
        # hidden (n_layers, batch_size, hidden_dim)
        # r_out (batch_size, time_step, hidden_size)
        batch_size = x.size(0)
        
        # get RNN outputs
        r_out, hidden = self.rnn(x, hidden)
        # shape output to be (batch_size*seq_length, hidden_dim)
        r_out = r_out.view(-1, self.hidden_dim)  
        
        # get final output 
        output = self.fc(r_out)
        
        return output, hidden
192/8:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
192/9:
# generate evenly spaced, test data pts
device_states.shape
192/10:
test_input = torch.Tensor(device_states).unsqueeze(0) # give it a batch_size of 1 as first dimension
print('Input size: ', test_input.size())
192/11:
# test out rnn sizes
test_out, test_h = test_rnn(test_input, None)
print('Output size: ', test_out.size())
print('Hidden state size: ', test_h.size())
192/12:

# decide on hyperparameters
input_size=10 
output_size=10
hidden_dim=32
n_layers=1

# instantiate an RNN
rnn = RNN(input_size, output_size, hidden_dim, n_layers)
print(rnn)
192/13:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array()
192/14:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
192/15: device_states.shape
192/16: next(iter(train_loader)).shape
192/17:
# train the RNN
def train(rnn, n_steps, print_every):
    
    # initialize the hidden state
    hidden = None      
    
    batch_i = 0
    for data in train_loader:
        # defining the training data 
        batch_i += 1
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()

        # display loss and predictions
        if batch_i%print_every == 0:        
            print('Loss: ', loss.item())
    
    return rnn
192/18:
n_steps = 1
print_every = 15

trained_rnn = train(rnn, n_steps, print_every)
192/19: trained_rnn
192/20:
hidden = None
for data in validation_loader:
    x = data[:-1]
    y = data[1:]
    
    x = x.type("torch.FloatTensor")
    y = y.type("torch.FloatTensor")

    # convert data into Tensors

    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
    y_tensor = torch.Tensor(y)

    # outputs from the rnn
    prediction, hidden = trained_rnn(x_tensor, hidden)

    print(prediction)
    break
192/21:
hidden = None
for data in validation_loader:
    x = data[:-1]
    y = data[1:]
    
    x = x.type("torch.FloatTensor")
    y = y.type("torch.FloatTensor")

    # convert data into Tensors

    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
    y_tensor = torch.Tensor(y)

    # outputs from the rnn
    prediction, hidden = trained_rnn(x_tensor, hidden)

    print(prediction.shape)
    break
192/22:
hidden = None
for data in validation_loader:
    x = data[:-1]
    y = data[1:]
    
    x = x.type("torch.FloatTensor")
    y = y.type("torch.FloatTensor")

    # convert data into Tensors

    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
    y_tensor = torch.Tensor(y)

    # outputs from the rnn
    prediction, hidden = trained_rnn(x_tensor, hidden)

    print(prediction[0].shape)
    break
192/23:
train_loss = []
test_loss = []
hidden_state = []
192/24:
train_loss = []
test_loss = []
hidden_state = []
epochs = 10
192/25:
train_loss = []
test_loss = []
hidden_state = []
epochs = 1
192/26:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        batch_i += 1
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        train += criterion(prediction, y_tensor)
        
        
        
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
192/27:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        train += criterion(prediction, y_tensor)
        
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
192/28:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
192/29: prediction
192/30:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
%matplotlib inline
torch.set_printoptions(precision=4)
192/31: prediction
192/32:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
192/33:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
192/34:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
192/35:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
        torch.save(rnn.state_dict(), "./checkpoints/checkpoint_{}".format(epoch))
192/36: prediction
192/37: print(prediction)
192/38: print(prediction[0])
192/39:
train_loss = []
test_loss = []
hidden_state = []
epochs = 20
192/40:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
        torch.save(rnn.state_dict(), "./checkpoints/checkpoint_{}".format(epoch))
193/1:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
%matplotlib inline
torch.set_printoptions(precision=4)
193/2:
plt.figure(figsize=(8,5))

# how many time steps/data pts are in one batch of data
seq_length = 20

# generate evenly spaced data pts
time_steps = np.linspace(0, np.pi, seq_length + 1)
data = np.sin(time_steps)
data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension

x = data[:-1] # all but the last piece of data
y = data[1:] # all but the first
193/3: # splitting the dataser
193/4:
# display the data
plt.plot(time_steps[1:], x, 'r.', label='input, x') # x
plt.plot(time_steps[1:], y, 'b.', label='target, y') # y

plt.legend(loc='best')
plt.show()
193/5:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
193/6: data_frame1.head()
193/7:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
193/8:
# Creating data indices for training and validation splits:
validation_split = 0.3
batch_size = 100
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
193/9:
class RNN(nn.Module):
    def __init__(self, input_size, output_size, hidden_dim, n_layers):
        super(RNN, self).__init__()
        
        self.hidden_dim=hidden_dim

        # define an RNN with specified parameters
        # batch_first means that the first dim of the input and output will be the batch_size
        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)
        
        # last, fully-connected layer
        self.fc = nn.Linear(hidden_dim, output_size)

    def forward(self, x, hidden):
        # x (batch_size, seq_length, input_size)
        # hidden (n_layers, batch_size, hidden_dim)
        # r_out (batch_size, time_step, hidden_size)
        batch_size = x.size(0)
        
        # get RNN outputs
        r_out, hidden = self.rnn(x, hidden)
        # shape output to be (batch_size*seq_length, hidden_dim)
        r_out = r_out.view(-1, self.hidden_dim)  
        
        # get final output 
        output = self.fc(r_out)
        
        return output, hidden
193/10:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
193/11:
# generate evenly spaced, test data pts
device_states.shape
193/12:
test_input = torch.Tensor(device_states).unsqueeze(0) # give it a batch_size of 1 as first dimension
print('Input size: ', test_input.size())
193/13:
# test out rnn sizes
test_out, test_h = test_rnn(test_input, None)
print('Output size: ', test_out.size())
print('Hidden state size: ', test_h.size())
193/14:

# decide on hyperparameters
input_size=10 
output_size=10
hidden_dim=32
n_layers=1

# instantiate an RNN
rnn = RNN(input_size, output_size, hidden_dim, n_layers)
print(rnn)
193/15:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
193/16: device_states.shape
193/17: next(iter(train_loader)).shape
193/18:
train_loss = []
test_loss = []
hidden_state = []
epochs = 20
193/19:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
        torch.save(rnn.state_dict(), "./checkpoints/checkpoint_{}".format(epoch))
192/41: prediction
192/42: prediction = prediction[prediction<0.5] = 0
192/43: prediction[prediction<0.5] = 0
192/44: prediction[prediction < 0.5] = 0
193/20:

# decide on hyperparameters
input_size=10 
output_size=10
hidden_dim=64
n_layers=2

# instantiate an RNN
rnn = RNN(input_size, output_size, hidden_dim, n_layers)
print(rnn)
193/21:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
193/22: device_states.shape
193/23: next(iter(train_loader)).shape
193/24:
train_loss = []
test_loss = []
hidden_state = []
epochs = 20
193/25:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
        torch.save(rnn.state_dict(), "./checkpoints/checkpoint_{}".format(epoch))
192/45: prediction
195/1: prediction
195/2:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
%matplotlib inline
torch.set_printoptions(precision=4)
195/3:
plt.figure(figsize=(8,5))

# how many time steps/data pts are in one batch of data
seq_length = 20

# generate evenly spaced data pts
time_steps = np.linspace(0, np.pi, seq_length + 1)
data = np.sin(time_steps)
data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension

x = data[:-1] # all but the last piece of data
y = data[1:] # all but the first
195/4: # splitting the dataser
195/5:
# display the data
plt.plot(time_steps[1:], x, 'r.', label='input, x') # x
plt.plot(time_steps[1:], y, 'b.', label='target, y') # y

plt.legend(loc='best')
plt.show()
195/6:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
195/7: data_frame1.head()
195/8:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
195/9:
# Creating data indices for training and validation splits:
validation_split = 0.3
batch_size = 100
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
195/10:
class RNN(nn.Module):
    def __init__(self, input_size, output_size, hidden_dim, n_layers):
        super(RNN, self).__init__()
        
        self.hidden_dim=hidden_dim

        # define an RNN with specified parameters
        # batch_first means that the first dim of the input and output will be the batch_size
        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)
        
        # last, fully-connected layer
        self.fc = nn.Linear(hidden_dim, output_size)

    def forward(self, x, hidden):
        # x (batch_size, seq_length, input_size)
        # hidden (n_layers, batch_size, hidden_dim)
        # r_out (batch_size, time_step, hidden_size)
        batch_size = x.size(0)
        
        # get RNN outputs
        r_out, hidden = self.rnn(x, hidden)
        # shape output to be (batch_size*seq_length, hidden_dim)
        r_out = r_out.view(-1, self.hidden_dim)  
        
        # get final output 
        output = self.fc(r_out)
        
        return output, hidden
195/11:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
195/12:
# generate evenly spaced, test data pts
device_states.shape
195/13:

# decide on hyperparameters
input_size=10 
output_size=10
hidden_dim=64
n_layers=2

# instantiate an RNN
rnn = RNN(input_size, output_size, hidden_dim, n_layers)
print(rnn)
195/14:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
195/15: device_states.shape
195/16: next(iter(train_loader)).shape
195/17:
train_loss = []
test_loss = []
hidden_state = []
epochs = 20
195/18:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
        torch.save(rnn.state_dict(), "./checkpoints/checkpoint_{}".format(epoch))
194/1: a = randomGenerateState(10)
194/2:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import gym
import time
194/3:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import gym
import time
194/4:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import time
194/5:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor(int(res))

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/6: a = randomGenerateState(10)
194/7: a
194/8:
class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/9: env = iotenvBinary(10)
194/10: env
194/11: env()
194/12: env = iotenvBinary(8)
194/13:
# HyperParameters
BATCH_SIZE = 2
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 4
N_STATES = 4
ENV_SHAPE = 0
194/14:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
194/15:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        x = torch.unsqueeze(torch.LongTensor(x), 1)
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/16:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
        x = torch.unsqueeze(torch.LongTensor(x), 1)
        
        
        
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/17:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/18:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        print(s.shape)
        
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/19:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        print(s)
        
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/20:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        print([s].shape)
        
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/21:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/22:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])
        print(z.shape)
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/23:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/24:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        z = z.type(torch.FloatTensor)
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/25:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
        
        print(x.type())
        
        x = torch.unsqueeze(x, 1)
        
        
        
        if np.random.uniform() < EPSILON:
            actions_value = self.eval_net.forward(x)
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/26:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        z = z.type(torch.FloatTensor)
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/27:
# HyperParameters
BATCH_SIZE = 2
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 2
N_STATES = 2**8
ENV_SHAPE = 0
194/28:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(N_STATES, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
194/29:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
        
        
        x = torch.unsqueeze(x, 1)
        
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/30:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        z = z.type(torch.FloatTensor)
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward()
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY:
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/31:
temp = torch.zeros(8)
temp
194/32: temp = torch.zeros(8)
194/33:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
194/34:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
        
        
        x = torch.unsqueeze(x, 1)
        
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/35:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        z = z.type(torch.FloatTensor)
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/36: a = torch.Tensor([1,0,1,1,1,1,0,0,0,0])
194/37: a
194/38:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        z = z.type(torch.FloatTensor)
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/39:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor([res])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/40: a = randomGenerateState(10)
194/41:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    return torch.tensor([list(res)])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/42: a = randomGenerateState(10)
194/43:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    print(res)
    return torch.tensor([list(res)])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/44: a = randomGenerateState(10)
194/45:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    print(res)
    return torch.tensor([list(res)])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/46: a = randomGenerateState(10)
194/47:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    return torch.tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/48: a = randomGenerateState(10)
194/49:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    return torch.tensor([res])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/50: a = randomGenerateState(10)
194/51:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    return torch.Tensor([res])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/52: a = randomGenerateState(10)
194/53:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = np.array(res)
    return torch.Tensor([res])

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/54: a = randomGenerateState(10)
194/55:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/56: a = randomGenerateState(10)
194/57:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(int(res))
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/58: a = randomGenerateState(10)
194/59:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(f,g):
    # g is new, f is old
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '1' :
            sm += (energy[dev, int(g[dev])] - energy[dev, int(f[dev])] )
    return sm

def r_human(f,g) :
    x = stateXOR(f,g)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/60: a = randomGenerateState(10)
194/61: a
194/62: a.shape
194/63:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    print(s)
    ep_r = 0
    while True:
        
        z = torch.tensor([s])

        z = z.type(torch.FloatTensor)
        
        a = dqn.choose_action(z)
        s_, r, done, info = env.step(a)
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/64:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    ep_r = 0
    while True:
                
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/65:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/66:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
                
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/67:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/68: env = iotenvBinary(10)
194/69:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 8
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/70: # flatten the input and send input into linear layer
194/71:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
194/72:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/73:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/74:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/75:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/76:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/77:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/78:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/79: # flatten the input and send input into linear layer
194/80:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/81:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/82:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/83:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            print(actions_value)
            
            action = torch.max(actions_value, 1)[1].data.numpy()
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/84:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/85:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            print(actions_value)
            
            action = torch.max(actions_value)
            
            print(action)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/86:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/87:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            print(actions_value)
            
            action = torch.max(actions_value)
            
            print(action[0])
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/88:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/89:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            print(actions_value)
            
            action = torch.max(actions_value)
            
            action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        else:
            action = np.random.randint(0, N_ACTIONS)
            action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/90:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/91:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            print(actions_value)
            
            action = torch.max(actions_value)
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/92:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/93:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        
        
    
        s_, r, done, info = env.step(str(a))
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/94:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):
        
            
        print(x.shape)
        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            print(actions_value)
            
            val, ind = torch.max(actions_value, 0)
            
            print(ind)
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return action
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/95:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        
        
    
        s_, r, done, info = env.step(str(a))
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/96:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/97:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        print(s)
        a = dqn.choose_action(s)
        
        
    
        s_, r, done, info = env.step(str(a))
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/98:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/99:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        
        print(action)
        
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/100: env = iotenvBinary(10)
194/101:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/102: # flatten the input and send input into linear layer
194/103:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/104:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/105:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/106:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action):
        self.prev = self.state
        
        print(self.state)
        print(action)
        
        self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/107: env = iotenvBinary(10)
194/108:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/109: # flatten the input and send input into linear layer
194/110:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/111:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/112:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/113:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/114:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/115:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/116: env = iotenvBinary(10)
194/117:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/118: # flatten the input and send input into linear layer
194/119:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/120:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/121:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/122:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        
        self.state = str(self.state)
        
        print(self.state)
        
        break
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/123: env = iotenvBinary(10)
194/124:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/125:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        
        self.state = str(self.state)
        
        print(self.state)
        
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/126: env = iotenvBinary(10)
194/127:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/128: # flatten the input and send input into linear layer
194/129:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/130:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/131:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/132:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        
        self.state = str(self.state)
        
        st = ""
        for i in self.state:
            i = str(i)
            st += i
        print(st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/133: env = iotenvBinary(10)
194/134:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/135: # flatten the input and send input into linear layer
194/136:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/137:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/138:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/139:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        
        self.state = str(self.state)
        
        st = ""
        for i in self.state:
            i = str(i)
            st += i
        print("sshjfgh", st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/140: env = iotenvBinary(10)
194/141:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/142: # flatten the input and send input into linear layer
194/143:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/144:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/145:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/146:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
        
        self.state = str(self.state)
        
        st = ""
        for i in self.state:
            print(i)
            i = str(i)
            st += i
        print("sshjfgh", st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/147: env = iotenvBinary(10)
194/148:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/149: # flatten the input and send input into linear layer
194/150:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/151:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/152:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/153:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
            
        st = ""
        for i in self.state:
            print(i)
            i = str(i)
            st += i
        print("sshjfgh", st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/154: env = iotenvBinary(10)
194/155:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/156: # flatten the input and send input into linear layer
194/157:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/158:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/159:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/160:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
            
        st = ""
        for i in self.state:
            print(i.item())
            i = str(i)
            st += i
        print("sshjfgh", st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/161: env = iotenvBinary(10)
194/162:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/163: # flatten the input and send input into linear layer
194/164:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/165:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/166:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/167:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
            
        st = ""
        for i in self.state:
            i = str(int(i))
            print(i)
            st += i
        print("sshjfgh", st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev,self.state)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/168: env = iotenvBinary(10)
194/169:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/170: # flatten the input and send input into linear layer
194/171:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/172:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/173:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/174:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print(self.state)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index] 
         
            
        print(self.state)
        
            
        st = ""
        for i in self.state:
            i = str(int(i))
            print(i)
            st += i
        print("sshjfgh", st)
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, st)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev, st)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/175: env = iotenvBinary(10)
194/176:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/177: # flatten the input and send input into linear layer
194/178:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/179:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/180:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/181:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        print("p", self.prev)
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index]         
            
        st = ""
        for i in self.state:
            i = str(int(i))
            print(i)
            st += i
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, st)
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev, st)
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/182: env = iotenvBinary(10)
194/183:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/184: # flatten the input and send input into linear layer
194/185:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/186:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/187:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/188:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self,action_index):
        self.prev = self.state
        
        p = ""
        for i in self.prev:
            i = str(int(i))
            print(i)
            p += i
        self.prev = p
#         print(action_index)
        
        #self.state = self.state[:action-1]+ str(1-int(self.state[action-1])) +self.state[action-1+1:]
        self.state[action_index] = 1 - self.state[action_index]         
            
        st = ""
        for i in self.state:
            i = str(int(i))
            print(i)
            st += i
        self.state = st
        
        
        #old=new sum such energy
        #XNOR
        R_human = r_human(self.prev, self.state )
        
        # old!=new perform new-old
        #XOR
        R_energy = r_energy(self.prev, self.state )
        
        print('reward',R_human, R_energy)
        
        reward = self.biasHuman*R_human + (1-self.biasHuman)*R_energy
        
        # no such thing as done, therefore use done=False
        done=False
        
        info = 'none'
        
        return [self.state], reward, done, info
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/189: env = iotenvBinary(10)
194/190:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
194/191: # flatten the input and send input into linear layer
194/192:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
194/193:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
194/194:
# Run DQN

start = time.time()
dqn = DQN()
# dqn.load_model()
print("Start")
print('\nCollecting experience...')
for i_episode in range(60000):
    s = env.reset()
    
    ep_r = 0
    while True:
        
        
        a = dqn.choose_action(s)
        
        s_, r, done, info = env.step(a)
        
        
        
        # modify the reward
        r = env.get_reward() #check this step if needed 
        dqn.store_transition(s, a, r, s_)
        ep_r += r
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))
        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))       
        if done:
            break
        s = s_
end = time.time()
194/195: energy = np.array(12,5,3)
194/196:
energy = (10,5,3,4)
energy = np.asarray(energy)
194/197:
energy = (10,5,3,4)
energy = np.asarray(energy)
print(enerdy)
194/198:
energy = (10,5,3,4)
energy = np.asarray(energy)
print(energy)
199/1: import pandas as pd
199/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
199/3:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
199/4: df = df.drop('use [kW]', axis = 1)
199/5: df = df.drop('gen [kW]', axis = 1)
199/6: df.desc()
199/7: df.desc
199/8: df.describe
199/9: df.describe()
199/10: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
199/11:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
199/12: df = df.drop('Date & Time', axis = 1)
199/13: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
199/14:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
199/15: df.fillna(0).astype(bool).sum(axis=1)
199/16: df.fillna(0).astype(bool).sum(axis=1)
199/17: df.astype(bool).sum(axis = 0)
199/18: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
199/19:
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
199/20:
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
199/21:
import numpy as np
import sklearn
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
200/1: import pandas as pd
200/2:
df = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df.head()
200/3: df = df.drop('use [kW]', axis = 1)
200/4: df = df.drop('gen [kW]', axis = 1)
200/5: df.describe()
200/6: df['Date & Time'] = pd.to_datetime(df['Date & Time'])
200/7:
df['Month'] = df['Date & Time'].dt.month
df['Day'] = df['Date & Time'].dt.day
df['Hour'] = df['Date & Time'].dt.hour
df['Minute'] = df['Date & Time'].dt.minute
200/8: df = df.drop('Date & Time', axis = 1)
200/9: df.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
200/10:
df['Furnace'] = df['Furnace'].multiply(1000)
df['Cellar Outlets'] = df['Cellar Outlets'].multiply(1000)
df['Washing Machine'] = df['Washing Machine'].multiply(1000)
df['Refrigerator'] = df['Refrigerator'].multiply(1000)
df['Dishwasher'] = df['Dishwasher'].multiply(1000)

df['Kitchen Lights'] = df['Kitchen Lights'].multiply(1000)
df['Bedroom 1 Outlets'] = df['Bedroom 1 Outlets'].multiply(1000)
df['Bedroom 1 Lights'] = df['Bedroom 1 Lights'].multiply(1000)
df['Master Bedroom Outlets'] = df['Master Bedroom Outlets'].multiply(1000)
df['Master Bedroom Lights'] = df['Master Bedroom Lights'].multiply(1000)
df['Heating Duct'] = df['Heating Duct'].multiply(1000)
200/11: df.fillna(0).astype(bool).sum(axis=1)
200/12: df.astype(bool).sum(axis = 0)
200/13: new_df = df[['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct']].copy()
200/14:
import numpy as np
import sklearn
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

mms = MinMaxScaler()
200/15:
furnace_df = new_df['Furnace']
furnace_df = np.asarray(furnace_df, dtype=int)
mms.fit(furnace_df.reshape(-1,1))
data_furnace = mms.transform(furnace_df.reshape(-1, 1))

cellar_df = new_df['Cellar Outlets']
cellar_df = np.asarray(cellar_df, dtype=int)
mms.fit(cellar_df.reshape(-1,1))
data2 = mms.transform(cellar_df.reshape(-1, 1))

wash_df = new_df['Washing Machine']
wash_df = np.asarray(wash_df, dtype=int)
mms.fit(wash_df.reshape(-1,1))
data3 = mms.transform(wash_df.reshape(-1, 1))

refri_df = new_df['Refrigerator']
refri_df = np.asarray(refri_df, dtype=int)
mms.fit(refri_df.reshape(-1,1))
data4 = mms.transform(refri_df.reshape(-1, 1))

dish_df = new_df['Dishwasher']
dish_df = np.asarray(dish_df, dtype=int)
mms.fit(dish_df.reshape(-1,1))
data5 = mms.transform(dish_df.reshape(-1, 1))

kitchen_df = new_df['Kitchen Lights']
kitchen_df = np.asarray(kitchen_df, dtype=int)
mms.fit(kitchen_df.reshape(-1,1))
data6 = mms.transform(kitchen_df.reshape(-1, 1))

bedl_df = new_df['Bedroom 1 Lights']
bedl_df = np.asarray(bedl_df, dtype=int)
mms.fit(bedl_df.reshape(-1,1))
data7 = mms.transform(bedl_df.reshape(-1, 1))

bedo_df = new_df['Bedroom 1 Outlets']
bedo_df = np.asarray(bedo_df, dtype=int)
mms.fit(bedo_df.reshape(-1,1))
data8 = mms.transform(bedo_df.reshape(-1, 1))

mbedl_df = new_df['Master Bedroom Lights']
mbedl_df = np.asarray(mbedl_df, dtype=int)
mms.fit(mbedl_df.reshape(-1,1))
data9 = mms.transform(mbedl_df.reshape(-1, 1))

mbedo_df = new_df['Master Bedroom Outlets']
mbedo_df = np.asarray(mbedo_df, dtype=int)
mms.fit(mbedo_df.reshape(-1,1))
data10 = mms.transform(mbedo_df.reshape(-1, 1))
194/199:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767, 0.000000),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467, 0.000933))
energy = np.asarray(energy)
print(energy)
194/200:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767, 0.000000),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467, 0.000933))
energy = np.asarray(energy)
print(energy[0])
194/201:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767, 0.000000),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467, 0.000933))
energy = np.asarray(energy)
print(energy[0][9])
194/202:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767, 0.000000),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467, 0.000933))
energy = np.asarray(energy)
print(energy[0][10])
194/203:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767, 0.000000),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467, 0.000933))
energy = np.asarray(energy)
print(energy[0][9])
194/204:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467))
energy = np.asarray(energy)
print(energy[0][9])
194/205:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467))
energy = np.asarray(energy)
194/206:
def r_energy(state_str):
    for i in state_str:
        print i
194/207:
def r_energy(state_str):
    for i in state_str:
        print i
        
r_energy("1011010101")
194/208:
def r_energy(state_str):
    r_energy_sum = 0
    for index in range(0,10):
        for i in state_str:
            r_energy_sum += energy[i][index]
r_energy("1011010101")
194/209:
def r_energy(state_str):
    r_energy_sum = 0
    for i in enumerate(state_str):
         print(i)
r_energy("1011010101")
194/210:
def r_energy(state_str):
    r_energy_sum = 0
    for i,bit in enumerate(state_str):
         print(bit)
r_energy("1011010101")
194/211:
def r_energy(state_str):
    r_energy_sum = 0
    for i,bit in enumerate(state_str):
         print(i)
r_energy("1011010101")
194/212:
def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
         r_energy_sum += energy[bit][i]
r_energy("1011010101")
194/213:
def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
         r_energy_sum += energy[bit][i]
r_energy('1011010101')
194/214:
def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        print(i)
        print(bit)
         r_energy_sum += energy[bit][i]
r_energy('1011010101')
194/215:
def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        print(i)
        print(bit)
        r_energy_sum += energy[bit][i]
r_energy('1011010101')
194/216:
def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        print(i)
        print(bit)
        r_energy_sum += energy[int(bit)][i]
r_energy('1011010101')
194/217:
def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return r_energy_sum
r_energy('1011010101')
194/218:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm
194/219:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    sm = 0
    for dev,match in enumerate(x) :
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm

r_human('1010011000', '1110010101')
194/220:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return -r_energy_sum
194/221: r_energy('1010011000')
194/222:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        print(i)
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm

r_human('1010011000', '1110010101')
194/223:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        print(i, bit)
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm

r_human('1010011000', '1110010101')
194/224:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        print(1, bit)
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm

r_human('1010011000', '1110010101')
194/225:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        print(i, int(bit))
        if match == '0' :  #therefore XNOR
            sm += energy[dev, int(g[dev])]
    return sm

r_human('1010011000', '1110010101')
194/226:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[int(bit)[i]]
        return r_human_sum

r_human('1010011000', '1110010101')
194/227:
def r_human(state_str1, state_str2) :
    x = stateXOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[int(bit)][i]
        return r_human_sum

r_human('1010011000', '1110010101')
194/228:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for i in range(len(state1)):
        if(state1[i] == state2[i]):
            result += "1"
        else:
            result += "0"
    return result
194/229: stateXNOR('1010011000', '1110010101')
194/230:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for i in state1:
        if(state1[i] == state2[i]):
            result += "1"
        else:
            result += "0"
    return result
194/231: stateXNOR('1010011000', '1110010101')
194/232:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for index1,val1 in state1:
        for index1, val2 in state2:
        if(val1 == val2):
            result += "1"
        else:
            result += "0"
    return result
194/233:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for index1,val1 in state1:
        for index1, val2 in state2:
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/234: stateXNOR('1010011000', '1110010101')
194/235:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for index1,val1 in state1:
        for index1, val2 in state2:
            print(val1, val2)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/236: stateXNOR('1010011000', '1110010101')
194/237:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for val1,index in state1:
        for val2,index in state2:
            print(val1, val2)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/238: stateXNOR('1010011000', '1110010101')
194/239:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for index,val1 in state1:
        for index,val2 in state2:
            print(val1, val2)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/240: stateXNOR('1010011000', '1110010101')
194/241:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    state2 = enumerate(str2)
    result = ""
    for index,val1 in state1:
        for index,val2 in state2:
            print(index, val1, val2)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/242: stateXNOR('1010011000', '1110010101')
194/243:
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[int(bit)][i]
        return r_human_sum

r_human('1010011000', '1110010101')
194/244:
def stateXNOR(str1, str2):
    state1 = enumerate(str1)
    print(state1)
    state2 = enumerate(str2)
    print(state2)
    result = ""
    for index,val1 in state1:
        for index,val2 in state2:
            print(index, val1, val2)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/245: stateXNOR('1010011000', '1110010101')
194/246:
def stateXNOR(str1, str2):
    result = ""
    for index,val1 in enumerate(str1):
        for index,val2 in enumerate(str2):
            print(index, val1, val2)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/247: stateXNOR('1010011000', '1110010101')
194/248:
def stateXNOR(str1, str2):
    result = ""
    for index,val1 in enumerate(str1):
        for index,val2 in enumerate(str2):
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/249: stateXNOR('1010011000', '1110010101')
194/250: stateXNOR('10010', '10001')
194/251:
def stateXNOR(str1, str2):
    result = ""
    for index,val1 in enumerate(str1):
        for index,val2 in enumerate(str2):
            print(str1)
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/252: stateXNOR('10010', '10001')
194/253:
def stateXNOR(str1, str2):
    result = ""
    for index,val1 in enumerate(str1) and index,val2 in enumerate(str2):
            if(val1 == val2):
                result += "1"
            else:
                result += "0"
    return result
194/254: stateXNOR('10010', '10001')
194/255:
xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}
def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])
194/256: stateXNOR('10010', '10001')
194/257:
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[int(bit)][i]
        return r_human_sum

r_human('1010011000', '1110010101')
194/258: stateXNOR('10010', '10001')
194/259:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]
        return r_human_sum
194/260:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]
        return r_human_sum
    
def convert2btr(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
194/261:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
194/262:
list = [1,2,3,4,5]
print(max(list))
194/263:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state, state_list, reward_list):
        self.rnn = rnn_state
    
        for i in range(10):
            self.prev = self.state
            self.state[action_index] = 1 - self.state[action_index]
            state_list.append(convert2str(self.state))
            reward = get_reward(self.prev, self.state, self.rnn)
            reward_list.append(reward)
            action_index = dqn.choose_action(self.state)
            step(action_index, rnn_state, state_list, reward_list)
        
        return [self.state], max(reward_list)
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
194/264: env = iotenvBinary(10)
201/1:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import time
201/2:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467))
energy = np.asarray(energy)
201/3:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    print(x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/4:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    R_human = r_human(convert2str(self.prev), convert2str(self.state))
    R_energy = r_energy(convert2str(self.prev), convert2str(self.state))
    print('reward',R_human, R_energy)
    reward = R_human + R_energy
    return reward
201/5: a = randomGenerateState(10)
201/6: a.shape
201/7: temp = torch.zeros(8)
201/8:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state, state_list, reward_list):
        self.rnn = rnn_state
    
        for i in range(10):
            self.prev = self.state
            self.state[action_index] = 1 - self.state[action_index]
            state_list.append(convert2str(self.state))
            reward = get_reward(self.prev, self.state, self.rnn)
            reward_list.append(reward)
            action_index = dqn.choose_action(self.state)
            step(action_index, rnn_state, state_list, reward_list)
        
        return [self.state], max(reward_list)
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/9: env = iotenvBinary(10)
201/10:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/11:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
201/12:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/13:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')
for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    for i_timestamp in range(10):
        
        a = dqn.choose_action(s)
        
#         rnn_state = RNN()

        rnn_state = env.reset()
        state_list = []
        reward_list = []
        
        s_, r = env.step(a, rnn_state, state_list, reward_list)
        
        # loop here with new states state will change everytime
        
        #for every state in list, along with RNN state, find reward Re,Rh
        
        #final reward = Rh + Re
        
        
        dqn.store_transition(s, a, r, s_)
        
        ep_r += r
        
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))

        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
        s = s_
        
end = time.time()
201/14:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    print('reward',R_human, R_energy)
    reward = R_human + R_energy
    return reward
201/15:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    print('reward',R_human, R_energy)
    reward = R_human + R_energy
    return reward
201/16:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state, state_list, reward_list):
        self.rnn = rnn_state
    
        for i in range(10):
            self.prev = self.state
            self.state[action_index] = 1 - self.state[action_index]
            state_list.append(convert2str(self.state))
            reward = get_reward(self.prev, self.state, self.rnn)
            reward_list.append(reward)
            action_index = dqn.choose_action(self.state)
            step(action_index, rnn_state, state_list, reward_list)
        
        return [self.state], max(reward_list)
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/17: env = iotenvBinary(10)
201/18:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/19:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
201/20:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/21:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')
for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    for i_timestamp in range(10):
        
        a = dqn.choose_action(s)
        
#         rnn_state = RNN()

        rnn_state = env.reset()
        state_list = []
        reward_list = []
        
        s_, r = env.step(a, rnn_state, state_list, reward_list)
        
        # loop here with new states state will change everytime
        
        #for every state in list, along with RNN state, find reward Re,Rh
        
        #final reward = Rh + Re
        
        
        dqn.store_transition(s, a, r, s_)
        
        ep_r += r
        
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))

        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
        s = s_
        
end = time.time()
201/22:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state, state_list, reward_list):
        self.rnn = rnn_state
    
        for i in range(10):
            self.prev = self.state
            self.state[action_index] = 1 - self.state[action_index]
            state_list.append(convert2str(self.state))
            reward = get_reward(self.prev, self.state, self.rnn)
            reward_list.append(reward)
            action_index = dqn.choose_action(self.state)
            self.step(action_index, rnn_state, state_list, reward_list)
        
        return [self.state], max(reward_list)
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/23: env = iotenvBinary(10)
201/24:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/25:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
201/26:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/27:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')
for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    for i_timestamp in range(10):
        
        a = dqn.choose_action(s)
        
#         rnn_state = RNN()

        rnn_state = env.reset()
        state_list = []
        reward_list = []
        
        s_, r = env.step(a, rnn_state, state_list, reward_list)
        
        # loop here with new states state will change everytime
        
        #for every state in list, along with RNN state, find reward Re,Rh
        
        #final reward = Rh + Re
        
        
        dqn.store_transition(s, a, r, s_)
        
        ep_r += r
        
        if dqn.memory_counter > MEMORY_CAPACITY: 
            dqn.learn()
#             if done:
#                 print('Ep: ', i_episode,
#                       '| Ep_r: ', round(ep_r, 2))

        if(i_episode % 500 == 0):
            print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
        s = s_
        
end = time.time()
201/28:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
        self.rnn = rnn_state
    
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, self.rnn)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/29: env = iotenvBinary(10)
201/30:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/31:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
201/32:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
        return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/33:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clash = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(reward_list, 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    dqn.store_transition(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/34:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/35:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clash = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(reward_list, 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    dqn.store_transition(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/36:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clash = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    dqn.store_transition(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/37:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clash = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/38:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/39:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    reward = R_human + R_energy
    return reward
201/40:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
        self.rnn = rnn_state
    
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, self.rnn)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/41: env = iotenvBinary(10)
201/42:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/43:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        print(actions_value.shape)
        return actions_value
201/44:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/45:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clash = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/46:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/47:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/48:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clash = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/49:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    clash = stateXNOR(convert2str(temp), convert2str(best_s))
    
    print(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/50:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == 1:
            clash += 1
    print(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/51:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == 1:
            clash += 1
    print(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/52:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/53:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        print(transition)
        print(index)
        
        break
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/54:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        print(transition)
        print(index)
        
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/55:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/56:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        print(transition)
        print(index)
        
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/57:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    break
    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = s_
        
end = time.time()
201/58:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/59:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/60:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/61:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 500 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/62:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = env.reset()   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
195/19: prediction
195/20: prediction.shape
195/21: prediction
195/22:
for i in prediction:
    print(i)
    break
195/23:
for i in prediction:
    for j in i:
        if j <0.5:
            j = 0
        else:
            j = 1
195/24: prediction
195/25:
for i in range(len(prediction)):
    for j in range(len(i)):
        if prediction[i][j] <0.5:
            prediction[i][j] = 0
        else:
            prediction[i][j] = 1
195/26:
for i in range(len(prediction)):
    for j in range(prediction[i]):
        if prediction[i][j] <0.5:
            prediction[i][j] = 0
        else:
            prediction[i][j] = 1
195/27: temp = prediction
195/28: prediction[0,0]
195/29: temp = prediction[:]
195/30: temp
195/31:
for i in range(len(prediction)):
    for j in range(prediction[i]):
        if prediction[i,j] <0.5:
            prediction[i,j] = 0
        else:
            prediction[i,j] = 1
195/32: prediction.shape
201/63:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/64:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/65:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
201/66: device_states.shape
201/67:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2038):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        a
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/68:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2038):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/69:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/70:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/71:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/72:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2038):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/73: clashes
201/74:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import time
import matplotlib.pyplot as plt
%matplotlib inline
201/75: plt.plot(clashes)
201/76:
plt.plot(clashes)
plt.ylim(0,10)
201/77:
plt.plot(clashes)
plt.ylim(0,100)
201/78:
clashes.sort(reverse=True)
plt.plot(clashes)
plt.ylim(0,100)
201/79:
clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
201/80:
plt.plot(clashes)
# plt.ylim(0,100)
201/81:
plt.plot(clashes)
# plt.ylim(0,100)
201/82:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2038):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/83:
# clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
201/84:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/85:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    
    print(R_human, R_energy)
    
    reward = R_human + R_energy
    return reward
201/86:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
        self.rnn = rnn_state
    
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, self.rnn)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/87: env = iotenvBinary(10)
201/88:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/89:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/90:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/91:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/92:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
201/93: device_states.shape
201/94:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
    print(best_r, best_i, best_s)
    
    print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/95:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/96:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    
    
    print(dqn_prev_state)
    print(dqn_curr_state)
    print(rnn_state)
    
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    
    print(R_human, R_energy)
    
    reward = R_human + R_energy
    return reward
201/97:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/98: env = iotenvBinary(10)
201/99:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/100:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/101:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/102:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/103:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
201/104:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/105:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    
    
    print("p", dqn_prev_state)
    print("c", dqn_curr_state)
    print("r", rnn_state)
    
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    
#     print(R_human, R_energy)
    
    reward = R_human + R_energy
    return reward
201/106:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/107: env = iotenvBinary(10)
201/108:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/109:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/110:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/111:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/112:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
201/113: device_states.shape
201/114:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/115:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        self.prev = self.state[:]
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/116: env = iotenvBinary(10)
201/117:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/118:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/119:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/120:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/121:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
201/122: device_states.shape
201/123:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/124:
def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    
    
    print("p", dqn_prev_state)
    print("c", dqn_curr_state)
    print("r", rnn_state)
    
    print("----------------------")
    
    R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
    R_energy = r_energy(convert2str(dqn_curr_state))
    
#     print(R_human, R_energy)
    
    reward = R_human + R_energy
    return reward
201/125:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(action_index)
        self.prev = self.state[:]
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/126: env = iotenvBinary(10)
201/127:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/128:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/129:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/130:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/131:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
201/132: device_states.shape
201/133:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/134: z = tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1.])
201/135: z = torch.Tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1.])
201/136: z[5] = 1
201/137: z
201/138: z = torch.Tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1.])
201/139: z[5] = 1 - z[5]
201/140: z
201/141: z[5,0] = 1 - z[5]
201/142:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(action_index)
        self.prev = self.state[:]
        tmp = 1 - self.state[action_index]
        reward = get_reward(self.prev, tmp, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/143: env = iotenvBinary(10)
201/144:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/145:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/146:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/147:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/148:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/149: # device_states.shape
201/150:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/151:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(action_index)
        self.prev = self.state
        self.state[action_index] = 1 - self.state[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/152: env = iotenvBinary(10)
201/153:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/154:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/155:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/156:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/157:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/158:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/159:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(action_index)
        self.prev = self.state
        
#         self.state =   self.state.data.numpy
        
        
        self.state.data[action_index] = 1 - self.state.data[action_index]
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/160: env = iotenvBinary(10)
201/161:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/162:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/163:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/164:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/165:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/166: # device_states.shape
201/167:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/168:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(action_index)
        self.prev = self.state
        
        self.state =   self.state.data.numpy()
        self.state.data[action_index] = 1 - self.state.data[action_index]
        
        self.state = torch.Tensor(self.state)
        
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/169: env = iotenvBinary(10)
201/170:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/171:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/172:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/173:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/174:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/175: # device_states.shape
201/176:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/177:
clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
201/178:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(action_index)
        self.prev = self.state
        
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/179: env = iotenvBinary(10)
201/180:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/181:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/182:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/183:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/184:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/185: # device_states.shape
201/186:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/187:
z = torch.Tensor([0., 1., 0., 0., 0., 0., 0., 1., 1., 1.])
p = z
201/188: p[5] = 1 - p[5]
201/189: p
201/190:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
    def step(self, action_index, rnn_state):
    
        print(self.prev)
        self.prev = self.state
        
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        print(self.state)
        
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/191: env = iotenvBinary(10)
201/192:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/193:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/194:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/195:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/196:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/197: # device_states.shape
201/198:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/199:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, action_index, rnn_state):
    
        self.prev = self.state
        print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        print(self.state)
        
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/200: env = iotenvBinary(10)
201/201:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/202:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/203:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/204:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/205:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/206: # device_states.shape
201/207:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/208:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, action_index, rnn_state):
    
        self.prev = self.state
#         print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
#         print(self.state)
        
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/209: env = iotenvBinary(10)
201/210:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/211:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/212:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/213:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/214:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/215: # device_states.shape
201/216:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/217:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state
#         print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
#         print(self.state)
        
        reward = get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/218: env = iotenvBinary(10)
201/219:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/220:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/221:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/222:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/223:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state
#         print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
#         print(self.state)
        
        reward = self.get_reward(self.prev, self.state, rnn_state)
               
        return self.state, reward
    
    def get_reward(dqn_prev_state, dqn_curr_state, rnn_state):
    
        print("p", dqn_prev_state)
        print("c", dqn_curr_state)
        print("r", rnn_state)

        print("----------------------")

        R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
        R_energy = r_energy(convert2str(dqn_curr_state))

    #     print(R_human, R_energy)

        reward = R_human + R_energy
        return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/224: env = iotenvBinary(10)
201/225:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/226:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/227:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/228:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/229:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/230: # device_states.shape
201/231:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/232:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state
#         print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
#         print(self.state)
        
        reward = self.get_reward(rnn_state)
               
        return self.state, reward
    
    def get_reward(self, rnn_state):
    
        dqn_prev_state = self.prev
        dqn_curr_state = self.state
        
        print("p", dqn_prev_state)
        print("c", dqn_curr_state)
        print("r", rnn_state)

        print("----------------------")

        R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
        R_energy = r_energy(convert2str(dqn_curr_state))

    #     print(R_human, R_energy)

        reward = R_human + R_energy
        return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/233: env = iotenvBinary(10)
201/234:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/235:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/236:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/237:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/238:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/239: # device_states.shape
201/240:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/241:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state
        print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        print(self.state)
        
        reward = self.get_reward(rnn_state)
               
        return self.state, reward
    
    def get_reward(self, rnn_state):
    
        dqn_prev_state = self.prev
        dqn_curr_state = self.state
        
        print("p", dqn_prev_state)
        print("c", dqn_curr_state)
        print("r", rnn_state)

        print("----------------------")

        R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
        R_energy = r_energy(convert2str(dqn_curr_state))

    #     print(R_human, R_energy)

        reward = R_human + R_energy
        return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/242: env = iotenvBinary(10)
201/243:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/244:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/245:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/246:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/247:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/248: # device_states.shape
201/249:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/250:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state
        print(self.prev)

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        print(self.state)
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/251: env = iotenvBinary(10)
201/252:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/253:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/254:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/255:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/256:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/257: # device_states.shape
201/258:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/259:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/260: env = iotenvBinary(10)
201/261:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/262:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/263:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/264:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/265:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/266: # device_states.shape
201/267:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/268:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]*int(bit)
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/269:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/270: env = iotenvBinary(10)
201/271:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/272:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/273:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/274:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/275:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/276: # device_states.shape
201/277:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/278:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    
    
    
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    print("h", x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        r_human_sum += energy[1][i]*int(bit)
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/279:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/280: env = iotenvBinary(10)
201/281:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/282:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/283:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/284:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/285:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/286: # device_states.shape
201/287:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/288:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    
    
    
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    print("h", x)
    r_human_sum = 0
    for i, bit in enumerate(x) :
        
        print(energy[1][i])
        print(bit)
        
        r_human_sum += energy[1][i]*int(bit)
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/289:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/290: env = iotenvBinary(10)
201/291:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/292:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/293:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/294:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/295:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/296: # device_states.shape
201/297:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/298:
clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
201/299: energy[1][0]
201/300: energy[1][2]
201/301:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0
    
    
    
    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
        return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x) :
        
        print(i)
        print("en", energy[1][i])
        print(bit)
        
        r_human_sum += energy[1][i]*int(bit)
        return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/302:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/303: env = iotenvBinary(10)
201/304:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/305:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/306:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/307:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/308:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/309: # device_states.shape
201/310:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/311:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0

    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
    
    return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x):
        r_human_sum += energy[1][ctr]*int(bit)

    return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/312:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/313: env = iotenvBinary(10)
201/314:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/315:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/316:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/317:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/318:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/319: # device_states.shape
201/320:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/321:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0

    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
    
    return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x):
        r_human_sum += energy[1][i]*int(bit)

    return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
201/322:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
        print(rnn_state)
        print(self.state)
        print(R_human, R_energy)
        print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
201/323: env = iotenvBinary(10)
201/324:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
201/325:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
201/326:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
201/327:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
201/328:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
201/329: # device_states.shape
201/330:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
201/331:
clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
201/332:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 50 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
202/332:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
202/333: env = iotenvBinary(10)
202/334:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
202/335:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
202/336:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
203/1:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import time
import matplotlib.pyplot as plt
%matplotlib inline
203/2:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467))
energy = np.asarray(energy)
203/3: energy[1][2]
203/4:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0

    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
    
    return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x):
        r_human_sum += energy[1][i]*int(bit)

    return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
203/5:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
203/6: env = iotenvBinary(10)
203/7:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
203/8:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
203/9:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
203/10:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
203/11:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
203/12:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(2000):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 100 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/13:
# clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
203/14: device_states.shape
203/15:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/16:
# clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
203/17:
clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
203/18:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(20387):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/19:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/20: state_list
203/21: reward_list
203/22:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state.data, reward
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
203/23: env = iotenvBinary(10)
203/24:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
203/25:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
203/26:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
203/27:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
203/28:
# device_states = []
# for i in data_frame1["state"]:
#     if len(str(i)) == 10:
#         i = list(str(i))
#         i = [int(i[k]) for k in range(len(i))]
#         device_states.append(i)
# device_states = np.array(device_states)
203/29: device_states.shape
203/30:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
    
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/31:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        print(a)
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    break
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/32:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        print(a)
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        print(s_)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_
    break
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/33:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        print(a)
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        print(s_)
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_[:]
    break
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/34:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/35:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    
#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += r
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
            
    s = best_s
        
end = time.time()
203/36:
# clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
203/37: clashes
203/38:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state.data, reward, R_human, R_energy
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
203/39: env = iotenvBinary(10)
203/40:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
203/41:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
203/42:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
203/43: device_states.shape
203/44:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rh = []
re = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rh.append(hr)
        re.append(he)

    
    s = best_s[:]
        
end = time.time()
203/45:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(temp)
#     print(best_s)
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/46: reward
203/47: clashes
203/48:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    temp = s
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
    print(temp)
    print(best_s)
    print(stateXNOR(convert2str(temp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/49:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(1):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
    print(s)
    print(best_s)
    print(stateXNOR(convert2str(temp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(temp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/50:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
#     print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/51:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
    print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/52:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
#     print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/53:
np.random.seed(101)
torch.manual_seed(101)
203/54:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(203875):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
#     print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/55: plt.plot(reward)
203/56:
# clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
203/57: clashes
203/58:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
#     print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/59:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
    print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/60:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
    print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        
        if i === str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/61:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
    print(stateXNOR(convert2str(temp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        print(i)
        print(type(i))
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/62:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(2):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
    print(stateXNOR(convert2str(s), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        print(i)
        print(type(i))
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/63:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
#     print(s)
#     print(best_s)
    print(stateXNOR(convert2str(s), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        print(i)
        print(type(i))
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/64:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    
    print(s)
    print(best_s)
    print(stateXNOR(convert2str(s), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        print(i)
        print(type(i))
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/65:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s)
    print(best_s)
    print(stateXNOR(convert2str(s), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        print(i)
        print(type(i))
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/66:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s[:]
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        print(i)
        print(type(i))
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/67:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

for i_episode in range(4):
    s = env.reset() 
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s[:]
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/68:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s[:]
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/69:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s[:]
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/70:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s[:]
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_[:]
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/71:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s[:]
        
end = time.time()
203/72:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
203/73:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
203/74: state_list
204/1:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import time
import matplotlib.pyplot as plt
%matplotlib inline
204/2:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467))
energy = np.asarray(energy)
204/3: energy[1][2]
204/4:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0

    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
    
    return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x):
        r_human_sum += energy[1][i]*int(bit)

    return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
204/5:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state.data, reward, R_human, R_energy
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
204/6: env = iotenvBinary(10)
204/7:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
204/8:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
204/9:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
204/10:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
204/11:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
204/12:
np.random.seed(101)
torch.manual_seed(101)
204/13: device_states.shape
204/14:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(temp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
204/15:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i]
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(a)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
204/16:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
204/17: state_list
204/18:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(1):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        print(s_)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
204/19:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(1):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        print(s_)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(s.data)
#     print(best_s.data)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
204/20: state_list
204/21:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(1):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(s.data)
#     print(best_s.data)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
204/22: state_list
205/1:
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import random
import time
import matplotlib.pyplot as plt
%matplotlib inline
205/2:
energy = ((0.003162, 0.006850, 0.000000, 0.000000, 0.000000, 0.000000, 0.000417, 0.000583, 0.000000, 0.001767),
          (0.981883, 0.533200, 0.059717, 1.328767, 0.002550, 0.004033, 1.458150, 0.104350, 1.421250, 0.058467))
energy = np.asarray(energy)
205/3: energy[1][2]
205/4:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0

    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
    
    return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x):
        r_human_sum += energy[1][i]*int(bit)

    return r_human_sum
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
205/5:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state.data, reward, R_human, R_energy
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
205/6: env = iotenvBinary(10)
205/7:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
205/8:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
205/9:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
205/10:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
205/11:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
205/12:
np.random.seed(101)
torch.manual_seed(101)
205/13: device_states.shape
205/14:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(10):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.data
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(s.data)
#     print(best_s.data)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/15: state_list
205/16:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(10):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
        print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(s.data)
#     print(best_s.data)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/17: state_list
205/18:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(10):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(s.data)
#     print(best_s.data)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/19: state_list
205/20:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(10):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/21:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(10):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(1):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/22:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(1):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.data
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(s.data)
    print(best_s.data)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/23:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(1):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/24:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(s), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/25:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(4):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/26:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(10):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/27:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(20):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/28:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(203875):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
    print(tmp)
    print(best_s)
    print(stateXNOR(convert2str(tmp), convert2str(best_s)))
    print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
    print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/29:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(203875):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(tmp)
#     print(best_s)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        reward.append(ep_r)
        rhr.append(hr)
        rer.append(he)

    
    s = best_s.data
        
end = time.time()
205/30:
# clashes.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
205/31: clashes
205/32:
tmp = clashes[:]
tmp.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
205/33: plot(tmp)
205/34:
tmpc = clashes[:]
tmpc.sort(reverse=True)
plt.plot(clashes)
# plt.ylim(0,100)
205/35: plt.plot(tmpc)
205/36:
zx = []
for i in range(0, len(clashes), 5000):
    zx.append(clashes[i])
205/37: plt.plot(zx)
205/38: plt.plot(reward)
205/39:
t_r = reward[:]
t_r.sort()
plt.plot(t_r)
205/40:
zx.sort(reverse=True)
plt.plot(zx)
205/41: plt.plot(rhr)
205/42: plt.plot(rhe)
205/43: plt.plot(rer)
205/44:
t_r = reward[:]
t_r.sort()
plt.plot(t_r)
plt.xlabel("timestep")
plt.ylabel("reward")
205/45:
zx.sort(reverse=True)
plt.plot(zx)
plt.xlabel("timestep")
plt.ylabel("clashes")
205/46:
zx.sort(reverse=True)
plt.plot(zx)
plt.xlabel("timestep")
plt.ylabel("device mode changes")
205/47: device_states.shape
205/48: device_states[0]
205/49: r_energy(convert2str(device_states[0]))
205/50: r_human(convert2str(device_states[0]), convert2str(device_states[1]))
205/51:
def human_eval():
    
    for i in range(len(device_states)-1):
        print(i)
        break
205/52: human_eval()
205/53:
def human_eval():
    
    for i in range(len(device_states)-1):
        print(device_states[i])
        break
205/54: human_eval()
205/55: reward
205/56: len(reward)
205/57:
human_r = []
human_rh = []
human_re = []
human_clash = []
def human_eval():
    
    for i in range(0, len(device_states)-1, 5000):
        
        r_e = r_energy(convert2str(device_states[i]))
        r_h = r_human(convert2str(i), convert2str(i+1))
        
        tot = r_e + r_h
        
        
        human_r.append(tot)
        human_rh.append(r_h)
        human_re.append(r_e)
        
        clash = 0
    
        for i in stateXNOR(convert2str(i), convert2str(i+1)):
            if i == str(1):
                clash += 1
        human_clash.append(clash)
205/58: human_eval()
205/59:
human_r = []
human_rh = []
human_re = []
human_clash = []
def human_eval():
    
    for i in range(0, len(device_states)-1, 5000):
        
        r_e = r_energy(convert2str(device_states[i]))
        r_h = r_human(convert2str(device_states[i]), convert2str(device_states[i+1]))
        
        tot = r_e + r_h
        
        
        human_r.append(tot)
        human_rh.append(r_h)
        human_re.append(r_e)
        
        clash = 0
    
        for i in stateXNOR(convert2str(device_states[i]), convert2str(device_states[i+1])):
            if i == str(1):
                clash += 1
        human_clash.append(clash)
205/60: human_eval()
205/61: human_r
205/62: len(human_clash)
205/63:
plt.plot(t_r, label = "DQN")
plt.plot(human_r, label= "Human")
plt.legend()
205/64:
plt.plot(t_r, label = "DQN")
plt.plot(human_r, label= "Human")
plt.xlabel("Time step")
plt.ylabel("Reward")
plt.legend()
205/65:
plt.plot(t_r, label = "DQN")
plt.plot(human_r, label= "Human")
plt.xlabel("Time step")
plt.ylabel("Total Reward")
plt.legend()
205/66: human_clash
205/67:
plt.plot(rhr, label = "DQN")
plt.plot(human_rh, label= "Human")
plt.xlabel("Time step")
plt.ylabel("Total Reward")
plt.legend()
205/68:
t_rhr = rhr[:]
t_rhr.sort()
205/69:
plt.plot(t_rhr, label = "DQN")
plt.plot(human_rh, label= "Human")
plt.xlabel("Time step")
plt.ylabel("Total Reward")
plt.legend()
205/70:
plt.plot(t_rhr, label = "DQN")
plt.plot(human_rh, label= "Human")
plt.xlabel("Time step")
plt.ylabel("R-human Reward")
plt.legend()
205/71:
t_rer = rer[:]
t_rer.sort()
205/72:
plt.plot(t_rer, label = "DQN")
plt.plot(human_re, label= "Human")
plt.xlabel("Time step")
plt.ylabel("R-human Reward")
plt.legend()
205/73:
human_r = []
human_rh = []
human_re = []
human_clash = []
def human_eval():
    
    for i in range(0, len(device_states)-1):
        
        r_e = r_energy(convert2str(device_states[i]))
        r_h = r_human(convert2str(device_states[i]), convert2str(device_states[i]))
        
        tot = r_e + r_h
        
        
        human_r.append(tot)
        human_rh.append(r_h)
        human_re.append(r_e)
        
        clash = 0
    
        for i in stateXNOR(convert2str(device_states[i]), convert2str(device_states[i+1])):
            if i == str(1):
                clash += 1
        human_clash.append(clash)
205/74: human_eval()
205/75: len(human_clash)
205/76: len(t_r)
205/77:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(203875):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(tmp)
#     print(best_s)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 5000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        

    
    s = best_s.data.clone()
    reward.append(ep_r)
    rhr.append(hr)
    rer.append(he)
        
end = time.time()
205/78:
t_reward = reward[:]
t_reward.sort()
205/79: len(human_r)
205/80: len(reward)
205/81: len(reward[1:])
205/82:
plt.figure(figsize=(10,7))
plt.plot(reward[1:], label = "DQN")
plt.plot(human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.legend()
205/83:
plt.figure(figsize=(10,7))
plt.plot(reward[1:], label = "DQN")
plt.plot(human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/84:
t_reward = reward[1:]
t_reward.sort()
205/85:
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/86:
t_human_r = human_r[:]
t_human_r.sort()
205/87:
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/88:
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step", font_size = "20")
plt.ylim(-10,10)
plt.legend()
205/89:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step", font_size = "20")
plt.ylim(-10,10)
plt.legend()
205/90:
# plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step", labelsize = "20")
plt.ylim(-10,10)
plt.legend()
205/91:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/92:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
# plt.ylim(-10,10)
plt.legend()
205/93:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/94:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(reward[1:], label = "DQN")
plt.plot(human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/95: len(human_rh)
205/96: len(rhr)
205/97:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(rhr[1:], label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/98:
t_rhr = rhr[1:]
t_rhr.sort()
205/99:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rhr, label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/100: len(human_re)
205/101: len(rer)
205/102:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(rer[1:], label = "DQN")
plt.plot(human_re, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/103:
t_human_re = human_re[:]
t_human_re.sort(reversed=True)
205/104:
t_human_re = human_re[:]
t_human_re.sort(reverse=True)
t_rer = rer[1:]
t_rer.sort()
205/105:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rer, label = "DQN")
plt.plot(t_human_re, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/106: len(human_clash)
205/107: len(clashes)
205/108:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(clashes[1:], label = "DQN")
plt.plot(human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/109:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(clashes[1:], label = "DQN")
plt.plot(human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/110:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.sca(clashes[1:], label = "DQN")
plt.scatter(human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/111:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.scatter(clashes[1:], label = "DQN")
plt.scatter(human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/112:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(clashes[1:], label = "DQN")
plt.plot(human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/113:
t_human_clash = human_clash[:]
t_human_clash
205/114:
t_human_clash = human_clash[:]
t_clashes = clashes[1:]
205/115:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_clashes, label = "DQN")
plt.plot(t_human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/116:
t_human_clash = human_clash[:]
t_clashes = clashes[1:]
t_clashes.sort()
205/117:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_clashes, label = "DQN")
plt.plot(t_human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/118:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(15,7))
plt.plot(t_clashes, label = "DQN")
plt.plot(t_human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/119:
human_r = []
human_rh = []
human_re = []
human_clash = []
def human_eval():
    
    for i in range(0, len(device_states)-1):
        
        r_e = r_energy(convert2str(device_states[i]))
        r_h = r_human(convert2str(device_states[i]), convert2str(device_states[i]))
        
        tot = r_e + r_h
        
        
        human_r.append(tot)
        human_rh.append(r_h)
        human_re.append(r_e)
        
        clash = 0
    
        for i in stateXNOR(convert2str(device_states[i]), convert2str(device_states[i])):
            if i == str(1):
                clash += 1
        human_clash.append(clash)
205/120: human_eval()
205/121:
t_human_clash = human_clash[:]
t_clashes = clashes[1:]
t_clashes.sort()
205/122:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(15,7))
plt.plot(t_clashes, label = "DQN")
plt.plot(t_human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/123:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_clashes, label = "DQN")
plt.plot(t_human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/124:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(203875):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(tmp)
#     print(best_s)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 2000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        

    
    s = best_s.data.clone()
    reward.append(ep_r)
    rhr.append(hr)
    rer.append(he)
        
end = time.time()
205/125:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rhr, label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Total human reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/126:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rhr, label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Human reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/127: t_human_re.sort()
205/128:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rer, label = "DQN")
plt.plot(t_human_re, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/129:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rer, label = "DQN")
plt.plot(t_human_re, label = "Human")
plt.ylabel("Energy reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/130:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(rhr[1:], label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/131:
# Environment

def randomGenerateState(numD):
    res = ""
    for x in range(numD) :
        if random.random() > 0.5 :
            res+= "1"
        else :
            res+= "0"
    res = list(res)
    res = [int(i) for i in res]
    res = np.array(res)
    return torch.Tensor(res)

def stateXOR(f,g):
    y = int(f, 2)^int(g,2)
    return bin(y)[2:].zfill(len(f))

xnor_map = {('0', '1'): '0', ('1', '0'): '0', ('1', '1'): '1', ('0', '0'): '1'}

def stateXNOR(str1, str2):
    return ''.join([xnor_map[a, b] for a, b in zip(str1, str2)])

def r_energy(state_str):
    r_energy_sum = 0

    for i, bit in enumerate(state_str):
        r_energy_sum += energy[int(bit)][i]*int(bit)
    
    return -r_energy_sum
    
    
def r_human(state_str1, state_str2) :
    x = stateXNOR(state_str1, state_str2)
    
    r_human_sum = 0
    for i, bit in enumerate(x):
        r_human_sum += energy[1][i]*int(bit)

    return r_human_sum * 0.5
    
def convert2str(state):
    p = ""
    for i in state:
        i = str(int(i))
        p += i
    return p
205/132:
#return tensors as outputs and convert inputs into strings

class iotenvBinary :
    def __init__(self,numD,biasHuman=0.4) :
        self.numD = numD # no. of binary digits/ devices
        self.state = randomGenerateState(numD)
        self.biasHuman = biasHuman
        
        
    def step(self, s, action_index, rnn_state):
    
        self.state = s
        self.prev = self.state

            
        self.state.data[action_index] = torch.tensor(1) - self.state.data[action_index]
        
        

        R_human = r_human(convert2str(rnn_state), convert2str(self.state))
        R_energy = r_energy(convert2str(self.state))
        
#         print(rnn_state)
#         print(self.state)
#         print(R_human, R_energy)
#         print("--------------")
        
        reward = R_human + R_energy    
    
        return self.state.data, reward, R_human, R_energy
    
#     def get_reward(self, rnn_state):
    
#         dqn_prev_state = self.prev
#         dqn_curr_state = self.state
        
#         print("p", dqn_prev_state)
#         print("c", dqn_curr_state)
#         print("r", rnn_state)

#         print("----------------------")

#         R_human = r_human(convert2str(rnn_state), convert2str(dqn_curr_state))
#         R_energy = r_energy(convert2str(dqn_curr_state))

#     #     print(R_human, R_energy)

#         reward = R_human + R_energy
#         return reward  
    
    def reset(self):
        return randomGenerateState(self.numD)
        
        # self.prev 
        
    def render(self) :
        pass
205/133: env = iotenvBinary(10)
205/134:
# HyperParameters
BATCH_SIZE = 2**4
LR = 0.01
EPSILON = 0.9
GAMMA = 0.9
TARGET_REPLACE_ITER = 100
MEMORY_CAPACITY = 2000000
# env = env.unwrapped
# N_ACTIONS = env.action_space.n
# N_STATES = env.observation_space.shape[0]
# ENV_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape

N_ACTIONS = 10
N_STATES = 2**8
ENV_SHAPE = (N_STATES,1)
205/135:
# Neural Network

class Net(nn.Module):
    
    def __init__(self, ):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 50)
        self.fc1.weight.data.normal_(0, 0.1)
        self.out = nn.Linear(50, N_ACTIONS)
        self.out.weight.data.normal_(0, 0.1)
        
    def forward(self, x):
        x = self.fc1(x)
        x = F.relu(x)
        actions_value = self.out(x)
        return actions_value
205/136:
# DQN

class DQN(object):
    
    def __init__(self):
        self.eval_net, self.target_net = Net(), Net()
        self.learn_step_counter = 0
        self.memory_counter = 0
        self.memory = np.zeros((MEMORY_CAPACITY, 22))
        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr = LR)
        self.loss_func = nn.MSELoss()
        
    
    def choose_action(self, x):        
        if np.random.uniform() < EPSILON:
            
            actions_value = self.eval_net.forward(x)
            
            
            val, ind = torch.max(actions_value, 0)
            
            
#             action = action if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
#         else:
#             action = np.random.randint(0, N_ACTIONS)
#             action = action[0] if ENV_SHAPE == 0 else action.reshape(ENV_SHAPE)
            return ind
    
    def store_transitions(self, s, a, r, s_):
        transition = np.hstack((s, [a,r], s_))
        index = self.memory_counter % MEMORY_CAPACITY
        
        self.memory[index, :] = transition
        self.memory_counter += 1
        
    def learn(self):
        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:
            self.target_net.load_state_dict(self.eval_net.state_dict())
        self.learn_step_counter += 1

        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)
        b_memory = self.memory[sample_index, :]
        b_s = torch.FloatTensor(b_memory[:, :N_STATES])
        b_a = torch.LongTensor(b_memory[:, :N_STATES:N_STATES+1].astype(int))
        b_r = torch.FloatTensor(b_memory[:, :N_STATES+1:N_STATES+2])
        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])
        
        q_eval = self.eval_net(b_s).gather(1, b_a)
        q_next = self.target_net(b_s_).detach
        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)
        loss = self.loss_func(q_eval, q_target)
        
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
    def save_model(self, eval_name = 'eval_net', train_name = 'train_net'):
        torch.save(self.eval_net.state_dict(), self.PATH  + str(N_STATES) + eval_name)
        torch.save(self.target_net.state_dict(), self.PATH  + str(N_STATES)+ train_name)
        
    def load_model(self, eval_name = 'eval_net.m', train_name = 'train_net.m'):
        self.eval_net.load_state_dict(torch.load(self.PATH +  str(N_STATES) + eval_name))
        self.target_net.load_state_dict(torch.load(self.PATH  + str(N_STATES) + train_name))
205/137:
data_frame = pd.read_csv('../lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
205/138:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
205/139:
np.random.seed(101)
torch.manual_seed(101)
205/140: device_states.shape
205/141:
# Run DQN

start = time.time()
dqn = DQN()
print("Start")
print('\nCollecting experience...')

clashes = []
reward = []
rhr = []
rer = []

s = env.reset() 

for i_episode in range(203875):
    ep_r = 0
    hr = 0
    he = 0
    
    tmp = s.clone()
    state_list = []
    reward_list = []
    rh_list = []
    re_list = []
    
    for i_timestamp in range(10):    
        a = dqn.choose_action(s)
        
        rnn_state = device_states[i_episode]   
        s_, r, rh, re = env.step(s, a, rnn_state)
#         print(s_.data)
        
        state_list.append(s_.data)
        reward_list.append(r)
        rh_list.append(rh)
        re_list.append(re)

        s = s_.clone()
    
    
    best_r, best_i = torch.max(torch.Tensor(reward_list), 0)
    best_s = state_list[best_i].data
    best_rh = rh_list[best_i]
    best_re = re_list[best_i]

#     print(best_r, best_i, best_s)
#     print(tmp)
#     print(best_s)
#     print(stateXNOR(convert2str(tmp), convert2str(best_s)))
#     print("--------")
    clash = 0
    
    for i in stateXNOR(convert2str(tmp), convert2str(best_s)):
        if i == str(1):
            clash += 1
#     print(clash)
    clashes.append(clash)
    
    dqn.store_transitions(tmp, best_i, best_r, best_s)

    ep_r += best_r
    hr += best_rh
    he += best_re
        
    if dqn.memory_counter > MEMORY_CAPACITY: 
        dqn.learn()

    if(i_episode % 2000 == 0):
        print('Ep: ', i_episode,'| Ep_r: ', round(ep_r, 2))  
        

    
    s = best_s.data.clone()
    reward.append(ep_r)
    rhr.append(hr)
    rer.append(he)
        
end = time.time()
205/142:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(reward[1:], label = "DQN")
plt.plot(human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/143:
t_reward = reward[1:]
t_reward.sort()
205/144:
t_human_r = human_r[:]
t_human_r.sort()
205/145:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_reward, label = "DQN")
plt.plot(t_human_r, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/146:
t_rhr = rhr[1:]
t_rhr.sort()
205/147:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(rhr[1:], label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/148:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rhr, label = "DQN")
plt.plot(human_rh, label = "Human")
plt.ylabel("Human reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/149: len(human_re)
205/150: len(rer)
205/151:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(rer[1:], label = "DQN")
plt.plot(human_re, label = "Human")
plt.ylabel("Total reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/152: t_human_re = human_re[:]
205/153: t_human_re.sort()
205/154:
t_rer = rer[1:]
t_rer.sort()
205/155:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_rer, label = "DQN")
plt.plot(t_human_re, label = "Human")
plt.ylabel("Energy reward")
plt.xlabel("Time step")
plt.ylim(-10,10)
plt.legend()
205/156:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(clashes[1:], label = "DQN")
plt.plot(human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
205/157:
t_human_clash = human_clash[:]
t_clashes = clashes[1:]
t_clashes.sort()
205/158:
plt.rcParams.update({'font.size': 22})
plt.figure(figsize=(10,7))
plt.plot(t_clashes, label = "DQN")
plt.plot(t_human_clash, label = "Human")
plt.ylabel("# of matches")
plt.xlabel("Time step")
plt.legend()
207/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
208/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
209/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
210/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
211/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
212/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
213/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
214/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
214/2: import torchvision
214/3: import torch
214/4: import torchvision
215/1: import torchvision
216/1:
import logging
logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
215/2: !which python
217/1: import torchvision
219/1: import torchvision
220/1: import torchvision
220/2: !pip3 install torchvision
220/3: import torchvision
221/1: import torchvision
222/1: import torchvision
222/2:
import torch
import torchvision
223/1:
import torch
import torchvision
223/2:
import torch
import torchvision
224/1:
import torch
import torchvision
224/2:
import torch
import torchvision
224/3: !pip install pytorch
224/4: !pip install torch
224/5:
import torch
import torchvision
224/6: !pip install torchvision
225/1:
import torch
import torchvision
225/2: torchvision.maakabhosda
226/1:
# import logging
# logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
# logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
226/2:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
227/1:
# import logging
# logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
# logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
228/1:
# import logging
# logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
# logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
228/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s02_l02/'
adv_image_path = '../../../FGSM Attack/s02_l02'
228/3:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


            if adversary.is_successful():
                print(
                    'attack success, adversarial_label=%d'
                    % (adversary.adversarial_label))

                adv=adversary.adversarial_example[0]

            else:
                print('attack failed')


            print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')

            cv2.imwrite(save_fname, adv)
228/4: perturb_images(image_path)
230/1: import torchvision
231/1:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb   
            
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

#             print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

#             if adversary.is_successful():
#                 print(
#                     'attack success, adversarial_label=%d'
#                     % (adversary.adversarial_label))

#                 adv=adversary.adversarial_example[0]

#             else:
#                 print('attack failed')


#             print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')
            
            print(save_fname)

            cv2.imwrite(save_fname, adv)
232/1:
# import logging
# logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
# logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.deepfool import DeepFoolAttack
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
232/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s02_l02/'
adv_image_path = '../../../DeepFool Attack/s02_l02'
232/3:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb   
            
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

#             print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

#             if adversary.is_successful():
#                 print(
#                     'attack success, adversarial_label=%d'
#                     % (adversary.adversarial_label))

#                 adv=adversary.adversarial_example[0]

#             else:
#                 print('attack failed')


#             print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')
            
            print(save_fname)

            cv2.imwrite(save_fname, adv)
232/4: perturb_images(image_path)
232/5:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def perturb_images(image_path):
    for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            print(src_fname)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]
            
            #cv2bgr bgr -> rgb   
            
            #224*224
            orig = cv2.resize(orig, (224, 224))
            adv=None
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)

            #DeepFool 
            attack = DeepFoolAttack(m)
            attack_config = {"iterations": 100, "overshoot": 0.02}

            inputs=img
            labels = None

#             print(inputs.shape)

            adversary = Adversary(inputs, labels)

            #
            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)

#             if adversary.is_successful():
#                 print(
#                     'attack success, adversarial_label=%d'
#                     % (adversary.adversarial_label))

#                 adv=adversary.adversarial_example[0]

#             else:
#                 print('attack failed')


#             print("deepfool attack done")
            
            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')
            
            print(save_fname)

            cv2.imwrite(save_fname, adv)
232/6: # show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
232/7: perturb_images(image_path)
229/1:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            print(src_fname)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


#             if adversary.is_successful():
#                 print(
#                     'attack success, adversarial_label=%d'
#                     % (adversary.adversarial_label))

#                 adv=adversary.adversarial_example[0]

#             else:
#                 print('attack failed')


#             print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')
            
            print(save_fname)

            cv2.imwrite(save_fname, adv)
233/1:
# import logging
# logging.basicConfig(level=logging.INFO,format="%(filename)s[line:%(lineno)d] %(levelname)s %(message)s")
# logger=logging.getLogger(__name__)

import torch
import torchvision
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.utils.data.dataloader as Data
import torch.nn as nn
from torchvision import models
import sys
sys.path.insert(0, '../')
from tools import show_images_diff
from advbox.adversary import Adversary
from advbox.attacks.gradient_method import FGSMT
from advbox.attacks.gradient_method import FGSM
from advbox.models.pytorch import PytorchModel
import numpy as np
import cv2
import os
233/2:
image_path = '../../../2017-IWT4S-CarsReId_LP-dataset/s01_l01/'
adv_image_path = '../../../FGSM Attack/s01_l01'
233/3:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            print(src_fname)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

            print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)


#             if adversary.is_successful():
#                 print(
#                     'attack success, adversarial_label=%d'
#                     % (adversary.adversarial_label))

#                 adv=adversary.adversarial_example[0]

#             else:
#                 print('attack failed')


#             print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')
            
            print(save_fname)

            cv2.imwrite(save_fname, adv)
233/4: perturb_images(image_path)
233/5:
# logging.info("CUDA Available: {}".format(torch.cuda.is_available()))
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

#cv2bgr bgr -> rgb  
def perturb_images(image_path):
        for filename in os.listdir(image_path):
            src_fname, ext = os.path.splitext(filename)
            print(src_fname)
            orig = cv2.imread(os.path.join(image_path, filename))[..., ::-1]

    # orig = cv2.imread(image_path)[..., ::-1]
    #224*224
            orig = cv2.resize(orig, (224, 224))
            img = orig.copy().astype(np.float32)

            #
            mean = [0.485, 0.456, 0.406]
            std = [0.229, 0.224, 0.225]
            img /= 255.0
            img = (img - mean) / std

            #pytorchCHW  
            #[224,224,3]->[3,224,224]
            img = img.transpose(2, 0, 1)

            img = Variable(torch.from_numpy(img).to(device).float().unsqueeze(0)).cpu().numpy()


            # Initialize the network
            #Alexnet
            model = models.alexnet(pretrained=True).to(device).eval()

            #print(model)

            # 
            for param in model.parameters():
                param.requires_grad = False

            # advbox demo
            m = PytorchModel(
                model, None,(-3, 3),
                channel_axis=1)
            attack = FGSMT(m)

            # epsilons
            attack_config = {"epsilons": 0.001, "epsilon_steps": 1, "steps": 100}

            inputs=img
            labels = None

#             print(inputs.shape)

            adversary = Adversary(inputs, labels)

            tlabel = 538
            adversary.set_target(is_targeted_attack=True, target_label=tlabel)


            adversary = attack(adversary, **attack_config)
            
            adv = adversary.adversarial_example[0]


#             if adversary.is_successful():
#                 print(
#                     'attack success, adversarial_label=%d'
#                     % (adversary.adversarial_label))

#                 adv=adversary.adversarial_example[0]

#             else:
#                 print('attack failed')


#             print("fgsm attack done")

            adv = adv.transpose(1, 2, 0)
            adv = (adv * std) + mean
            adv = adv * 256.0
            adv = np.clip(adv, 0, 255).astype(np.uint8)

#             show_images_diff(orig,adversary.original_label,adv,adversary.adversarial_label)
            
            save_fname = os.path.join(adv_image_path, os.path.basename(src_fname)+'.png')
            
            print(save_fname)

            cv2.imwrite(save_fname, adv)
233/6: perturb_images(image_path)
241/1:
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt
241/2:
epsilons = [0, .05, .1, .15, .2, .25, .3]
pretrained_model = "lenet_mnist_model.pth"
use_cuda=True
241/3:
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
241/4:
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([
            transforms.ToTensor(),
            ])),
        batch_size=1, shuffle=True)
241/5:
print("CUDA Available: ",torch.cuda.is_available())
device = torch.device("cuda" if (use_cuda and torch.cuda.is_available()) else "cpu")
241/6: model = Net().to(device)
241/7: model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))
241/8: model.eval()
241/9:
def fgsm_attack(image, epsilon, data_grad):
    sign_data_grad = data_grad.sign()
    perturbed_image = image + epsilon * sign_data_grad
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image
241/10:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        output = model(data)
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
241/11:
accuracies = []
examples = []

for eps in epsilons:
    acc, ex = test(model, device, test_loader, eps)
    accuracies.append(acc)
    examples.append(ex)
241/12:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        print("Data: ", data)
        
        output = model(data)
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
241/13:
i = 0
accuracies1 = []
examples1 = []
while(i < 50):
    acc, ex = test(model, device, test_loader, 0.25)
    accuracies1.append(acc)
    examples1.append(ex)
241/14:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        print(data.shape)
        
        output = model(data)
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
241/15:
i = 0
accuracies1 = []
examples1 = []
while(i < 5):
    acc, ex = test(model, device, test_loader, 0.25)
    accuracies1.append(acc)
    examples1.append(ex)
241/16:
i = 0
accuracies1 = []
examples1 = []
while(i < 5):
    acc, ex = test(model, device, test_loader, 0.25)
    accuracies1.append(acc)
    examples1.append(ex)
    i += 1
241/17:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        output = model(data)
        
        print(output.shape)
        
        init_pred = output.max(1, keepdim = True)[1]
        
        print(init_pred)
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
241/18:
i = 0
accuracies1 = []
examples1 = []
while(i < 5):
    acc, ex = test(model, device, test_loader, 0.25)
    accuracies1.append(acc)
    examples1.append(ex)
    i += 1
241/19:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        output = model(data)
        
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        print(loss)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
241/20:
i = 0
accuracies1 = []
examples1 = []
while(i < 5):
    acc, ex = test(model, device, test_loader, 0.25)
    accuracies1.append(acc)
    examples1.append(ex)
    i += 1
241/21:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        output = model(data)
        
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        print(perturbed_data)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
241/22:
i = 0
accuracies1 = []
examples1 = []
while(i < 5):
    acc, ex = test(model, device, test_loader, 0.25)
    accuracies1.append(acc)
    examples1.append(ex)
    i += 1
241/23:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        
        output = model(data)
        
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
        
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            if(epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    final_acc = correct/float(len(test_loader))
    print("Epsilon: {}\tTest Accuracy = {} / {} = {}".format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
243/1: train_loss
243/2:
import torch
from torch import nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler
%matplotlib inline
torch.set_printoptions(precision=4)
243/3:
plt.figure(figsize=(8,5))

# how many time steps/data pts are in one batch of data
seq_length = 20

# generate evenly spaced data pts
time_steps = np.linspace(0, np.pi, seq_length + 1)
data = np.sin(time_steps)
data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension

x = data[:-1] # all but the last piece of data
y = data[1:] # all but the first
243/4: # splitting the dataser
243/5:
# display the data
plt.plot(time_steps[1:], x, 'r.', label='input, x') # x
plt.plot(time_steps[1:], y, 'b.', label='target, y') # y

plt.legend(loc='best')
plt.show()
243/6:
data_frame = pd.read_csv('lstm_data_binary.csv')
data_frame = data_frame.drop(['Unnamed: 0'], axis = 1)
data_frame1 = data_frame.drop(['index'], axis = 1)
243/7: data_frame1.head()
243/8:
device_states = []
for i in data_frame1["state"]:
    if len(str(i)) == 10:
        i = list(str(i))
        i = [int(i[k]) for k in range(len(i))]
        device_states.append(i)
device_states = np.array(device_states)
243/9:
# Creating data indices for training and validation splits:
validation_split = 0.3
batch_size = 100
dataset_size = len(device_states)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))

train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size, 
                                           sampler=train_sampler)
validation_loader = torch.utils.data.DataLoader(device_states, batch_size=batch_size,
                                                sampler=valid_sampler)
243/10:
class RNN(nn.Module):
    def __init__(self, input_size, output_size, hidden_dim, n_layers):
        super(RNN, self).__init__()
        
        self.hidden_dim=hidden_dim

        # define an RNN with specified parameters
        # batch_first means that the first dim of the input and output will be the batch_size
        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)
        
        # last, fully-connected layer
        self.fc = nn.Linear(hidden_dim, output_size)

    def forward(self, x, hidden):
        # x (batch_size, seq_length, input_size)
        # hidden (n_layers, batch_size, hidden_dim)
        # r_out (batch_size, time_step, hidden_size)
        batch_size = x.size(0)
        
        # get RNN outputs
        r_out, hidden = self.rnn(x, hidden)
        # shape output to be (batch_size*seq_length, hidden_dim)
        r_out = r_out.view(-1, self.hidden_dim)  
        
        # get final output 
        output = self.fc(r_out)
        
        return output, hidden
243/11:
# test that dimensions are as expected
test_rnn = RNN(input_size=10, output_size=10, hidden_dim=10, n_layers=2)
243/12:
# generate evenly spaced, test data pts
device_states.shape
243/13:
test_input = torch.Tensor(device_states).unsqueeze(0) # give it a batch_size of 1 as first dimension
print('Input size: ', test_input.size())
243/14:
# test out rnn sizes
test_out, test_h = test_rnn(test_input, None)
print('Output size: ', test_out.size())
print('Hidden state size: ', test_h.size())
243/15:

# decide on hyperparameters
input_size=10 
output_size=10
hidden_dim=64
n_layers=2

# instantiate an RNN
rnn = RNN(input_size, output_size, hidden_dim, n_layers)
print(rnn)
243/16:
# MSE loss and Adam optimizer with a learning rate of 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)
global_hidden = np.array([])
243/17: device_states.shape
243/18: next(iter(train_loader)).shape
243/19:
train_loss = []
test_loss = []
hidden_state = []
epochs = 20
243/20:
for epoch in range(epochs):
    train = 0
    # initialize the hidden state
    hidden = None
    
    for data in train_loader:
        # defining the training data 
        x = data[:-1]
        y = data[1:]
        
        x = x.type("torch.FloatTensor")
        y = y.type("torch.FloatTensor")

        # convert data into Tensors
        
        x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
        y_tensor = torch.Tensor(y)

        # outputs from the rnn
        prediction, hidden = rnn(x_tensor, hidden)

        ## Representing Memory ##
        # make a new variable for hidden and detach the hidden state from its history
        # this way, we don't backpropagate through the entire history
        hidden = hidden.data

        # calculate the loss
        loss = criterion(prediction, y_tensor)
        
        train += loss.item()
    
        # zero gradients
        optimizer.zero_grad()
        # perform backprop and update weights
        loss.backward()
        optimizer.step()
        
    else:
        train_loss.append(train/len(train_loader))
        test = 0
        with torch.no_grad():
            for data in validation_loader:
                x = data[:-1]
                y = data[1:]
                
                x = x.type("torch.FloatTensor")
                y = y.type("torch.FloatTensor")
                x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension
                y_tensor = torch.Tensor(y)

                # outputs from the rnn
                prediction, hidden = rnn(x_tensor, hidden)

                ## Representing Memory ##
                # make a new variable for hidden and detach the hidden state from its history
                # this way, we don't backpropagate through the entire history
                hidden = hidden.data

                # calculate the loss
                test += criterion(prediction, y_tensor)
        test_loss.append(test/len(validation_loader))
        
        print("======================EPOCH {}==========================".format(epoch))
        print(" Training loss: {}, Testing loss: {}".format(train/len(train_loader),test/len(validation_loader) ))
        torch.save(rnn.state_dict(), "./checkpoints/checkpoint_{}".format(epoch))
243/21: train_loss
243/22: plt.plot(train_loss)
243/23:
plt.plot(train_loss)
plt.plot(test_loss)
243/24:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.legend()
243/25:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0,1)
plt.legend()
243/26:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0,01)
plt.legend()
243/27:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0,0.01)
plt.legend()
243/28:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0,0.1)
plt.legend()
243/29:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.2,0.1)
plt.legend()
243/30:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.2,0.1)
plt.legend()
243/31:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
plt.legend()
243/32:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
plt.ylim(0,20)
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend()
243/33:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
plt.xlim(0,20)
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend()
243/34:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
plt.xlim(0,19)
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend()
243/35:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
# plt.xlim(0,19)
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend()
243/36:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
# plt.xlim(0,19)
plt.ylabel("Loss")
plt.xlabel("Epochs", font_size = 20)
plt.legend()
243/37:
plt.plot(train_loss, label = "Train")
plt.plot(test_loss, label="Test")
plt.ylim(0.02,0.1)
# plt.xlim(0,19)
plt.ylabel("Loss")
plt.xlabel("Epochs")
plt.legend()
244/1:
import pandas as pd
import numpy as np
244/2: dataset = pd.read_csv('../EPIC_2018/Scenario 1/EpicLog_Scenario 1_19_Oct_2018_14_44.csv')
244/3: dataset.head()
244/4: dataset.desc()
244/5: dataset.desc
244/6: dataset.describe
244/7: dataset.describe()
244/8: dataset.shape()
244/9: dataset.shape
244/10: dataset.columns
244/11: list(dataset.columns)
247/1: import pretrainedmodels
247/2: import pretrainedmodels
247/3: import pytorch
247/4: import numpy
249/1: import pretrainedmodels
249/2: import pytorch
249/3: print(pretrainedmodels.model_names)
249/4:
model_name = 'alexnet' # could be fbresnet152 or inceptionresnetv2
model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')
model.eval()
249/5:
import torch
import pretrainedmodels.utils as utils

load_img = utils.LoadImage()

tf_img = utils.TransformImage(model)
250/1:
import torch
import torchvision
import torchvision.transforms as transforms
250/2:
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)

testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
250/3:
import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
    
dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
250/4:
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
    
dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
250/5:
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
250/6:
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
250/7:
for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
250/8:
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Assuming that we are on a CUDA machine, this should print a CUDA device:

print(device)
250/9: net.to(device)
250/10: inputs, labels = data[0].to(device), data[1].to(device)
250/11:
for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
250/12:
for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net.to(device)(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
251/1: import pandas as pd
251/2:
traffic_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv')
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
251/3: traffic_data.shape
251/4: tor_nontor_data.shape
251/5: traffic_data.columns
251/6: tor_nontor_data.columns
251/7: traffic_data['label'].value_counts
251/8: traffic_data['label'].value_counts()
251/9: tor_nontor_data['label'].value_counts()
251/10: traffic_data.info()
251/11: tor_nontor_data.info()
251/12: len(traffic_data['Source IP'].unique().tolist())
251/13: len(traffic_data[' Active Max'].unique().tolist())
251/14: len(traffic_data[' Flow Bytes/s'].unique().tolist())
251/15: len(traffic_data[' Flow Duration'].unique().tolist())
251/16: len(traffic_data[' Flow Bytes/s'].unique().tolist())
251/17: len(traffic_data[' Flow IAT Max'].unique().tolist())
251/18: len(traffic_data[' Flow IAT Min'].unique().tolist())
251/19: len(traffic_data[' Idle Std'].unique().tolist())
251/20: len(traffic_data[' Idle Max'].unique().tolist())
251/21: len(traffic_data[' Idle Min'].unique().tolist())
251/22:
for i in traffic_data.columns:
    print("i:" + len(traffic_data.i.unique().tolist()))
251/23:
for col in traffic_data.columns:
    print("col:" + len(traffic_data.col.unique().tolist()))
251/24:
for col in traffic_data.columns():
    print("col:" + len(traffic_data.col.unique().tolist()))
251/25:
for col in traffic_data:
    print("col:" + len(traffic_data.col.unique().tolist()))
251/26:
for col in traffic_data:
    print("col:" + len(traffic_data[col].unique().tolist()))
251/27:
for col in traffic_data:
    print("col:" + len(traffic_data['col'].unique().tolist()))
251/28:
for col in traffic_data:
    print("col:" + len(col.unique().tolist()))
252/1: import pandas as pd
252/2:
traffic_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv')
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
252/3: traffic_data.shape
252/4: tor_nontor_data.shape
252/5: traffic_data.columns
252/6: tor_nontor_data.columns
252/7: traffic_data['label'].value_counts()
252/8: tor_nontor_data['label'].value_counts()
252/9: traffic_data.info()
252/10: tor_nontor_data.info()
252/11:
for col in traffic_data:
    print("col:" + len(col.unique().tolist()))
252/12:
for col in traffic_data:
    print(traffic_data[col])
252/13:
for name, values in traffic_data.iteritems():
     print('{name}: {value}'.format(name=name, value=values[0]))
252/14:
for col in traffic_data:
    print("col:" + len(traffic_data[col].unique().tolist()))
252/15:
for col in traffic_data:
    print("col:", len(traffic_data[col].unique().tolist()))
252/16:
for col in traffic_data:
    print(traffic_data[col]": ", len(traffic_data[col].unique().tolist()))
252/17:
for col in traffic_data:
    print(traffic_data[col]": ", len(traffic_data[col].unique().tolist()))
252/18:
for col in traffic_data:
    print(traffic_data[col]": "len(traffic_data[col].unique().tolist()))
252/19:
for col in traffic_data:
    print(traffic_data[col]+ ": " + len(traffic_data[col].unique().tolist()))
252/20:
for col in traffic_data:
    print(traffic_data[col]+ ": " + str(len(traffic_data[col].unique().tolist()))
252/21:
for col in traffic_data:
    print(traffic_data[col]+ ": " + str(len(traffic_data[col].unique().tolist())))
252/22:
for col in traffic_data.columns:
    print(traffic_data[col]+ ": " + str(len(traffic_data[col].unique().tolist())))
252/23:
for index,row in traffic_data.iterrows():
    print(row.index)
252/24:
for index,row in traffic_data.iterrows():
    print(row.index[i])
252/25:
for index,row in traffic_data.iterrows():
    print(row.index[0])
252/26:
for index,row in traffic_data.iterrows():
    print(row[0].index)
252/27:
for index,row in traffic_data.iterrows():
    print(row[1].index)
252/28:
for index,row in traffic_data.iterrows():
    for i in range(30):
        print(row.index[i])
252/29:
for index,row in traffic_data.iterrows():
    for i in range(30):
        print(row.index[i].unique())
252/30:
for index,row in traffic_data.iterrows():
    for i in range(30):
        print(row.index[i])
252/31:
for index,row in traffic_data.iterrows():
    for i in range(29):
        print(row.index[i])
252/32:
len(traffic_data[' Active Max'].unique().tolist())
len(traffic_data[' Active Min'].unique().tolist())
len(traffic_data[' Active Std'].unique().tolist())
len(traffic_data[' Bwd IAT Max'].unique().tolist())
len(traffic_data[' Bwd IAT Min'].unique().tolist())
len(traffic_data[' Bwd IAT Std'].unique().tolist())
len(traffic_data[' Flow Bytes/s'].unique().tolist())
len(traffic_data[' Flow Duration'].unique().tolist())
len(traffic_data[' Flow IAT Max'].unique().tolist())
len(traffic_data[' Flow IAT Mean'].unique().tolist())
len(traffic_data[' Flow IAT Min'].unique().tolist())
len(traffic_data[' Fwd IAT Std'].unique().tolist())
252/33:
print(len(traffic_data[' Active Max'].unique().tolist())
len(traffic_data[' Active Min'].unique().tolist())
len(traffic_data[' Active Std'].unique().tolist())
len(traffic_data[' Bwd IAT Max'].unique().tolist())
len(traffic_data[' Bwd IAT Min'].unique().tolist())
len(traffic_data[' Bwd IAT Std'].unique().tolist())
len(traffic_data[' Flow Bytes/s'].unique().tolist())
len(traffic_data[' Flow Duration'].unique().tolist())
len(traffic_data[' Flow IAT Max'].unique().tolist())
len(traffic_data[' Flow IAT Mean'].unique().tolist())
len(traffic_data[' Flow IAT Min'].unique().tolist())
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
252/34:
print(len(traffic_data[' Active Max'].unique().tolist()),
len(traffic_data[' Active Min'].unique().tolist()),
len(traffic_data[' Active Std'].unique().tolist()),
len(traffic_data[' Bwd IAT Max'].unique().tolist()),
len(traffic_data[' Bwd IAT Min'].unique().tolist()),
len(traffic_data[' Bwd IAT Std'].unique().tolist()),
len(traffic_data[' Flow Bytes/s'].unique().tolist()),
len(traffic_data[' Flow Duration'].unique().tolist()),
len(traffic_data[' Flow IAT Max'].unique().tolist()),
len(traffic_data[' Flow IAT Mean'].unique().tolist()),
len(traffic_data[' Flow IAT Min'].unique().tolist()),
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
252/35:
print(len(traffic_data[' Idle Max'].unique().tolist()),
len(traffic_data[' Idle Min'].unique().tolist()),
len(traffic_data[' Idle Std'].unique().tolist()),
len(traffic_data['Bwd IAT Mean'].unique().tolist()),
len(traffic_data['Active Mean'].unique().tolist()),
len(traffic_data['Idle Mean'].unique().tolist()))
252/36: len(traffic_data[' Flow IAT Mean'].unique().tolist())
252/37: len(tor_nontor_data[' Flow IAT Mean'].unique().tolist())
252/38:
columns = ['Source IP', ' Source Port', ' Destination IP', ' Destination Port',
       ' Protocol', ' Flow Duration', ' Flow Bytes/s', ' Flow Packets/s',
       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',
       'Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min',
       'Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min',
       'Active Mean', ' Active Std', ' Active Max', ' Active Min',
       'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', 'label']
252/39: import numpy as np
252/40: tor_nontor_data['traffic_label'] = np.NAN
252/41: tor_nontor_data.drop(columns='traffic_label', axis =1)
252/42: tor_nontor_data['traffic_label'] = np.NAN
252/43: tor_nontor_data = tor_nontor_data.drop(columns='traffic_label', axis =1)
252/44: tor_nontor_data.columns
252/45: import numpy as np
252/46: tor_nontor_data['traffic_label'] = tor_nontor_data.apply(lambda _: '', axis=1)
252/47: final_df = tor_nontor_data.set_index(columns)
252/48: traffic_data.rename(columns = "label" : "traffic_label")
252/49: traffic_data.rename(columns = {"label" : "traffic_label"})
252/50: traffic_data = traffic_data.rename(columns = {"label" : "traffic_label"})
252/51: final_df.update(traffic_data.set_index(columns))
252/52:
columns = ['Source IP', ' Source Port', ' Destination IP', ' Destination Port',
       ' Protocol', ' Flow Duration', ' Flow Bytes/s', ' Flow Packets/s',
       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',
       'Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min',
       'Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min',
       'Active Mean', ' Active Std', ' Active Max', ' Active Min',
       'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min']
252/53: final_df = tor_nontor_data.set_index(columns)
252/54: final_df.update(traffic_data.set_index(columns))
252/55:
columns = [' Flow Duration', ' Flow Bytes/s', ' Flow Packets/s',
       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',
       'Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min',
       'Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min',
       'Active Mean', ' Active Std', ' Active Max', ' Active Min',
       'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min']
252/56: final_df = tor_nontor_data.set_index(columns)
252/57: final_df.update(traffic_data.set_index(columns))
253/1:
from sklearn.ensemble import AdaBoostClassifier
from sklearn import datasets
# Import train_test_split function
from sklearn.model_selection import train_test_split
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
253/2:
from sklearn.ensemble import AdaBoostClassifier
from sklearn import datasets
# Import train_test_split function
from sklearn.model_selection import train_test_split
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
254/1:
import pandas as pd
import numpy as np
254/2:
from sklearn.ensemble import AdaBoostClassifier
from sklearn import datasets
# Import train_test_split function
from sklearn.model_selection import train_test_split
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
255/1:
import pandas as pd
import numpy as np
255/2:
from sklearn.ensemble import AdaBoostClassifier
from sklearn import datasets
# Import train_test_split function
from sklearn.model_selection import train_test_split
#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
255/3:
iris = datasets.load_iris()
X = iris.data
y = iris.target
255/4: X
255/5: X.shape
255/6: dtype(X)
255/7: type(X)
255/8: X[1]
255/9: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
255/10: tor_nontor_data.head()
255/11: tor_nontor_data.columns
255/12:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std',]].copy()
255/13: df.head()
255/14: df.to_numpy
255/15: df.head()
255/16: X = df.to_numpy
255/17: X
255/18: X.shape
255/19: X.shape()
255/20: X = df.to_numpy()
255/21: X.shape()
255/22: X.shape
255/23: y
255/24: y = tor_nontor_data['label']
255/25: y = tor_nontor_data['label'].to_numpy()
255/26: y
255/27: y.shape
255/28: y.shape
255/29:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
255/30: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
255/31:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)

model = trial1.fit(X_train, y_train)

y_pred = model.predict(X_test)
255/32: from sklearn import preprocessing
255/33:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df)
df_normalized = pd.DataFrame(np_scaled)
255/34: df.isnull().values.any()
255/35: df.shape
255/36: df_final = df.dropna()
255/37: df_final.shape
255/38: df_final.isnull().values.any()
255/39: from sklearn import preprocessing
255/40:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df_final)
df_normalized = pd.DataFrame(np_scaled)
255/41: df_final.replace([np.inf, -np.inf], np.nan)
255/42: df_final = df_final.replace([np.inf, -np.inf], np.nan)
255/43: df_final = df_final.dropna()
255/44: df_final.shape
255/45: np.where(df_final.values >= np.finfo(np.float64).max)
255/46: del = np.where(df_final.values >= np.finfo(np.float64).max)
255/47: to_del = np.where(df_final.values >= np.finfo(np.float64).max)
255/48: np.delete(df_final, to_del)
255/49: df_final.drop(df_final.values >= np.finfo(np.float64).max)
255/50: df_final.drop(df_final.values >= np.finfo(np.float64).max, inplace=True)
255/51: df_final.drop(to_del, inplace=True)
255/52: df_final.drop(to_del.index, inplace=True)
257/1:
import pandas as pd
import numpy as np
257/2: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
257/3: tor_nontor_data.head()
257/4: tor_nontor_data.columns
257/5:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
257/6: df.head()
257/7: df.notnull().values.all()
257/8: df.isnull().values.all()
257/9: df = df.fillna(df.mean())
257/10: df.isnull().values.all()
257/11: df.notnull().values.all()
257/12: df = df.dropna()
257/13: df.isnull().values.all()
257/14: df.notnull().values.all()
257/15: df.shape()
257/16: df.shape
257/17: df.replace([np.inf, -np.inf], np.nan)
257/18: df = df.replace([np.inf, -np.inf], np.nan)
257/19: df = df.dropna()
257/20: df.shape
257/21: df.notnull().values.all()
257/22: df.isnull().values.all()
257/23:  pandas.options.mode.use_inf_as_na = True
257/24: pd.options.mode.use_inf_as_na = True
257/25: df = df.replace([np.inf, -np.inf], np.nan)
257/26: df.notnull().values.all()
257/27: df.isnull().values.all()
257/28: df = df.fillna(df.mean())
257/29: df = df.dropna()
257/30: df.shape
257/31: df.isna()
257/32: df.isna
257/33: df.isna()
257/34: from sklearn import preprocessing
257/35:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df)
df_normalized = pd.DataFrame(np_scaled)
257/36: np.nan_to_num(df)
257/37: np.isnan(df)
257/38: df = df.replace([np.inf, -np.inf], np.nan)
257/39: np.nan_to_num(df)
257/40: df[:] = np.nan_to_num(df)
257/41: np.nan_to_num(df)
257/42: np.isinf(df)
257/43: df.replace('Infinity', df.mean())
257/44: df = df[:84186]
257/45: df
257/46:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df)
df_normalized = pd.DataFrame(np_scaled)
257/47:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
257/48: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
257/49: X = df.to_numpy()
257/50: X
257/51: y = tor_nontor_data['label']
257/52: y
257/53: y = y.to_numpy()
257/54: y
257/55: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
257/56: y = tor_nontor_data['label']
258/1:
import pandas as pd
import numpy as np
258/2: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
258/3:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
258/4: df.isnull().values.any()
258/5: df = df.dropna()
258/6: df.isnull().values.any()
258/7: df[:-5]
258/8: df[:5]
258/9: df[-1:5]
258/10: df[:,-5:]
258/11: df.iloc[:,-5:]
258/12: df.iloc[:, 5:]
258/13: df.shape
258/14: df
258/15: df = df.dropna()
258/16: df
258/17: df = df[:84186]
258/18: df
258/19:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
258/20: X = data.to_numpy()
258/21: y = df['label']
258/22: y = y.to_numpy()
258/23: X.shape
258/24: y.shape
258/25: from sklearn import preprocessing
258/26:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df)
df_normalized = pd.DataFrame(np_scaled)
258/27:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
258/28: X = data.to_numpy()
258/29: y = df['label']
258/30: y = y.to_numpy()
258/31: X.shape
258/32: y.shape
258/33: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
258/34:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
258/35: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
258/36:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model = trial1.fit(X_train, y_train)
y_pred = model.predict(X_test)
258/37: print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
258/38:
trial2 = AdaBoostClassifier(n_estimators=100, learning_rate=1)
model = trial1.fit(X_train, y_train)
y_pred = model.predict(X_test)
258/39: print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
258/40:
from sklearn.svm import SVC
svc=SVC(probability=True, kernel='linear')
258/41:
trial3 = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)
model = trial1.fit(X_train, y_train)
y_pred = model.predict(X_test)
258/42: print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
258/43:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train)
y_pred1 = model.predict(X_test)
258/44: print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))
258/45:
trial2 = AdaBoostClassifier(n_estimators=100, learning_rate=1)
model2 = trial1.fit(X_train, y_train)
y_pred2 = model.predict(X_test)
258/46: print("Accuracy:",metrics.accuracy_score(y_test, y_pred2))
258/47:
trial3 = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)
model3 = trial1.fit(X_train, y_train)
y_pred3 = model.predict(X_test)
258/48: print("Accuracy:",metrics.accuracy_score(y_test, y_pred3))
258/49: from sklearn.metrics import confusion_matrix
258/50: confusion_matrix(y_test, y_pred1)
258/51: confusion_matrix(y_test, y_pred2)
258/52: confusion_matrix(y_test, y_pred3)
259/1:
import pandas as pd
import numpy as np
259/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
259/3:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
259/4:
data = pd.get_dummies(data)
data.head()
259/5:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
259/6: data.head()
259/7:
df['label'] = pd.get_dummies(df['label'])
df.head()
259/8:
df['label'] = pd.get_dummies(df['label'])
df.head(100)
259/9:
df['label'] = pd.get_dummies(df['label'])
df.head()
259/10:
df['label'] = pd.get_dummies(df['label'])
df.head(60)
259/11:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
259/12:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
259/13: data.head()
259/14: df['label'].head()
259/15: df['label'].head(10)
259/16: df['label'].head(100)
259/17: df.replace(nonTOR, 0)
259/18: df.replace('nonTOR', 0)
259/19: df = df.replace('nonTOR', 0)
259/20: df = df.replace('TOR', 1)
259/21: df.head()
259/22: df.head(1000)
259/23: df['label'].unique
259/24: df['label'].unique()
259/25:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
259/26: data.head()
259/27: y
259/28: X
259/29:
from sklearn.model_selection import train_test_split
from sklearn import metrics
259/30: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
259/31: from sklearn.ensemble import RandomForestRegressor
259/32:
rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)
rf.fit(X_train, y_train)
259/33: predictions = rf.predict(y_test)
259/34: predictions = rf.predict(X_test)
259/35: errors = abs(predictions - test_labels)
259/36: errors = abs(predictions - y_test)
259/37: print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')
259/38: mape = 100 * (errors / test_labels)
259/39: mape = 100 * (errors / y_test)
259/40:
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')
259/41: accuracy
259/42: mape
259/43: print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))
259/44: print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
259/45: print("Accuracy:",metrics.accuracy_score(y_test, predictions))
259/46: from sklearn.metrics import confusion_matrix
259/47: confusion_matrix(y_test, predictions)
259/48: X_train.shape
259/49: X_test.shape
259/50: y_train.shape
259/51: y_test.shape
259/52:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
259/53:
def random_forest_classifier(features, target):
    """
    To train the random forest classifier with features and target data
    :param features:
    :param target:
    :return: trained random forest classifier
    """
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
259/54: trial1 = random_forest_classifier(X_train, y_train)
259/55: print(trial1)
259/56: y_pred = trained_model.predict(X_test)
259/57: y_pred = trial1.predict(X_test)
259/58:
print("Train Accuracy :: ", accuracy_score(y_train, trial1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred))
259/59: print(" Confusion matrix ", confusion_matrix(y_test, y_pred))
259/60: confusion_matrix(y_test, y_pred)
260/1:
import pandas as pd
import numpy as np
260/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
260/3:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
260/4:
from sklearn.metrics import confusion_matrix 
from sklearn.cross_validation import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
260/5:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
260/6:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def tarin_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
260/7:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
260/8:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
260/9: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
260/10:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
260/11:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
260/12:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
260/13:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
260/14:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
260/15:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
261/1:
import pandas as pd
import numpy as np
261/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
261/3:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
261/4:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 
from sklearn.neural_network import MLPClassifier
261/5: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
261/6:
mlp = MLPClassifier(hidden_layer_sizes=(20, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
261/7: from sklearn import preprocessing
261/8:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
261/9:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
261/10:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 
from sklearn.neural_network import MLPClassifier
261/11: from sklearn import preprocessing
261/12:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
261/13:
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
261/14: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
261/15:
mlp = MLPClassifier(hidden_layer_sizes=(20, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
261/16:
mlp = MLPClassifier(hidden_layer_sizes=(100, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
261/17:
mlp = MLPClassifier(hidden_layer_sizes=(1000, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
261/18:
mlp = MLPClassifier(hidden_layer_sizes=(1000,100,10, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
261/19: X
261/20: data
261/21:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
261/22:
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
261/23: data
258/53: df = df.drop_duplicates(keep=False, inplace=True)
258/54:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
258/55: df
258/56: df.head()
262/1:
import pandas as pd
import numpy as np
262/2: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
262/3:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
262/4: df.isnull().values.any()
262/5: df = df.dropna()
262/6: df = df[:84186]
262/7: df = df.drop_duplicates(keep=False, inplace=True)
262/8: df.head()
262/9:
import pandas as pd
import numpy as np
262/10: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
262/11:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
262/12: df.isnull().values.any()
262/13: df = df.dropna()
262/14: df.isnull().values.any()
262/15: df = df[:84186]
262/16: df.drop_duplicates(keep=False, inplace=True)
262/17: df.head()
262/18:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
262/19: X = data.to_numpy()
262/20: y = df['label']
262/21: y = y.to_numpy()
262/22: X.shape
262/23: y.shape
262/24: from sklearn import preprocessing
262/25:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
262/26:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
262/27: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
262/28:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train)
y_pred1 = model.predict(X_test)
262/29: confusion_matrix(y_test, y_pred3)
262/30:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train)
y_pred1 = model1.predict(X_test)
262/31: print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))
262/32:
trial2 = AdaBoostClassifier(n_estimators=100, learning_rate=1)
model2 = trial1.fit(X_train, y_train)
y_pred2 = model2.predict(X_test)
262/33: print("Accuracy:",metrics.accuracy_score(y_test, y_pred2))
262/34:
from sklearn.svm import SVC
svc=SVC(probability=True, kernel='linear')
262/35:
trial3 = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)
model3 = trial1.fit(X_train, y_train)
y_pred3 = model3.predict(X_test)
262/36: print("Accuracy:",metrics.accuracy_score(y_test, y_pred3))
262/37: from sklearn.metrics import confusion_matrix
262/38: confusion_matrix(y_test, y_pred1)
262/39: confusion_matrix(y_test, y_pred2)
262/40: confusion_matrix(y_test, y_pred3)
263/1:
import pandas as pd
import numpy as np
263/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
263/3: df.drop_duplicates(keep=False, inplace=True)
263/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
263/5: data.head()
263/6: df = df.replace('nonTOR', 0)
263/7: df = df.replace('TOR', 1)
263/8:
from sklearn.model_selection import train_test_split
from sklearn import metrics
263/9: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
263/10: X_train.shape
263/11: X_test.shape
263/12: y_train.shape
263/13: y_test.shape
263/14:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
263/15:
def random_forest_classifier(features, target):
    """
    To train the random forest classifier with features and target data
    :param features:
    :param target:
    :return: trained random forest classifier
    """
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
263/16: trial1 = random_forest_classifier(X_train, y_train)
263/17: print(trial1)
263/18: y_pred = trial1.predict(X_test)
263/19:
print("Train Accuracy :: ", accuracy_score(y_train, trial1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred))
263/20: confusion_matrix(y_test, y_pred)
264/1:
import pandas as pd
import numpy as np
264/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
264/3: df.drop_duplicates(keep=False, inplace=True)
264/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
264/5:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
264/6: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
264/7:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
264/8:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
264/9:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
264/10:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
264/11:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
265/1:
import pandas as pd
import numpy as np
265/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
265/3: df.drop_duplicates(keep=False, inplace=True)
265/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
265/5:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 
from sklearn.neural_network import MLPClassifier
265/6: from sklearn import preprocessing
265/7:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
265/8:
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
265/9: data
265/10:
x = data.values 
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
data = pandas.DataFrame(x_scaled)
265/11:
x = data.values 
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
data = pd.DataFrame(x_scaled)
265/12:
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
265/13: data
265/14: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
265/15:
mlp = MLPClassifier(hidden_layer_sizes=(1000,100,10, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
265/16:
mlp = MLPClassifier(hidden_layer_sizes=(50, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
265/17:
mlp = MLPClassifier(hidden_layer_sizes=(100,50, 3), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
265/18:
mlp = MLPClassifier(hidden_layer_sizes=(1000, 100, 10), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
265/19:
print("Training set score: %f" % mlp.score(learnset, learnlabels))
print("Test set score: %f" % mlp.score(learnset, learnlabels))
mlp.classes_
265/20: print("Training set score: %f" % mlp.score(X_train, y_train))
265/21: print("Test set score: %f" % mlp.score(X_test, y_test))
265/22: mlp.classes_
265/23: y_pred = mlp.predict(X_test)
265/24:
print("Train Accuracy :: ", accuracy_score(y_train, mlp.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred))
265/25: confusion_matrix(y_test, y_pred)
262/41:
print("Train Accuracy :: ", accuracy_score(y_train, model1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred))
262/42: from sklearn.metrics import accuracy_score
262/43:
print("Train Accuracy :: ", accuracy_score(y_train, model1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred))
262/44:
print("Train Accuracy :: ", accuracy_score(y_train, model1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred1))
268/1: print('this stuff')
268/2: print('this stuff')
268/3: print('cool')
268/4: print('in your face')
268/5: !pip install gym
270/1:
import gym

env = gym.make("Taxi-v2")
env.reset()
270/2: env.observation_space.n
270/3: env.action_space.n
270/4: env.render()
270/5:
env.env.s = 114
env.render()
270/6:
env.env.s = 114
env.step(1)
env.render()
270/7: state, reward, done, info = env.step(1)
270/8:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/9:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/10:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/11:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/12:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/13:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/14:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/15:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/16:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/17:
state = env.reset()
counter = 0
reward = None

while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1
    
print(counter)
270/18:
state = env.reset()
counter = 0
reward = None
    
while reward != 20:
    state, reward, done, info = env.step(env.action_space.sample())
    counter += 1

print(counter)
270/19:
import numpy as np
Q = np.zeros([env.observation_space.n, env.action_space.n])
270/20:
import numpy as np
Q = np.zeros([env.observation_space.n, env.action_space.n])
270/21:
# total accumulated reward G
G = 0

# learning rate
alpha = 0.618
270/22:
for episode in range(1, 1001):
    done = False
    G, reward = 0, 0
    state = env.reset()
    while done != True:
        action = np.argmax(Q[state])
        state2, reward, done, info = env.step(action)
        Q[state, action] += alpha * (reward + np.max(Q[state2]) - Q[state, action])
        G += reward
        state = state2
    if episode % 50 == 0:
        print("episode {} total: {}".format(episode, G))
270/23:
for episode in range(1, 1001):
    done = False
    G, reward = 0, 0
    state = env.reset()
    while done != True:
        action = np.argmax(Q[state])
        state2, reward, done, info = env.step(action)
        Q[state, action] += alpha * (reward + np.max(Q[state2]) - Q[state, action])
        G += reward
        state = state2
        env.render()
    if episode % 50 == 0:
        print("episode {} total: {}".format(episode, G))
270/24:
for episode in range(1, 1001):
    done = False
    G, reward = 0, 0
    state = env.reset()
    while done != True:
        action = np.argmax(Q[state])
        state2, reward, done, info = env.step(action)
        Q[state, action] += alpha * (reward + np.max(Q[state2]) - Q[state, action])
        G += reward
        state = state2
        env.render()
    if episode % 50 == 0:
        print("episode {} total: {}".format(episode, G))
270/25:
from os import system
system('clear')
270/26:
from os import system
_ = system('clear')
270/27:
from os import system
import time
270/28:
for episode in range(1, 1001):
    done = False
    G, reward = 0, 0
    state = env.reset()
    while done != True:
        action = np.argmax(Q[state])
        state2, reward, done, info = env.step(action)
        Q[state, action] += alpha * (reward + np.max(Q[state2]) - Q[state, action])
        G += reward
        state = state2
        env.render()
        _ = system('clear')
        time.sleep(5)
    if episode % 50 == 0:
        print("episode {} total: {}".format(episode, G))
270/29:
for episode in range(1, 1001):
    done = False
    G, reward = 0, 0
    state = env.reset()
    while done != True:
        action = np.argmax(Q[state])
        state2, reward, done, info = env.step(action)
        Q[state, action] += alpha * (reward + np.max(Q[state2]) - Q[state, action])
        G += reward
        state = state2
        env.render()
        time.sleep(1)
    if episode % 50 == 0:
        print("episode {} total: {}".format(episode, G))
270/30: env = gym.make("MsPacman-v0")
270/31: !pip install gym[atari]
272/1:
import pandas as pd
import numpy as np
272/2: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
272/3:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
272/4: df.isnull().values.any()
272/5: df = df.dropna()
272/6: df = df[:84186]
272/7: df.drop_duplicates(keep=False, inplace=True)
272/8: df.head()
272/9:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
272/10: X = data.to_numpy()
272/11: y = df['label']
272/12: y = y.to_numpy()
272/13: X.shape
272/14: y.shape
272/15: from sklearn import preprocessing
272/16:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
272/17:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
272/18: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
272/19:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train)
y_pred1 = model1.predict(X_test)
272/20: print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))
272/21: from sklearn.metrics import accuracy_score
272/22:
print("Train Accuracy :: ", accuracy_score(y_train, model1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred1))
272/23:
trial2 = AdaBoostClassifier(n_estimators=100, learning_rate=1)
model2 = trial1.fit(X_train, y_train)
y_pred2 = model2.predict(X_test)
272/24: print("Accuracy:",metrics.accuracy_score(y_test, y_pred2))
272/25:
from sklearn.svm import SVC
svc=SVC(probability=True, kernel='linear')
272/26:
trial3 = AdaBoostClassifier(n_estimators=50, base_estimator=svc,learning_rate=1)
model3 = trial1.fit(X_train, y_train)
y_pred3 = model3.predict(X_test)
272/27: print("Accuracy:",metrics.accuracy_score(y_test, y_pred3))
272/28: from sklearn.metrics import confusion_matrix
272/29: confusion_matrix(y_test, y_pred1)
272/30: confusion_matrix(y_test, y_pred2)
272/31: confusion_matrix(y_test, y_pred3)
272/32: import matplotlib.pyplot as plt
272/33: y.shape[1]
272/34: y.shape[0]
272/35: y
272/36: y.shape
272/37:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train).decision_function(X_test)
y_pred1 = model1.predict(X_test)
272/38:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train).decision_function(X_test)
# y_pred1 = model1.predict(X_test)
272/39:
y = label_binarize(y, classes=[0, 1])
n_classes = y.shape[1]
272/40: from sklearn.preprocessing import label_binarize
272/41:
y = label_binarize(y, classes=[0, 1])
n_classes = y.shape[1]
272/42: y.shape
272/43: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
272/44:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train)
y_pred1 = model1.predict(X_test)
272/45:
trial1 = AdaBoostClassifier(n_estimators=50, learning_rate=1)
model1 = trial1.fit(X_train, y_train).decision_function(X_test)
# y_pred1 = model1.predict(X_test)
272/46:
print("Train Accuracy :: ", accuracy_score(y_train, model1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, model1.predict(X_test)))
272/47:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(1):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], model1[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
272/48:

from sklearn.metrics import roc_curve, auc
272/49:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(1):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], model1[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
272/50:
plt.figure()
lw = 2
plt.plot(fpr[2], tpr[2], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
272/51:
plt.figure()
lw = 2
plt.plot(fpr[0], tpr[0], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
272/52:
plt.figure()
lw = 2
plt.plot(fpr[0], tpr[0], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
272/53:
plt.figure()
lw = 2
plt.plot(fpr[1], tpr[1], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
272/54:
plt.figure()
lw = 2
plt.plot(fpr[1], tpr[1], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
272/55: y
272/56: y.unique
272/57: y.unique()
272/58: y.head(10)
272/59: y.head[10]
272/60: y
272/61: print(y)
272/62: classifier = AdaBoostClassifier()
272/63: y_score = classifier.fit(X_train, y_train).predict(X_test)
272/64:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
273/1:
import pandas as pd
import numpy as np
273/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
273/3: df.drop_duplicates(keep=False, inplace=True)
273/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
273/5:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
273/6: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
273/7:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
273/8:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
273/9:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
273/10:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
273/11:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
272/65: y_test
272/66: y_test.shape
272/67: n_classes
272/68: y_test[:0]
272/69: y_test[:1]
272/70:
print(__doc__)

import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp
272/71:
# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
272/72:
# Binarize the output
y = label_binarize(y, classes=[0, 1, 2])
n_classes = y.shape[1]
272/73:
# Add noisy features to make the problem harder
random_state = np.random.RandomState(0)
n_samples, n_features = X.shape
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
272/74:
# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,
                                                    random_state=0)
272/75:
# Learn to predict each class against the other
classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,
                                 random_state=random_state))
y_score = classifier.fit(X_train, y_train).decision_function(X_test)
272/76:
# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
272/77: y.shape
272/78: y_test[:0]
272/79: y_test[:1]
272/80: y_test[:2]
272/81: y_test[:3]
272/82:
print(__doc__)

import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp
272/83:
# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
272/84: y
272/85:
import pandas as pd
import numpy as np
272/86: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
272/87:
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
272/88: df.isnull().values.any()
272/89: df = df.dropna()
272/90: df = df[:84186]
272/91: df.drop_duplicates(keep=False, inplace=True)
272/92: df.head()
272/93:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
272/94: X = data.to_numpy()
272/95: y = df['label']
272/96: y = y.to_numpy()
272/97: X.shape
272/98: y.shape
272/99:
from sklearn.preprocessing import LabelBinarizer
encoder = LabelBinarizer()
transfomed_label = encoder.fit_transform(["TOR", "nonTOR"])
print(transfomed_label)
272/100: y
272/101:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
272/102: le.fit(y)
272/103: y
272/104: le.fit_transform(y)
272/105: y
272/106: y = le.fit_transform(y)
272/107: y
272/108: y.unique
272/109: z = lsit(y)
272/110: z = list(y)
272/111: z.unique
272/112: z.unique()
272/113: np.unique(y)
272/114: from sklearn.preprocessing import label_binarize
272/115:
y = label_binarize(y, classes=[0, 1])
n_classes = y.shape[1]
272/116: y.shape
272/117: y
272/118:
# Import some data to play with
iris = datasets.load_iris()
X1 = iris.data
y1 = iris.target
272/119: y1
272/120:
# Binarize the output
y1 = label_binarize(y1, classes=[0, 1, 2])
n_classes = y1.shape[1]
272/121: y1
272/122: from sklearn import preprocessing
272/123:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
272/124:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
272/125: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
272/126: classifier = AdaBoostClassifier()
272/127: y_score = classifier.fit(X_train, y_train).predict(X_test)
272/128:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
272/129: label_binarize([1,4], classes = [1,2,4,6])
272/130: y1.shape
272/131: y1
272/132:
# Import some data to play with
iris = datasets.load_iris()
X1 = iris.data
y1 = iris.target
272/133: y1
272/134: y1.shape
272/135:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
272/136: X = data.to_numpy()
272/137: y = df['label']
272/138: y = y.to_numpy()
272/139: X.shape
272/140: y.shape
272/141:
# from sklearn.preprocessing import LabelBinarizer
# encoder = LabelBinarizer()
# transfomed_label = encoder.fit_transform(["TOR", "nonTOR"])
# print(transfomed_label)
272/142:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
272/143: y = le.fit_transform(y)
272/144: np.unique(y)
272/145: y
272/146: y.shape
272/147: from sklearn.preprocessing import label_binarize
272/148:
y = label_binarize(y, classes=[0, 1])
n_classes = y.shape[1]
272/149: y.shape
272/150: y
272/151: y_score
272/152: y_score.shape
272/153: y_test.shape
272/154: y = df['label']
272/155: y = y.to_numpy()
272/156: y.shape
272/157: y = le.fit_transform(y)
272/158: yt = np.transpose(y)
272/159: yt
272/160: from sklearn.preprocessing import label_binarize
272/161: yt = label_binarize(y, classes=[0, 1])
272/162: yt
272/163: yt = np.transpose(yt)
272/164: yt
272/165: yt[0]
272/166: np.unique(yt[0])
272/167: from sklearn import preprocessing
272/168:
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(data)
df_normalized = pd.DataFrame(np_scaled)
272/169:
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
272/170: X_train, X_test, y_train, y_test = train_test_split(X, yt, test_size=0.3)
272/171: X_train, X_test, y_train, y_test = train_test_split(X, yt[0], test_size=0.3)
272/172: classifier = AdaBoostClassifier()
272/173: y_score = classifier.fit(X_train, y_train).predict(X_test)
272/174: y_score.shape
272/175: y_test.shape
272/176:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
272/177: y_score.shape
272/178: y_test.shape
272/179: y_test[:,1]
272/180: y_test[:,0]
272/181:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(1):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
272/182:
fpr = dict()
tpr = dict()
roc_auc = dict()
# for i in range(1):
fpr[0], tpr[0], _ = roc_curve(y_test[:, 0], y_score[:, 0])
roc_auc[0] = auc(fpr[0], tpr[0])
274/1:
import pandas as pd
import numpy as np
274/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
274/3: df.drop_duplicates(keep=False, inplace=True)
274/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
274/5: df = df.replace('nonTOR', 0)
274/6: df = df.replace('TOR', 1)
274/7:
from sklearn.model_selection import train_test_split
from sklearn import metrics
274/8: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
274/9: X_train.shape
274/10: X_test.shape
274/11: y_train.shape
274/12: y_test.shape
274/13:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
274/14:
def random_forest_classifier(features, target):
    """
    To train the random forest classifier with features and target data
    :param features:
    :param target:
    :return: trained random forest classifier
    """
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
274/15: trial1 = random_forest_classifier(X_train, y_train)
274/16: print(trial1)
274/17: y_pred = trial1.predict(X_test)
274/18:
print("Train Accuracy :: ", accuracy_score(y_train, trial1.predict(X_train)))
print("Test Accuracy  :: ", accuracy_score(y_test, y_pred))
274/19: confusion_matrix(y_test, y_pred)
274/20: rf_probs = trial1.predict_proba(X_test)[:, 1]
274/21: rf_probs
274/22: from sklearn.metrics import roc_auc_score
274/23:

roc_value = roc_auc_score(y_test, rf_probs)
274/24: roc_value
274/25:
from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
274/26:
plt.style.use('fivethirtyeight')
plt.rcParams['font.size'] = 18
274/27: train_rf_predictions = trial1.predict(X_train)
274/28: train_rf_probs = trial1.predict_proba(X_train)[:, 1]
274/29:
def evaluate_model(predictions, probs, train_predictions, train_probs):
    """Compare machine learning model to baseline performance.
    Computes statistics and shows ROC curve."""
    
    baseline = {}
    
    baseline['recall'] = recall_score(y_test, 
                                     [1 for _ in range(len(y_test))])
    baseline['precision'] = precision_score(y_test, 
                                      [1 for _ in range(len(y_test))])
    baseline['roc'] = 0.5
    
    results = {}
    
    results['recall'] = recall_score(y_test, predictions)
    results['precision'] = precision_score(y_test, predictions)
    results['roc'] = roc_auc_score(y_test, probs)
    
    train_results = {}
    train_results['recall'] = recall_score(y_train, train_predictions)
    train_results['precision'] = precision_score(y_train, train_predictions)
    train_results['roc'] = roc_auc_score(y_train, train_probs)
    
    for metric in ['recall', 'precision', 'roc']:
        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')
    
    # Calculate false positive rates and true positive rates
    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(test_labels))])
    model_fpr, model_tpr, _ = roc_curve(y_test, probs)

    plt.figure(figsize = (8, 6))
    plt.rcParams['font.size'] = 16
    
    # Plot both curves
    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')
    plt.plot(model_fpr, model_tpr, 'r', label = 'model')
    plt.legend();
    plt.xlabel('False Positive Rate'); 
    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');
    plt.show();

evaluate_model(y_pred, rf_probs, train_rf_predictions, train_rf_probs)
plt.savefig('roc_auc_curve.png')
274/30:
def evaluate_model(predictions, probs, train_predictions, train_probs):
    """Compare machine learning model to baseline performance.
    Computes statistics and shows ROC curve."""
    
    baseline = {}
    
    baseline['recall'] = recall_score(y_test, 
                                     [1 for _ in range(len(y_test))])
    baseline['precision'] = precision_score(y_test, 
                                      [1 for _ in range(len(y_test))])
    baseline['roc'] = 0.5
    
    results = {}
    
    results['recall'] = recall_score(y_test, predictions)
    results['precision'] = precision_score(y_test, predictions)
    results['roc'] = roc_auc_score(y_test, probs)
    
    train_results = {}
    train_results['recall'] = recall_score(y_train, train_predictions)
    train_results['precision'] = precision_score(y_train, train_predictions)
    train_results['roc'] = roc_auc_score(y_train, train_probs)
    
    for metric in ['recall', 'precision', 'roc']:
        print("f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}'")
    
    # Calculate false positive rates and true positive rates
    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(test_labels))])
    model_fpr, model_tpr, _ = roc_curve(y_test, probs)

    plt.figure(figsize = (8, 6))
    plt.rcParams['font.size'] = 16
    
    # Plot both curves
    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')
    plt.plot(model_fpr, model_tpr, 'r', label = 'model')
    plt.legend();
    plt.xlabel('False Positive Rate'); 
    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');
    plt.show();

evaluate_model(y_pred, rf_probs, train_rf_predictions, train_rf_probs)
plt.savefig('roc_auc_curve.png')
275/1:
# roc curve and auc
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
275/2:
# generate 2 class dataset
X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)
275/3: X
275/4: y
275/5:
# split into train/test sets
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)
275/6:
# generate a no skill prediction (majority class)
ns_probs = [0 for _ in range(len(testy))]
275/7:
# fit a model
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
275/8:
# predict probabilities
lr_probs = model.predict_proba(testX)
# keep probabilities for the positive outcome only
lr_probs = lr_probs[:, 1]
275/9: lr_probs
275/10:
# calculate scores
ns_auc = roc_auc_score(testy, ns_probs)
lr_auc = roc_auc_score(testy, lr_probs)
275/11: ns_auc
275/12: lr_auc
275/13:
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Logistic: ROC AUC=%.3f' % (lr_auc))
275/14:
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)
275/15: print(ns_fpr, ns_tpr)
275/16: print(lr_fpr, lr_tpr)
275/17:
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()
276/1:
import pandas as pd
import numpy as np
276/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
276/3: df.drop_duplicates(keep=False, inplace=True)
276/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
276/5: df = df.replace('nonTOR', 0)
276/6: df = df.replace('TOR', 1)
276/7: df
276/8: df[label].unique
276/9: df.label.unique
276/10:
from sklearn.model_selection import train_test_split
from sklearn import metrics
276/11: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
276/12: X_train.shape
276/13: X_test.shape
276/14: y_train.shape
276/15: y_test.shape
275/18: trainX.shape
275/19: trainy.shape
275/20: testX.shape
275/21: testy.shape
276/16: y
276/17: y_test
276/18: df = df['label'].replace('nonTOR', 0)
276/19: df = df['label'].replace('TOR', 1)
276/20: df.head()
277/1:
import pandas as pd
import numpy as np
277/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
277/3: df.drop_duplicates(keep=False, inplace=True)
277/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
277/5:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
277/6: yn = le.fit_transform(y)
277/7: yn
277/8: yn.unique
277/9: yn.unique()
277/10: np.unique(yn)
277/11:
from sklearn.model_selection import train_test_split
from sklearn import metrics
277/12: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
277/13: X_train.shape
277/14: X_test.shape
277/15: y_train.shape
277/16: y_test.shape
277/17: y_test
277/18:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
277/19:
def random_forest_classifier(features, target):
    """
    To train the random forest classifier with features and target data
    :param features:
    :param target:
    :return: trained random forest classifier
    """
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
277/20: ns_probs = [0 for _ in range(len(y_test))]
277/21: ns_probs
277/22: ns_probs.unique
277/23: trial1 = random_forest_classifier(X_train, y_train)
277/24: train_rf_predictions = trial1.predict(X_test)
277/25: # train_rf_predictions = trial1.predict(X_test)
277/26: y_pred = trial1.predict(X_test)
277/27: y_pred
277/28: y_pred = trial1.predict_proba(X_test)
277/29: y_pred
277/30:
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, y_pred)
277/31:
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
277/32:
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, y_pred)
277/33: y_pred[:1]
277/34: y_pred[:2]
277/35: y_pred[:5]
277/36: lr_probs = y_pred.reshape(-1,1)
277/37: lr_probs
277/38:
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, lr_probs)
277/39:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
277/40: y_pred
277/41:
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, y_pred)
277/42:
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Logistic: ROC AUC=%.3f' % (lr_auc))
277/43:
ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)
277/44:
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)
277/45:
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(y_test, y_pred)
277/46: print(ns_fpr, ns_tpr)
277/47: print(lr_fpr, lr_tpr)
277/48:
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()
277/49:
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Random Forest')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()
280/1:
import pandas as pd
import numpy as np
280/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]
280/3: df.drop_duplicates(keep=False, inplace=True)
280/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
280/5:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
280/6: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
280/7:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
280/8:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
280/9:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
280/10: y_train.head()
280/11: y_train[:10]
280/12: unique_y = y_train.unique
280/13: unique_y = np.unique(y_train)
280/14: le = preprocessing.LabelEncoder()
280/15:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
280/16: le.fit(unique_y)
280/17: temp = le.transform(y_train)
280/18: temp[:10]
280/19: y_train = le.transform(y_train)
280/20: y_test = le.transform(y_test)
280/21:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
280/22:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
280/23:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]
280/24: df.drop_duplicates(keep=False, inplace=True)
280/25:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
280/26: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
280/27: unique_y = np.unique(y_train)
280/28: unique_y = np.unique(y_train)
280/29:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
280/30: le.fit(unique_y)
280/31: y_train = le.transform(y_train)
280/32: y_test = le.transform(y_test)
280/33:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
280/34:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
280/35:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
283/1:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:84186]
283/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]
283/3:
import pandas as pd
import numpy as np
283/4:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]
283/5: df.drop_duplicates(keep=False, inplace=True)
283/6:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
283/7:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
283/8:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
283/9: yn = le.fit_transform(y)
283/10: np.unique(yn)
283/11:
from sklearn.model_selection import train_test_split
from sklearn import metrics
283/12: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
283/13: X_train.shape
283/14: X_test.shape
283/15: y_train.shape
283/16: y_test.shape
283/17: y_test
283/18:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
283/19:
def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
283/20: ns_probs = [0 for _ in range(len(y_test))]
283/21: trial1 = random_forest_classifier(X_train, y_train)
283/22:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
283/23: y_pred
283/24:
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
283/25:
ns_auc = roc_auc_score(y_test, ns_probs)
lr_auc = roc_auc_score(y_test, y_pred)
283/26:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(np.unique(yn)):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
283/27:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
283/28: len(np.unique(yn))
283/29:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    print(y_test[:i], y_pred[:i])
    break
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
283/30:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    print(y_test[:i])
    break
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
283/31:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    print(y_test[:,i])
    break
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
283/32: y_test[0]
283/33:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    index = 0
    p = []
    q = []
    for value in y_test:
        if value == i:
            p.append(y_test[index])
            q.append(y_pred[index]) 
        index += 1
    fpr[i], tpr[i], _ = roc_curve(p, q)
    roc_auc[i] = auc(fpr[i], tpr[i])
283/34:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    index = 0
    p = []
    q = []
    for value in y_test:
        if value == i:
            p.append(y_test[index])
            q.append(y_pred[index]) 
        index += 1
    some_value = roc_auc_score(p, q)
#     roc_auc[i] = auc(fpr[i], tpr[i])
283/35:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    index = 0
    p = []
    q = []
    for value in y_test:
        if value == i:
            p.append(y_test[index])
            q.append(y_pred[index]) 
        index += 1
    print(p, q)
    some_value = roc_auc_score(p, q)
#     roc_auc[i] = auc(fpr[i], tpr[i])
283/36:
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(len(np.unique(yn))):
    index = 0
    p = []
    q = []
    for value in y_test:
        if value == i:
            p.append(y_test[index])
            q.append(y_pred[index]) 
        index += 1
    print(len(p), len(q))
    some_value = roc_auc_score(p, q)
#     roc_auc[i] = auc(fpr[i], tpr[i])
283/37:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df[df['label'] == 'VOIP' or df['label'] == 'BROWSING' ]
y = y.to_numpy()
283/38:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df[(df['label'] == 'VOIP') or (df['label'] == 'BROWSING')]
y = y.to_numpy()
283/39:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
283/40:
y_final = []
x_final = []
index = 0
for key in y:
    if y == 'VOIP' or y =='BROWSING':
        x_final = X[index]
        y_final = y[index]
    index += 1
283/41:
y_final = []
x_final = []
index = 0
for key in y:
    if y == 'VOIP' or 'BROWSING':
        x_final = X[index]
        y_final = y[index]
    index += 1
283/42:
y_final = []
x_final = []
index = 0
for key in y:
    if (y == 'VOIP') or (y =='BROWSING'):
        x_final = X[index]
        y_final = y[index]
    index += 1
283/43:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
283/44:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
283/45:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
283/46: yn = le.fit_transform(y)
283/47: np.unique(yn)
283/48:
from sklearn.model_selection import train_test_split
from sklearn import metrics
283/49: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
283/50: X_train.shape
283/51: X_test.shape
283/52: y_train.shape
283/53: y_test.shape
283/54: y_test
283/55:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
283/56:
def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
283/57: ns_probs = [0 for _ in range(len(y_test))]
283/58: trial1 = random_forest_classifier(X_train, y_train)
283/59:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
283/60: y_pred
283/61:
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
283/62: len(np.unique(yn))
283/63: y_test[0]
283/64:
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Logistic: ROC AUC=%.3f' % (lr_auc))
283/65:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
283/66:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
283/67: cal_accuracy(y_test, y_pred)
283/68: y_pred = np.around(y_pred)
283/69: cal_accuracy(y_test, y_pred)
282/1:
traffic_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv')
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
282/2: import pandas as pd
282/3:
traffic_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv')
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
282/4: traffic_data.shape
282/5: traffic_data.columns
282/6: traffic_data['label'].value_counts()
284/1: import pandas as pd
284/2:
traffic_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv')
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
284/3: traffic_data.shape
284/4: traffic_data.columns
284/5: traffic_data['label'].value_counts()
284/6: traffic_data['Label'].value_counts()
284/7: traffic_data.info()
284/8:
print(len(traffic_data[' Active Max'].unique().tolist()),
len(traffic_data[' Active Min'].unique().tolist()),
len(traffic_data[' Active Std'].unique().tolist()),
len(traffic_data[' Bwd IAT Max'].unique().tolist()),
len(traffic_data[' Bwd IAT Min'].unique().tolist()),
len(traffic_data[' Bwd IAT Std'].unique().tolist()),
len(traffic_data[' Flow Bytes/s'].unique().tolist()),
len(traffic_data[' Flow Duration'].unique().tolist()),
len(traffic_data[' Flow IAT Max'].unique().tolist()),
len(traffic_data[' Flow IAT Mean'].unique().tolist()),
len(traffic_data[' Flow IAT Min'].unique().tolist()),
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
284/9:
print(len(traffic_data[' Active Max'].unique().tolist()),
len(traffic_data[' Bwd IAT Max'].unique().tolist()),
len(traffic_data[' Bwd IAT Min'].unique().tolist()),
len(traffic_data[' Bwd IAT Std'].unique().tolist()),
len(traffic_data[' Flow Bytes/s'].unique().tolist()),
len(traffic_data[' Flow Duration'].unique().tolist()),
len(traffic_data[' Flow IAT Max'].unique().tolist()),
len(traffic_data[' Flow IAT Mean'].unique().tolist()),
len(traffic_data[' Flow IAT Min'].unique().tolist()),
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
284/10:
print(
len(traffic_data[' Bwd IAT Max'].unique().tolist()),
len(traffic_data[' Bwd IAT Min'].unique().tolist()),
len(traffic_data[' Bwd IAT Std'].unique().tolist()),
len(traffic_data[' Flow Bytes/s'].unique().tolist()),
len(traffic_data[' Flow Duration'].unique().tolist()),
len(traffic_data[' Flow IAT Max'].unique().tolist()),
len(traffic_data[' Flow IAT Mean'].unique().tolist()),
len(traffic_data[' Flow IAT Min'].unique().tolist()),
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
284/11:
print(
len(traffic_data[' Bwd IAT Min'].unique().tolist()),
len(traffic_data[' Bwd IAT Std'].unique().tolist()),
len(traffic_data[' Flow Bytes/s'].unique().tolist()),
len(traffic_data[' Flow Duration'].unique().tolist()),
len(traffic_data[' Flow IAT Max'].unique().tolist()),
len(traffic_data[' Flow IAT Mean'].unique().tolist()),
len(traffic_data[' Flow IAT Min'].unique().tolist()),
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
284/12:
print(
len(traffic_data[' Flow Bytes/s'].unique().tolist()),
len(traffic_data[' Flow Duration'].unique().tolist()),
len(traffic_data[' Flow IAT Max'].unique().tolist()),
len(traffic_data[' Flow IAT Mean'].unique().tolist()),
len(traffic_data[' Flow IAT Min'].unique().tolist()),
len(traffic_data[' Fwd IAT Std'].unique().tolist()))
284/13:
print(len(traffic_data[' Idle Max'].unique().tolist()),
len(traffic_data[' Idle Min'].unique().tolist()),
len(traffic_data[' Idle Std'].unique().tolist()),
len(traffic_data['Bwd IAT Mean'].unique().tolist()),
len(traffic_data['Active Mean'].unique().tolist()),
len(traffic_data['Idle Mean'].unique().tolist()))
284/14:
print(len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Active Min'].unique().tolist()),
len(traffic_data['Active Std'].unique().tolist()),
len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Min'].unique().tolist()),
len(traffic_data['Bwd IAT Std'].unique().tolist()),
len(traffic_data['Flow Bytes/s'].unique().tolist()),
len(traffic_data['Flow Duration'].unique().tolist()),
len(traffic_data['Flow IAT Max'].unique().tolist()),
len(traffic_data['Flow IAT Mean'].unique().tolist()),
len(traffic_data['Flow IAT Min'].unique().tolist()),
len(traffic_data['Fwd IAT Std'].unique().tolist()))
284/15:
print(len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Min'].unique().tolist()),
len(traffic_data['Bwd IAT Std'].unique().tolist()),
len(traffic_data['Flow Bytes/s'].unique().tolist()),
len(traffic_data['Flow Duration'].unique().tolist()),
len(traffic_data['Flow IAT Max'].unique().tolist()),
len(traffic_data['Flow IAT Mean'].unique().tolist()),
len(traffic_data['Flow IAT Min'].unique().tolist()),
len(traffic_data['Fwd IAT Std'].unique().tolist()))
284/16:
print(len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Min'].unique().tolist()),
len(traffic_data['Bwd IAT Std'].unique().tolist()),
len(traffic_data['Flow Bytes/s'].unique().tolist()),
len(traffic_data['Flow Duration'].unique().tolist()),
len(traffic_data['Flow IAT Max'].unique().tolist()),
len(traffic_data['Flow IAT Mean'].unique().tolist()),
len(traffic_data['Flow IAT Min'].unique().tolist()),
len(traffic_data['Fwd IAT Std'].unique().tolist()))
284/17:
print(len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Min'].unique().tolist()),
len(traffic_data['Bwd IAT Std'].unique().tolist()),
len(traffic_data['Flow Bytes/s'].unique().tolist()),
len(traffic_data['Flow Duration'].unique().tolist()),
len(traffic_data['Flow IAT_Max'].unique().tolist()),
len(traffic_data['Flow IAT_Mean'].unique().tolist()),
len(traffic_data['Flow IAT_Min'].unique().tolist()),
len(traffic_data['Fwd IAT_Std'].unique().tolist()))
284/18:
print(len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Max'].unique().tolist()),
len(traffic_data['Bwd IAT Min'].unique().tolist()),
len(traffic_data['Bwd IAT Std'].unique().tolist()),
len(traffic_data['Flow Bytes/s'].unique().tolist()),
len(traffic_data['Flow Duration'].unique().tolist()),
len(traffic_data['Flow IAT_Max'].unique().tolist()),
len(traffic_data['Flow IAT_Mean'].unique().tolist()),
len(traffic_data['Flow IAT_Min'].unique().tolist()),
len(traffic_data['Fwd IAT Std'].unique().tolist()))
284/19:
print(len(traffic_data[].unique().tolist()),
len(traffic_data['Idle Min'].unique().tolist()),
len(traffic_data['Idle Std'].unique().tolist()),
len(traffic_data['Bwd IAT Mean'].unique().tolist()),
len(traffic_data['Active Mean'].unique().tolist()),
len(traffic_data['Idle Mean'].unique().tolist()))
284/20:
print(len(traffic_data['Idle Max'].unique().tolist()),
len(traffic_data[' Idle Min'].unique().tolist()),
len(traffic_data[' Idle Std'].unique().tolist()),
len(traffic_data['Bwd IAT Mean'].unique().tolist()),
len(traffic_data['Active Mean'].unique().tolist()),
len(traffic_data['Idle Mean'].unique().tolist()))
284/21:
print(
len(traffic_data['Bwd IAT Mean'].unique().tolist()),
len(traffic_data['Active Mean'].unique().tolist()))
284/22: len(traffic_data['Flow IAT_Mean'].unique().tolist())
285/1:
import pandas as pd
import numpy as np
285/2: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv', low_memory=False)
285/3: tor_nontor_data.index
285/4: tor_nontor_data.head()
285/5: tor_nontor_data.columns
285/6:
df = tor_nontor_data[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
df = df.dropna()
df = df[:-1]
285/7: df.drop_duplicates(keep=False, inplace=True)
285/8:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']]
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
285/9:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']]
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
285/10:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
285/11:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
285/12: yn = le.fit_transform(y)
285/13: np.unique(yn)
285/14:
from sklearn.model_selection import train_test_split
from sklearn import metrics
285/15: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
285/16: X_train.shape
285/17: X_test.shape
285/18: y_train.shape
285/19: y_test.shape
285/20: y_test
285/21:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
285/22:
def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
285/23: ns_probs = [0 for _ in range(len(y_test))]
285/24: trial1 = random_forest_classifier(X_train, y_train)
280/36:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
280/37:
import pandas as pd
import numpy as np
280/38:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv', low_memory=False)
df = tor_nontor_data[[]].copy()
df = df.dropna()
df = df[:14508]
280/39: df.drop_duplicates(keep=False, inplace=True)
280/40:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv', low_memory=False)
df = tor_nontor_data[[]].copy()
df = df.dropna()
df = df[:-1]
280/41: df.drop_duplicates(keep=False, inplace=True)
280/42:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv', low_memory=False)
df = tor_nontor_data[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
df = df.dropna()
df = df[:-1]
280/43: df.drop_duplicates(keep=False, inplace=True)
280/44:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
280/45:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
280/46: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
280/47:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
280/48:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
280/49:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
280/50:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
280/51:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
280/52: !pip install seaborn
286/1:
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
286/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv', low_memory=False)
df = tor_nontor_data[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
df = df.dropna()
df = df[:-1]
286/3: sns.boxplot(data=df)
286/4: df.head()
286/5: sns.violinplot(data=df)
286/6: plt = sns.boxplot(data=df)
286/7:
plt = sns.boxplot(data=df)
plt.xticks(rotation='vertical')
286/8:
plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation='180')
286/9:
plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=180)
286/10:
plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/11:
sns.violinplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/12:
plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/13:
sns.violinplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/14:
plt = sns.violinplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/15:
plt = sns.boxplot(data=df)
plt.figure(figsize=(16,6))
plt.tick_params(axis='x', labelrotation=90)
286/16:
plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/17:
plt = sns.swarmplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/18:
corr = df.corr()
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/19: type(plt)
286/20:
corr = df.corr()
sns.set(rc={'figure.figure':(16,6)})
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/21:
from matplotlib import rcParams
rcParams['figure.figure'] = 16,6
corr = df.corr()
# sns.set(rc={'figure.figure':(16,6)})
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/22: rcParams.keys()
286/23:
corr = df.corr()
fig, axplt = sns.heatmap(corr)
ax.tick_params(axis='x', labelrotation=90)
286/24:
corr = df.corr()
fig, ax = plt.subplots()
fig.set_size_inches(16,6)
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/25:
import matplotlib.pyplot as mplt
corr = df.corr()
fig, ax = mplt.subplots()
fig.set_size_inches(16,6)
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/26:
import matplotlib.pyplot as mplt
corr = df.corr()
fig, ax = mplt.subplots()
fig.set_size_inches(16,16)
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/27:
import matplotlib.pyplot as mplt
corr = df.corr()
fig, ax = mplt.subplots()
fig.set_size_inches(10,10)
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/28:
fig, ax = mplt.subplots()
fig.set_size_inches(16,10)

plt = sns.violinplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/29:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.violinplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/30:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
286/31:
import matplotlib.pyplot as mplt
corr = df.corr()
fig, ax = mplt.subplots()
fig.set_size_inches(12,10)
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
286/32: df.drop_duplicates(keep=False, inplace=True)
286/33: df['Label'].unique()
286/34:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/35: y[0]
286/36:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
286/37: y[0]
286/38:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/39: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/40:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/41:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/42:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/43:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/44: y_train[0]
286/45: y_test[0]
286/46: type(y_test[0])
286/47:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(y_train[0])
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/48:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/49:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/50:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/51:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/52:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/53:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/54:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/55: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/56:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/57:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/58:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/59: type(y_test[0])
286/60:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/61:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/62:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/63:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/64: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/65:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/66:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/67:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/68: type(y_test[0])
286/69:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/70:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/71:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
286/72:
data = df[[u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/73: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/74:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/75:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/76: type(y_test[0])
286/77:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/78:
data = df[[u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/79:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/80: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/81:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/82:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/83:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/84: type(y_test[0])
286/85:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/86:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/87:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
286/88:
data = df[[
       u'Flow Packets/s',u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Std',
       u'Fwd IAT Min',  u'Bwd IAT Std', ]].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/89:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/90: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/91:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/92:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/93:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/94: type(y_test[0])
286/95:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/96:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/97:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
286/98:
data = df[['Flow Duration'
       u'Flow Packets/s',u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Std',
       u'Fwd IAT Min',  u'Bwd IAT Std', ]].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/99:
data = df[[u'Flow Duration',
       u'Flow Packets/s',u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Std',
       u'Fwd IAT Min',  u'Bwd IAT Std', ]].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/100:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/101: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/102:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/103:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/104:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/105: type(y_test[0])
286/106:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/107:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/108:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
286/109:
from sklearn import metrics
import scikitplot

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred_gini)
286/110:
from sklearn import metrics

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred_gini)
auc = metrics.roc_auc_score(y_test, y_pred_gini)
mplt.plot(fpr, tpr)
mplt.show()
286/111: !pip install scikitplot
287/1:
import pandas as pd
import numpy as np
287/2: tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv', low_memory=False)
287/3: tor_nontor_data.columns
287/4:
df = tor_nontor_data[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min', u'Label']].copy()
df = df.dropna()
df = df[:-1]
287/5: df.drop_duplicates(keep=False, inplace=True)
287/6:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min']]
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
287/7:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
287/8:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
287/9: yn = le.fit_transform(y)
287/10: np.unique(yn)
287/11:
from sklearn.model_selection import train_test_split
from sklearn import metrics
287/12: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
287/13: X_train.shape
287/14: X_test.shape
287/15: y_train.shape
287/16: y_test.shape
287/17: y_test
287/18:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
287/19:
def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
287/20: ns_probs = [0 for _ in range(len(y_test))]
287/21: trial1 = random_forest_classifier(X_train, y_train)
287/22:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
287/23: y_pred
287/24:
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
287/25: len(np.unique(yn))
287/26: y_test[0]
287/27:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
287/28:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
287/29: cal_accuracy(y_test, y_pred)
287/30: y_pred = np.around(y_pred)
287/31: y_pred
287/32: y_test
287/33: np.around(y_test)
287/34:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
287/35: y_pred
287/36: y_pred
287/37: cal_accuracy(y_test, y_pred.astype(int))
286/112:
data = df[[u'Flow Duration',
       u'Flow Packets/s',u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Std',
       u'Fwd IAT Min',  u'Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/113:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/114: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/115:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/116:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/117:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/118: type(y_test[0])
286/119:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/120:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/121:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
286/122:
from sklearn import metrics

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred_gini)
auc = metrics.roc_auc_score(y_test, y_pred_gini)
mplt.plot(fpr, tpr)
mplt.show()
287/38: len(tor_nontor_data.columns)
286/123: df.columns
286/124: len(df.columns)
286/125: df.columns
286/126: df.Label.unique()
286/127:
data = df[[u'Flow Duration', u'Flow Bytes/s',
       u'Flow Packets/s', u'Flow IAT_Mean', u'Flow IAT_Std', u'Flow IAT_Max',
       u'Flow IAT_Min', u'Fwd IAT Mean', u'Fwd IAT Std', u'Fwd IAT Max',
       u'Fwd IAT Min', u'Bwd IAT Mean', u'Bwd IAT Std', u'Bwd IAT Max',
       u'Bwd IAT Min']].copy()
X = data.to_numpy()
y = df['Label']
y = y.to_numpy()
286/128:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
286/129: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
286/130:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/131:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/132:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/133: type(y_test[0])
286/134:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/135:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/136:
print("Results Using Entropy:") 
# Prediction using entropy 
y_pred_entropy = prediction(X_test, clf_entropy) 
cal_accuracy(y_test, y_pred_entropy)
286/137:
from sklearn import metrics

fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred_gini)
auc = metrics.roc_auc_score(y_test, y_pred_gini)
mplt.plot(fpr, tpr)
mplt.show()
286/138:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
print(cal_accuracy(y_test, y_pred_gini)       )
286/139:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.violinplot(data=[df - df['Flow Duration']])
plt.tick_params(axis='x', labelrotation=90)
286/140:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)
data = df.drop(columns='Flow Duration')
plt = sns.violinplot(data)
plt.tick_params(axis='x', labelrotation=90)
286/141:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)
df_temp = df.drop(columns='Flow Duration')
plt = sns.violinplot(data=df_temp)
plt.tick_params(axis='x', labelrotation=90)
286/142:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)
df_temp = df.drop(columns=['Flow Duration', 'Flow IAT_Max', 'Fwd IAT Max', 'Bwd IAT Max'])
plt = sns.violinplot(data=df_temp)
plt.tick_params(axis='x', labelrotation=90)
286/143:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)
df_temp = df.drop(columns=['Flow Duration', 'Flow IAT_Max', 'Fwd IAT Max', 'Bwd IAT Max', 'Flow IAT_Min', 'Fwd IAT Min', 'Bwd IAT Min'])
plt = sns.violinplot(data=df_temp)
plt.tick_params(axis='x', labelrotation=90)
288/1: import pandas as pd
288/2: import pandas as pd
288/3:
traffic_data = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv')
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
288/4: traffic_data.shape
288/5: tor_nontor_data.shape
288/6: tor_nontor_data.columns
288/7:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
288/8:
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
288/9:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
288/10:
import pandas as pd
import numpy as np
from matplotlib import pyplot as mplt
import seaborn as sns
288/11:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
288/12:
df = tor_nontor_data[[u'Source IP', u' Source Port', u' Destination IP', u' Destination Port',
       u' Protocol', u' Flow Duration', u' Flow Bytes/s', u' Flow Packets/s',
       u' Flow IAT Mean', u' Flow IAT Std', u' Flow IAT Max', u' Flow IAT Min',
       u'Fwd IAT Mean', u' Fwd IAT Std', u' Fwd IAT Max', u' Fwd IAT Min',
       u'Bwd IAT Mean', u' Bwd IAT Std', u' Bwd IAT Max', u' Bwd IAT Min',
       u'Active Mean', u' Active Std', u' Active Max', u' Active Min',
       u'Idle Mean', u' Idle Std', u' Idle Max', u' Idle Min']].copy()
288/13:
fig, ax = mplt.subplots()
fig.set_size_inches(16,8)

plt = sns.boxplot(data=df)
plt.tick_params(axis='x', labelrotation=90)
288/14:
import matplotlib.pyplot as mplt
corr = df.corr()
fig, ax = mplt.subplots()
fig.set_size_inches(12,10)
plt = sns.heatmap(corr)
plt.tick_params(axis='x', labelrotation=90)
288/15:
from sklearn import preprocessing

x = df.values
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df_norm = pd.DataFrame(x_scaled)
288/16:
from sklearn import preprocessing

x = df.drop(columns=[u'Source IP', u' Source Port', u' Destination IP', u' Destination Port',
       u' Protocol']).values
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df_norm = pd.DataFrame(x_scaled)
288/17:
from sklearn import preprocessing

df_tmp = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]
x = df_tmp.drop(columns=[u'Source IP', u' Source Port', u' Destination IP', u' Destination Port',
       u' Protocol']).values
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df_norm = pd.DataFrame(x_scaled)
288/18:
from sklearn import preprocessing

df_tmp = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]
x = df_tmp.drop(columns=[u'Source IP', u' Source Port', u' Destination IP', u' Destination Port',
       u' Protocol', u' Flow Bytes/s']).values
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
df_norm = pd.DataFrame(x_scaled)
286/144:
lab_dataset = pd.read_csv('./Datasets/TorCSV/CSV/from_lab/Tor_VoIP_HTTP_Data.csv')
tor_non_tor = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-A/tor_non-tor_data.csv')
only_tor = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv')
286/145: tor_non_tor.head()
286/146: only_tor.head()
286/147: lab_dataset.head()
286/148: tor_non_tor.columns
286/149: only_tor.columns
286/150: lab_dataset.columns
286/151: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)
286/152:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/153:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/154:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/155: type(y_test[0])
286/156:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/157:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/158: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99)
286/159:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/160:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/161:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/162: type(y_test[0])
286/163:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/164:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
286/165: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.999)
286/166:
# Function to perform training with giniIndex. 
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
286/167:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
286/168:
unique_y = np.unique(y_train)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)

y_train = le.transform(y_train)

y_test = le.transform(y_test)
286/169: type(y_test[0])
286/170:
clf_gini = train_using_gini(X_train, X_test, y_train) 
clf_entropy = train_using_entropy(X_train, X_test, y_train)
286/171:
# Operational Phase 
print("Results Using Gini Index:") 
          
# Prediction using gini 
y_pred_gini = prediction(X_test, clf_gini) 
cal_accuracy(y_test, y_pred_gini)
283/70:
import pandas as pd
import numpy as np
290/1:
import pandas as pd
import numpy as np
290/2:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]
290/3: df.drop_duplicates(keep=False, inplace=True)
290/4:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
290/5:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
290/6:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
290/7: yn = le.fit_transform(y)
290/8: np.unique(yn)
290/9:
from sklearn.model_selection import train_test_split
from sklearn import metrics
290/10: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
290/11: X_train.shape
290/12: X_test.shape
290/13: y_train.shape
290/14: y_test.shape
290/15: y_test
290/16:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
290/17:
def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
290/18: ns_probs = [0 for _ in range(len(y_test))]
290/19: trial1 = random_forest_classifier(X_train, y_train)
290/20:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
290/21: y_pred
290/22:
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
290/23: len(np.unique(yn))
290/24: y_test[0]
290/25:
# Function to make predictions 
def prediction(X_test, clf_object): 
  
    # Predicton on test with giniIndex 
    y_pred = clf_object.predict(X_test) 
    print("Predicted values:") 
    print(y_pred) 
    return y_pred 
      
# Function to calculate accuracy 
def cal_accuracy(y_test, y_pred): 
      
    print("Confusion Matrix: ", 
        confusion_matrix(y_test, y_pred)) 
      
    print ("Accuracy : ", 
    accuracy_score(y_test,y_pred)*100) 
      
    print("Report : ", 
    classification_report(y_test, y_pred))
290/26:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report
290/27: cal_accuracy(y_test, y_pred)
290/28:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
290/29:
def decision_tree_classifier(features, target):
    clf = DecisionTreeClassifier()
    clf.fit(features, target)
    return clf

def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
290/30: dtcf = decision_tree_classifier(X_train, y_train)
290/31: y_pred = dtcf.predict_proba(X_test)
290/32: y_pred
290/33: y_test
290/34: len(y_pred)
290/35: len(y_pred[0])
290/36: len(y_pred[1])
290/37: len(y_pred[2])
290/38: len(y_pred[0].index(1))
290/39: len(y_pred[0].where(1))
290/40: np.where(y_pred[0] == 1)
290/41: np.where(y_pred[2] == 1)
290/42: np.where(y_pred[10] == 1)
290/43: np.where(y_pred[10] == 1)[0]
290/44: np.where(y_pred[10] == 1)[0][0]
290/45:
y_pred_temp = []
for i in y_pred:
    y_pred_temp.append(np.where(i == 1)[0][0])
290/46:
y_pred_temp = []
for i in y_pred:
    print(i)
    break
    y_pred_temp.append(np.where(i == 1)[0][0])
290/47:
y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(np.where(i == 1)[0])
290/48: y_pred_temp
290/49:
y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(np.where(i == 1)[0][0])
290/50: type(y_pred_temp)
290/51: type(y_pred_temp[0])
290/52:
y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(np.where(i == 1)[0].item)
290/53: type(y_pred_temp[0])
290/54: y_pred_temp
290/55:
y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(np.where(i == 1)[0])
290/56: y_pred_temp
290/57: y_test
290/58: np.concatenate(y_pred_temp, axis=0)
290/59: cal_accuracy(y_test, y_pred_temp)
290/60:
from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred_temp, normalize=False)
290/61:
correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp:
        correct += 1
print(correct)
290/62:
correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)
290/63: correct / len(y_pred_temp)
290/64: float(correct) / len(y_pred_temp)
290/65:
from sklearn.metrics import roc_curve, auc

fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(np.unique(yn)):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_temp[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
290/66:
from sklearn.metrics import roc_curve, auc

fpr = dict()
tpr = dict()
roc_auc = dict()
for i in np.unique(yn):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred_temp[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
290/67:
import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp



# Binarize the output
y = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6, 7])
n_classes = y.shape[1]

# Add noisy features to make the problem harder
random_state = np.random.RandomState(0)
n_samples, n_features = X.shape
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]

# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,
                                                    random_state=0)

# Learn to predict each class against the other
classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,
                                 random_state=random_state))
y_score = classifier.fit(X_train, y_train).decision_function(X_test)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
292/1:
import pandas as pd
import numpy as np

tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]

df.drop_duplicates(keep=False, inplace=True)

data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
292/2:
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
292/3:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
292/4:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
292/5: yn = le.fit_transform(y)
292/6: np.unique(yn)
292/7:
from sklearn.model_selection import train_test_split
from sklearn import metrics
292/8: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
292/9: X_train.shape
292/10: X_test.shape
292/11: y_train.shape
292/12: y_test.shape
292/13: y_test
292/14:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
292/15:
def decision_tree_classifier(features, target):
    clf = DecisionTreeClassifier()
    clf.fit(features, target)
    return clf

def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
292/16: dtcf = train_using_entropy(X_train, y_train)
292/17: dtcf = train_using_entropy(X_train, X_test, y_train)
292/18: y_pred = dtcf.predict_proba(X_test)
292/19:
y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(np.where(i == 1)[0])
292/20: np.concatenate(y_pred_temp, axis=0)
292/21: y_pred
292/22: y_test
292/23: y_pred[0]
292/24: y_pred[0].max
292/25: y_pred[0].max()
292/26: y_pred[0].argmax()
292/27:
y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())
292/28: np.concatenate(y_pred_temp, axis=0)
292/29:
correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)
292/30: float(correct) / len(y_pred_temp)
292/31:
dtcf = train_using_entropy(X_train, X_test, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/32:
dtcf = train_using_gini(X_train, X_test, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/33: trial1 = random_forest_classifier(X_train, y_train)
292/34:
y_pred = trial1.predict_proba(X_test)
y_pred = y_pred[:, 1]
292/35: y_pred
292/36: len(y_pred)
293/1:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:-1]
293/2:
import pandas as pd
import numpy as np
293/3:
tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:-1]
293/4: df.drop_duplicates(keep=False, inplace=True)
293/5:
data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
293/6:
from sklearn.metrics import confusion_matrix 
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 
from sklearn.neural_network import MLPClassifier
293/7: from sklearn import preprocessing
293/8:
x = data.values 
min_max_scaler = preprocessing.MinMaxScaler()
x_scaled = min_max_scaler.fit_transform(x)
data = pd.DataFrame(x_scaled)
293/9:
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
293/10: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
293/11:
mlp = MLPClassifier(hidden_layer_sizes=(1000, 100, 10), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
293/12:
mlp = MLPClassifier(hidden_layer_sizes=(1000, 100, 100, 10), max_iter=150, alpha=1e-4,
                    solver='sgd', verbose=10, tol=1e-4, random_state=1,
                    learning_rate_init=.1)
mlp.fit(X_train, y_train)
292/37:
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import roc_auc_score

lb = LabelBinarizer()
lb.fit(y_test)

y_test = lb.transform(y_test)
y_pred_temp = lb.transform(y_pred_temp)

print(roc_auc_score(y_test, y_pred_temp, average='macro'))
292/38:
dtcf = train_using_entropy(X_train, X_test, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/39:
import pandas as pd
import numpy as np

tor_nontor_data = pd.read_csv('./Datasets/TorCSV/CSV/Scenario-B/traffic_labelled_data.csv', low_memory=False)
df = tor_nontor_data[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std', 'label']].copy()
df = df.dropna()
df = df[:14508]

df.drop_duplicates(keep=False, inplace=True)

data = df[[' Flow Duration', ' Flow Packets/s', ' Flow Bytes/s', ' Fwd IAT Max', 
                     'Fwd IAT Mean', ' Fwd IAT Std', ' Bwd IAT Max', 'Bwd IAT Mean', ' Bwd IAT Std']].copy()
X = data.to_numpy()
y = df['label']
y = y.to_numpy()
292/40:
def train_using_gini(X_train, X_test, y_train): 
  
    # Creating the classifier object 
    clf_gini = DecisionTreeClassifier(criterion = "gini", 
            random_state = 100,max_depth=3, min_samples_leaf=5) 
  
    # Performing training 
    print(type(y_train[0]))
    clf_gini.fit(X_train, y_train) 
    return clf_gini 
      
# Function to perform training with entropy. 
def train_using_entropy(X_train, X_test, y_train): 
  
    # Decision tree with entropy 
    clf_entropy = DecisionTreeClassifier( 
            criterion = "entropy", random_state = 100, 
            max_depth = 3, min_samples_leaf = 5) 
  
    # Performing training 
    clf_entropy.fit(X_train, y_train) 
    return clf_entropy
292/41:
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
292/42:
unique_y = np.unique(y)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

le.fit(unique_y)


y = le.transform(y)
292/43: yn = le.fit_transform(y)
292/44: np.unique(yn)
292/45:
from sklearn.model_selection import train_test_split
from sklearn import metrics
292/46: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
292/47: X_train.shape
292/48: X_test.shape
292/49: y_train.shape
292/50: y_test.shape
292/51: y_test
292/52:
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
292/53:
def decision_tree_classifier(features, target):
    clf = DecisionTreeClassifier()
    clf.fit(features, target)
    return clf

def random_forest_classifier(features, target):
    clf = RandomForestClassifier()
    clf.fit(features, target)
    return clf
292/54:
dtcf = train_using_entropy(X_train, X_test, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/55:
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import roc_auc_score

lb = LabelBinarizer()
lb.fit(y_test)

y_test = lb.transform(y_test)
y_pred_temp = lb.transform(y_pred_temp)

print(roc_auc_score(y_test, y_pred_temp, average='macro'))
292/56:
dtcf = train_using_gini(X_train, X_test, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/57: X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
292/58:
dtcf = train_using_gini(X_train, X_test, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/59:
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import roc_auc_score

lb = LabelBinarizer()
lb.fit(y_test)

y_test = lb.transform(y_test)
y_pred_temp = lb.transform(y_pred_temp)

print(roc_auc_score(y_test, y_pred_temp, average='macro'))
292/60:
dtcf = decision_tree_classifier(X_train, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/61:
X_train, X_test, y_train, y_test = train_test_split(X, yn, test_size=0.3)
dtcf = decision_tree_classifier(X_train, y_train)

y_pred = dtcf.predict_proba(X_test)

y_pred[0].argmax()

y_pred_temp = []
for i in y_pred:
#     print(i)
#     break
    y_pred_temp.append(i.argmax())

y_test

correct = 0
for i in range(len(y_pred_temp)):
    if y_test[i] == y_pred_temp[i]:
        correct += 1
print(correct)

print(float(correct) / len(y_pred_temp))
292/62:
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import roc_auc_score

lb = LabelBinarizer()
lb.fit(y_test)

y_test = lb.transform(y_test)
y_pred_temp = lb.transform(y_pred_temp)

print(roc_auc_score(y_test, y_pred_temp, average='macro'))
286/172: len(lab_dataset)
286/173: len(tor_non_tor)
286/174: len(only_tor)
286/175: tor_nontor_data['label'].unique()
286/176: tor_non_tor['label']
286/177: tor_non_tor['label'].unique()
286/178: len([tor_non_tor[tor_non_tor['label'] == 'TOR'])
286/179: len([tor_non_tor[tor_non_tor['label'] == 'TOR']])
286/180: len([tor_non_tor['label'] == 'TOR'])
286/181: tor_non_tor.groupby('label').count()
286/182: only_tor.groupby('label').count()
286/183: df.groupby('VoIP').count()
286/184: df['label'].groupby('VoIP').count()
286/185: df['Label'].groupby('VoIP').count()
286/186: df.Label.groupby('VoIP').count()
286/187: lab_dataset.groupby('Label').count()
286/188: 2500 * 30.0 / 60
286/189: 2500 * 30.0 / (60 * 60)
299/1:
from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
299/2:
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
299/3:
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
299/4:
model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)
300/1:
try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
300/2:
from __future__ import absolute_import, division, print_function, unicode_literals

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)
300/3:
fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
300/4:
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
300/5: train_images.shape
300/6: len(train_labels)
300/7: train_labels
300/8: test_images.shape
300/9: len(test_labels)
300/10:
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
300/11:
plt.figure()
plt.imshow(train_images[1])
plt.colorbar()
plt.grid(False)
plt.show()
300/12:
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
300/13:
train_images = train_images / 255.0

test_images = test_images / 255.0
300/14:
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()
300/15:
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
300/16:
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
300/17: model.fit(train_images, train_labels, epochs=10)
300/18:
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)
300/19: predictions = model.predict(test_images)
300/20: predictions[0]
300/21: np.argmax(predictions[0])
300/22: test_labels[0]
300/23:
def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array, true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array, true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')
300/24:
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()
300/25:
i = 12
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()
300/26:
i = 12
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()
300/27:
# Plot the first X test images, their predicted labels, and the true labels.
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()
300/28:
# Grab an image from the test dataset.
img = test_images[1]

print(img.shape)
300/29:
# Add the image to a batch where it's the only member.
img = (np.expand_dims(img,0))

print(img.shape)
300/30:
predictions_single = model.predict(img)

print(predictions_single)
300/31:
plot_value_array(1, predictions_single[0], test_labels)
_ = plt.xticks(range(10), class_names, rotation=45)
300/32: np.argmax(predictions_single[0])
301/1:
try:
  # %tensorflow_version only exists in Colab.
  %tensorflow_version 2.x
except Exception:
  pass
301/2:
from __future__ import absolute_import, division, print_function, unicode_literals
import functools

import numpy as np
import tensorflow as tf
301/3:
TRAIN_DATA_URL = "https://storage.googleapis.com/tf-datasets/titanic/train.csv"
TEST_DATA_URL = "https://storage.googleapis.com/tf-datasets/titanic/eval.csv"

train_file_path = tf.keras.utils.get_file("train.csv", TRAIN_DATA_URL)
test_file_path = tf.keras.utils.get_file("eval.csv", TEST_DATA_URL)
301/4:
# Make numpy values easier to read.
np.set_printoptions(precision=3, suppress=True)
301/5: !head {train_file_path}
301/6:
LABEL_COLUMN = 'survived'
LABELS = [0, 1]
301/7:
def get_dataset(file_path, **kwargs):
  dataset = tf.data.experimental.make_csv_dataset(
      file_path,
      batch_size=5, # Artificially small to make examples easier to show.
      label_name=LABEL_COLUMN,
      na_value="?",
      num_epochs=1,
      ignore_errors=True, 
      **kwargs)
  return dataset

raw_train_data = get_dataset(train_file_path)
raw_test_data = get_dataset(test_file_path)
301/8:
def show_batch(dataset):
  for batch, label in dataset.take(1):
    for key, value in batch.items():
      print("{:20s}: {}".format(key,value.numpy()))
301/9: show_batch(raw_train_data)
301/10:
try:
  import tensorflow.compat.v2 as tf
except Exception:
  pass

tf.enable_v2_behavior()

print(tf.__version__)
301/11:
try:
  import tensorflow.compat.v2 as tf
except Exception:
  pass

tf.enable_v2_behavior()

print(tf.__version__)
301/12:
try:
  import tensorflow.compat.v2 as tf
except Exception:
  pass

tf.enable_v2_behavior()

print(tf.__version__)
301/13: tf.enable_eager_execution()
301/14:
tf.enable_eager_execution(
    config=None,
    device_policy=None,
    execution_mode=None
)
301/15: from __future__ import absolute_import, division, print_function, unicode_literals
301/16:
try:
  import tensorflow.compat.v2 as tf
except Exception:
  pass

tf.enable_v2_behavior()

print(tf.__version__)
302/1: from __future__ import absolute_import, division, print_function, unicode_literals
302/2:
try:
  import tensorflow.compat.v2 as tf
except Exception:
  pass

tf.enable_v2_behavior()

print(tf.__version__)
302/3:
from __future__ import absolute_import, division, print_function, unicode_literals
import functools

import numpy as np
import tensorflow as tf
302/4:
TRAIN_DATA_URL = "https://storage.googleapis.com/tf-datasets/titanic/train.csv"
TEST_DATA_URL = "https://storage.googleapis.com/tf-datasets/titanic/eval.csv"

train_file_path = tf.keras.utils.get_file("train.csv", TRAIN_DATA_URL)
test_file_path = tf.keras.utils.get_file("eval.csv", TEST_DATA_URL)
302/5:
# Make numpy values easier to read.
np.set_printoptions(precision=3, suppress=True)
302/6: !head {train_file_path}
302/7:
LABEL_COLUMN = 'survived'
LABELS = [0, 1]
302/8:
def get_dataset(file_path, **kwargs):
  dataset = tf.data.experimental.make_csv_dataset(
      file_path,
      batch_size=5, # Artificially small to make examples easier to show.
      label_name=LABEL_COLUMN,
      na_value="?",
      num_epochs=1,
      ignore_errors=True, 
      **kwargs)
  return dataset

raw_train_data = get_dataset(train_file_path)
raw_test_data = get_dataset(test_file_path)
302/9:
def show_batch(dataset):
  for batch, label in dataset.take(1):
    for key, value in batch.items():
      print("{:20s}: {}".format(key,value.numpy()))
302/10: show_batch(raw_train_data)
302/11:
CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']

temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)

show_batch(temp_dataset)
302/12:
SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']

temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)

show_batch(temp_dataset)
302/13:
SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']
DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]
temp_dataset = get_dataset(train_file_path, 
                           select_columns=SELECT_COLUMNS,
                           column_defaults = DEFAULTS)

show_batch(temp_dataset)
302/14: example_batch, labels_batch = next(iter(temp_dataset))
302/15:
def pack(features, label):
  return tf.stack(list(features.values()), axis=-1), label
302/16:
packed_dataset = temp_dataset.map(pack)

for features, labels in packed_dataset.take(1):
  print(features.numpy())
  print()
  print(labels.numpy())
302/17: show_batch(raw_train_data)
302/18: example_batch, labels_batch = next(iter(temp_dataset))
302/19:
class PackNumericFeatures(object):
  def __init__(self, names):
    self.names = names

  def __call__(self, features, labels):
    numeric_features = [features.pop(name) for name in self.names]
    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]
    numeric_features = tf.stack(numeric_features, axis=-1)
    features['numeric'] = numeric_features

    return features, labels
302/20:
NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']

packed_train_data = raw_train_data.map(
    PackNumericFeatures(NUMERIC_FEATURES))

packed_test_data = raw_test_data.map(
    PackNumericFeatures(NUMERIC_FEATURES))
302/21: show_batch(packed_train_data)
302/22: example_batch, labels_batch = next(iter(packed_train_data))
302/23:
import pandas as pd
desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()
desc
302/24:
MEAN = np.array(desc.T['mean'])
STD = np.array(desc.T['std'])
302/25:
def normalize_numeric_data(data, mean, std):
  # Center the data
  return (data-mean)/std
302/26:
# See what you just created.
normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)

numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])
numeric_columns = [numeric_column]
numeric_column
302/27: example_batch['numeric']
302/28:
numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)
numeric_layer(example_batch).numpy()
302/29:
CATEGORIES = {
    'sex': ['male', 'female'],
    'class' : ['First', 'Second', 'Third'],
    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],
    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],
    'alone' : ['y', 'n']
}
307/1:
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn.functional as F
307/2:
#Dataset preparation

ds = np.lib.DataSource()
fp = ds.open('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')

x = np.genfromtxt(BytesIO(fp.read().encode()), delimiter=',', usecols=range(2), max_rows=100)
y = np.zeros(100)
y[50:] = 1

np.random.seed(1)
idx = np.arange(y.shape[0])
np.random.shuffle(idx)
X_test, y_test = x[idx[:25]], y[idx[:25]]
X_train, y_train = x[idx[25:]], y[idx[25:]]
mu, std = np.mean(X_train, axis=0), np.std(X_train, axis=0)
X_train, X_test = (X_train - mu) / std, (X_test - mu) / std

fig, ax = plt.subplots(1, 2, figsize=(7, 2.5))
ax[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1])
ax[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1])
ax[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1])
ax[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1])
plt.show()
307/3:
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from io import BytesIO
import torch
import torch.nn.functional as F
307/4:
#Dataset preparation

ds = np.lib.DataSource()
fp = ds.open('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')

x = np.genfromtxt(BytesIO(fp.read().encode()), delimiter=',', usecols=range(2), max_rows=100)
y = np.zeros(100)
y[50:] = 1

np.random.seed(1)
idx = np.arange(y.shape[0])
np.random.shuffle(idx)
X_test, y_test = x[idx[:25]], y[idx[:25]]
X_train, y_train = x[idx[25:]], y[idx[25:]]
mu, std = np.mean(X_train, axis=0), np.std(X_train, axis=0)
X_train, X_test = (X_train - mu) / std, (X_test - mu) / std

fig, ax = plt.subplots(1, 2, figsize=(7, 2.5))
ax[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1])
ax[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1])
ax[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1])
ax[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1])
plt.show()
307/5: device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
307/6: device
307/7:
def custom_where(cond, x_1, x_2):
    return (cond * x_1) + ((1 - cond) * x_2)
307/8:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self.sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print("Epoch: &03d" %(e+1), end = "")
            print(" | Train ACC: %.3f" % self.evaluate(x, y), end = "")
            print(" | Cost: %.3f" % self.logit_cost(y, self.forward(x)))
307/9:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self.sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print("Epoch: &03d" %(e+1), end="")
            print(" | Train ACC: %.3f" % self.evaluate(x, y), end="")
            print(" | Cost: %.3f" % self.logit_cost(y, self.forward(x)))
307/10:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self.sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print('Epoch: &03d' %(e+1), end="")
            print(" | Train ACC: %.3f" % self.evaluate(x, y), end="")
            print(" | Cost: %.3f" % self.logit_cost(y, self.forward(x)))
307/11:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self.sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
#             print('Epoch: %03d' % (e+1), end="")
            print('Epoch: &03d' % (e+1), end="")
            print(" | Train ACC: %.3f" % self.evaluate(x, y), end="")
            print(" | Cost: %.3f" % self.logit_cost(y, self.forward(x)))
307/12:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self.sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print('Epoch: %03d' % (e+1), end="")
            print(' | Train ACC: %.3f' % self.evaluate(x, y), end="")
            print(' | Cost: %.3f' % self._logit_cost(y, self.forward(x)))
#             print('Epoch: &03d' % (e+1), end="")
#             print(" | Train ACC: %.3f" % self.evaluate(x, y), end="")
#             print(" | Cost: %.3f" % self.logit_cost(y, self.forward(x)))
307/13:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self.sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print('Epoch: %03d' % (e+1), 
                  ' | Train ACC: %.3f' % self.evaluate(x, y), 
                  ' | Cost: %.3f' % self._logit_cost(y, self.forward(x)))
307/14:
X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)

logr = LogisticRegression1(num_features=2)
logr.train(X_train_tensor, y_train_tensor, num_epochs = 10, learning_rate = 0.1)

print('\nModel parameters:')
print('  Weights: %s' % logr.weights)
print('  Bias: %s' % logr.bias)
307/15:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self._sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def _sigmoid():
        return 1. / (1. + torch.exp(-z))
        
    def _logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print('Epoch: %03d' % (e+1), 
                  ' | Train ACC: %.3f' % self.evaluate(x, y), 
                  ' | Cost: %.3f' % self._logit_cost(y, self.forward(x)))
307/16:
X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)

logr = LogisticRegression1(num_features=2)
logr.train(X_train_tensor, y_train_tensor, num_epochs = 10, learning_rate = 0.1)

print('\nModel parameters:')
print('  Weights: %s' % logr.weights)
print('  Bias: %s' % logr.bias)
307/17:
class LogisticRegression1():
    def __init__(self, num_features):
        self.num_features = num_features
        self.weights = torch.zeros(num_features, 1, dtype=torch.float32, device=device)
        self.bias = torch.zeros(1, dtype=torch.float32, device=device)
        
    def forward(self, x):
        linear = torch.add(torch.mm(x, self.weights), self.bias)
        probas = self._sigmoid(linear)
        return probas
    
    def backward(self, probas, y):
        errors = y - probas.view(-1)
        return errors
    
    def predict_labels(self, x):
        probas = self.forward(x)
        labels = custom_where(probas >= .5,1,0)
        return labels
    
    def evaluate(self, x, y):
        labels = self.predict_labels(x).float()
        accuracy = torch.sum(labels.view(-1) == y) / y.size()[0]
        return accuracy
        
    def _sigmoid(self, z):
        return 1. / (1. + torch.exp(-z))
        
    def _logit_cost(self, y, proba):
        tmp1 = torch.mm(-y.view(1, -1), torch.log(proba))
        tmp2 = torch.mm((1 - y).view(1, -1), torch.log(proba))
        return tmp1 - tmp2
        
    def train(self, x, y, num_epochs, learning_rate = 0.01):
        for e in range(num_epochs):
            
            probas = self.forward(x)
            
            errors = self.backward(probas, y)
            neg_grad = torch.mm(x.transpose(0, 1), errors.view(-1, 1))
            
            self.weights += learning_rate * neg_grad
            self.bias += learning_rate * torch.sum(errors)
            
            print('Epoch: %03d' % (e+1), 
                  ' | Train ACC: %.3f' % self.evaluate(x, y), 
                  ' | Cost: %.3f' % self._logit_cost(y, self.forward(x)))
307/18:
X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=device)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=device)

logr = LogisticRegression1(num_features=2)
logr.train(X_train_tensor, y_train_tensor, num_epochs = 10, learning_rate = 0.1)

print('\nModel parameters:')
print('  Weights: %s' % logr.weights)
print('  Bias: %s' % logr.bias)
307/19:
X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=device)

test_acc = logr.evaluate(X_test_tensor, y_test_tensor)
print('Test set accuracy: %.2f%%' % (test_acc*100))
308/1:
from __future__ import print_function
import torch
308/2:
x = torch.empty(5,3)
print(x)
308/3:
x = torch.rand(5,3)
print(x)
308/4:
x = torch.zeros(5,3, dtype=torch.long)
print(x)
308/5:
x = torch.tensor(5.5, 3)
print(x)
308/6:
x = torch.tensor([5.5, 3])
print(x)
308/7: print(x.size())
308/8:
x = torch.rand(5,3)
y = torch.rand(5,3)
result = torch.empty(5,3)
torch.add(x,y, out=result)
print(result)
308/9: print(result[:,1])
308/10: print(result[:,0])
308/11: print(result[:5,0])
308/12: print(result[:3,0])
308/13: print(result[:1,0])
308/14: print(result[:0,0])
308/15: print(result[1:,0])
308/16: print(result[1:,:2])
308/17:
x = torch.randn(4,4)
y = x.view(16)
z = x.view(-1, 8)
print(x.size(), y.size(), z.size())
308/18:
x = torch.randn(1)
print(x)
print(x.item())
308/19:
if torch.cuda.is_available():
    device = torch.device("cuda")
    y = torch.ones_like(x, device=device)
    x = x.to(device)
    z = x + y
    print(z)
    print(z.to("cpu", torch.double))
309/1: import torch
309/2:
x = torch.ones(2,2, requires_grad=True)
print(x)
309/3:
y = x + 2
print(y)
309/4: print(y.grad_fn)
309/5:
z = y * y * 3
out = z.mean()
print(z, out)
309/6: out.backward()
309/7: print(x.grad)
309/8:
x = torch.randn(3, requires_grad= True)
y = x * 2
while y.data.norm() < 1000:
    y = y * 2
    
print(y)
310/1:
import torch
import torch.nn as nn
import torch.nn.functional as F
310/2:
class Net(nn.module):
    
    def __init__(self):
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        self.fc1 = nn.Linear(16*6*6, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features
310/3:
class Net(nn.Module):
    
    def __init__(self):
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        self.fc1 = nn.Linear(16*6*6, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features
310/4:
net = Net()
print(net)
310/5:
class Net(nn.Module):
    
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 3)
        self.conv2 = nn.Conv2d(6, 16, 3)
        self.fc1 = nn.Linear(16*6*6, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *= s
        return num_features
310/6:
net = Net()
print(net)
310/7:
params = list(net.parameters())
print(len(params))
print(params[0].size())
310/8:
input = torch.randn(1,1,32,32)
out = net(input)
print(out)
310/9:
net.zero_grad()
out.backward(torch.randn(1, 10))
310/10:
output = net(input)
target = torch.randn(10)
target = target.view(1, -1)
criterion = nn.MSELoss()

loss = criterion(output, target)
print(loss)
310/11: print(loss.grad_fn)
310/12: print(loss.grad_fn.next_functions[0][0])
310/13: print(loss.grad_fn.next_functions[0][0].next_functions[0][0])
310/14:
net.zero_grad()

print('conv1.bias.grad before backward')
print(net.conv1.bias.grad)
310/15: loss.backward()
310/16:
print('conv1.bias.grad after backward')
print(net.conv1.bias.grad)
310/17:
learning_rate = 0.01
for f in net.parameters():
    f.data.sub_(f.grad.data * learning_rate)
310/18:
import torch.optim as optim

optimizer = optim.SGD(net.parameters(), lr = 0.01)

optimizer.zero_grad()
output = net(input)
loss = criterion(input, target)
loss.backward()
optimizer.step()
311/1:
import torch
import torchvision
import torchvision.transforms as transforms
311/2:
transform = transforms.Compose(
            [transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root = './data', train= True, download= True, transform= transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size= 4, shuffle= True, num_workers= 2)

testset = torchvision.datasets.CIFAR10(root = './data', train= False, download= True, transform= transform)
testloader = torch.utils.data.DataLoader(testset, batch_size= 4, shuffle= False, num_workers= 2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
311/3:
import numpy as np
import matplotlib.pyplot as plt
311/4:
def imshow(img):
    img = img / 2 + 0.5
    npimp = img.numpy()
    plt.imshow(np.transpose(np.img, (1, 2, 0)))
    plt.show()
    
dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
311/5:
def imshow(img):
    img = img / 2 + 0.5
    npimp = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
    
dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
311/6:
def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
    
dataiter = iter(trainloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
311/7:
import torch
import torch.nn.functionas as F
311/8:
import torch
import torch.nn.functions as F
311/9:
import torch
import torch.nn.functional as F
311/10:
import torch.nn as nn
import torch.nn.functional as F
311/11:
class Net(nn.Module):
    
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    

net = Net()
311/12: import torch.optim as optim
311/13:
criterion  = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum= 0.9)
311/14:
for epoch in range(10):
    running_loss = 0.0
    for i,data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(ouputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        if i%2000 == 1999:
            print('[%d, %5d] loss: %.3f' % 
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
311/15:
for epoch in range(10):
    running_loss = 0.0
    for i,data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        if i%2000 == 1999:
            print('[%d, %5d] loss: %.3f' % 
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
311/16:
for epoch in range(2):
    running_loss = 0.0
    for i,data in enumerate(trainloader, 0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        if i%2000 == 1999:
            print('[%d, %5d] loss: %.3f' % 
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
311/17:
PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)
311/18:
dataiter = iter(testloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print('Ground truth: ', ' '.join('%5s' % classes[labels[j] for j in range(4)]))
311/19:
dataiter = iter(testloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print('Ground truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
311/20:
dataiter = iter(testloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print('Ground truth: '.join('%5s' % classes[labels[j]] for j in range(4)))
311/21:
dataiter = iter(testloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print('Ground truth: ', ''.join('%5s' % classes[labels[j]] for j in range(4)))
311/22:
dataiter = iter(testloader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))
print('Ground truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
311/23:
net = Net()
net.load_state_dict(torch.load(PATH))
311/24: outputs = net(images)
311/25:
_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join('%5s', % classes[predicted[j]] for j in range(4)))
311/26:
_, predicted = torch.max(outputs, 1)

print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))
311/27:
correct = 0 
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
print('Accuracy of the network on the 10000 test images: %d %%' %(100 * correct/total))
311/28:
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1
            
for i in range(10):
    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))
311/29:
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
311/30: net.to(device)
311/31: inputs, labels = data[0].to(device), data[1].to(device)
311/32:
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1
            
for i in range(10):
    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))
311/33:
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        inputs, labels = data[0].to(device), data[1].to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1
            
for i in range(10):
    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))
312/1:
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt
312/2:
epsilons = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]
pretrained_model = 'data/lenet_mnist_model.pth'
use_cuda = True
312/3:
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)
        
    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training= self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

    
test_loader = torch.utils.data.DataLoader(datasets.MNIST('../data', train=False, download = True,
                                                        transform = transforms.Compose([transforms.ToTensor(),])),
                                         batch_size=1, shuffle = True)

print('CUDA Available: ', torch.cuda.is_available())
device = torch.device("cuda" if (use_cuda and torch.cuda.is_available()) else "cpu")

model = Net().to(device)

model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))

model.eval()
312/4:
def fgsm_attack(image, epsilon, data_grad):
    sign_data_grad = data_grad.sign()
    perturbed_image = image + epsilon * sign_data_grad
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image
312/5:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    
    for data, target in test_loader:
        data, target = data.to(device), targer.to(device)
        data.requires_grad = True
        output = model(data)
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
            
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
312/6:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    
    for data, target in test_loader:
        data, target = data.to(device), targer.to(device)
        data.requires_grad = True
        output = model(data)
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
            
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            
            if (epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    
    final_acc = correct / float(len(test_loader))
    
    print('Epsilon: {}\tTest Accuracy = {} / {} = {}'.format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
312/7:
accuracies = []
examples = []

for eps in epsilons:
    acc, ex = test(model, device, test_loader, eps)
    accuracies.append(acc)
    examples.append(ex)
312/8:
def test(model, device, test_loader, epsilon):
    correct = 0
    adv_examples = []
    
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        data.requires_grad = True
        output = model(data)
        init_pred = output.max(1, keepdim = True)[1]
        
        if init_pred.item() != target.item():
            continue
            
        loss = F.nll_loss(output, target)
        
        model.zero_grad()
        
        loss.backward()
        
        data_grad = data.grad.data
        
        perturbed_data = fgsm_attack(data, epsilon, data_grad)
        
        output = model(perturbed_data)
        
        final_pred = output.max(1, keepdim = True)[1]
        
        if final_pred.item() == target.item():
            correct += 1
            
            if (epsilon == 0) and (len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
        else:
            if(len(adv_examples) < 5):
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))
                
    
    final_acc = correct / float(len(test_loader))
    
    print('Epsilon: {}\tTest Accuracy = {} / {} = {}'.format(epsilon, correct, len(test_loader), final_acc))
    
    return final_acc, adv_examples
312/9:
accuracies = []
examples = []

for eps in epsilons:
    acc, ex = test(model, device, test_loader, eps)
    accuracies.append(acc)
    examples.append(ex)
312/10:
plt.figure(figsize = (5,5))
plt.plot(epsilons, accuracies, '*-')
plt.yticks(np.arange(0, 1.1, step = 0.1))
plt.xticks(np.arange(0, 0.35, step = 0.05))
plt.title("Accuracy vs Epsilon")
plt.xlabel("Epsilon")
plt.ylabel("Accuracy")
plt.show()
313/1:
from __future__ import print_function, division
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

import warnings
warnings.filterwarnings("Ignore")

plt.ion()
314/1:
from __future__ import print_function, division
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

import warnings
warnings.filterwarnings("Ignore")

plt.ion()
314/2:
from __future__ import print_function, division
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

import warnings
warnings.filterwarnings("Ignore")

plt.ion()
315/1:
from __future__ import print_function, division
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

import warnings
warnings.filterwarnings("Ignore")

plt.ion()
315/2:
from __future__ import print_function, division
import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

import warnings
warnings.filterwarnings("ignore")

plt.ion()
315/3:
landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv')

n = 65
img_name = landmarks_frame.iloc[n, 0]
landmarks = landmarks_frame.iloc[n, 1:].as_matrix()
landmarks = landmarks.as_type('float').reshape(-1, 2)

print('Image Name: {}'.format(img_name))
print('Landmarks Shape: {}'.format(landmarks.shape))
print('First 4 landmarks: {}'.format(landmarks[:4]))
315/4:
landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv')

n = 65
img_name = landmarks_frame.iloc[n, 0]
landmarks = landmarks_frame.iloc[n, 1:].as_matrix()
landmarks = landmarks.astype('float').reshape(-1, 2)

print('Image Name: {}'.format(img_name))
print('Landmarks Shape: {}'.format(landmarks.shape))
print('First 4 landmarks: {}'.format(landmarks[:4]))
315/5:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[;, 1], s = 10, marker = '.', c = 'r')
    plt.pause(0.001)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/6:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 10, marker = '.', c = 'r')
    plt.pause(0.001)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/7:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 10, marker = '.', c = 'r')
    plt.pause(0.01)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/8:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 10, marker = '.', c = 'r')
    plt.pause(0.1)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/9:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 10, marker = '.', c = 'r')
    plt.pause(1)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/10:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 10, marker = '.', c = 'r')
    plt.pause(0.001)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/11:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 20, marker = '.', c = 'r')
    plt.pause(0.001)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/12:
def show_landmarks(image, landmarks):
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], s = 10, marker = '.', c = 'r')
    plt.pause(0.001)
    
plt.figure()
show_landmarks(io.imread(os.path.join('data/faces/', img_name)), landmarks)
plt.show()
315/13:
class FaceLandmarksDataset(Dataset):
    
    def __init__(self, csv_file, root_dir, transform = None):
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        
    def __len__(self):
        return len(self.landmarks_frame)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])
        image = io.imread(img_name)
        landmarks = self.landmarks_frame.iloc[idx, 1:]
        landmarks = np.array([landmarks])
        landmarks = landmarks.astype('float').reshape(-1, 2)
        sample = {'image': image, 'landmarks': landmarks}
        
        if self.transform:
            sample = self.transform(sample)
            
        return sample
315/14:
face_dataset = FaceLandmarksDataset(csv_file = 'data/faces/face_landmarks.csv',
                                    root_dir = 'data/faces/')

fig = plt.figure()

for i in range(len(face_dataset)):
    sample = face_dataset[i]
    
    print(i, sample['image'].shape, sample['landmarks'].shape)
    
    ax = plt.subplot(1, 4, i + 1)
    plt.tight_layout()
    ax.set_title('Sample #{}'.format(i))
    ax.axis('off')
    show_landmarks(**sample)
    
    if(i == 3):
        plt.show()
        break
315/15:
class Rescale(object):
    
    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        self.output_size = output_size
        
    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']
        h, w = image.shape[:2]
        if isinstance(self.output_size, int):
            if h > w:
                new_h, new_w = self.output_size * h / w, self.output_size
            else:
                new_h, new_w = self.output_size, self.output_size * w / h
        else:
            new_h, new_w = self.output_size
            
        new_h, new_w = int(new_h), int(new_w)
        
        img = transform.resize(image, (new_h, new_w))
        
        landmarks = landmarks * [new_w / w, new_h / h]
        
        return {'image': img, 'landmarks': landmarks}
315/16:
class RandomCrop(object):
    
    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        if isinstance(output_size, int):
            self.output_size = (output_size, output_size)
        else:
            assert len(output_size) == 2
            self.output_size = output_size
    
    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']
        h, w = image.shape[:2]
        new_h, new_w = self.output_size
        
        top = np.random.randint(0, h - new_h)
        left = np.random.randint(0, w - new_w)
        
        image = image[top: top + new_h, left: left + new_w]
        
        landmarks = landmarks - [left, top]
        
        return {'image': image, 'landmarks': landmarks}
315/17:
class ToTensor(object):
    
    def __call__(self, sample):
        image, landmarks = sample['image'], sample['landmarks']
        
        image = image.transpose((2, 0, 1))
        
        return {'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)}
315/18:
scale = Rescale(256)
crop = RandomCrop(128)
composed = transforms.Compose([Rescale(256), RandomCrop(224)])

fig = plt.figure()
sample = face_dataset[65]
for i, trfrm in enumerate([scale, crop, composed]):
    transformed_sample = trfrm(sample)
    
    ax.subplot(1, 3, i + 1)
    plt.tight_layout()
    ax.set_title(type(trfrm).__name__)
    show_landmarks(**transformed_sample)
    
plt.show()
315/19:
scale = Rescale(256)
crop = RandomCrop(128)
composed = transforms.Compose([Rescale(256), RandomCrop(224)])

fig = plt.figure()
sample = face_dataset[65]
for i, trfrm in enumerate([scale, crop, composed]):
    transformed_sample = trfrm(sample)
    
    ax = plt.subplot(1, 3, i + 1)
    plt.tight_layout()
    ax.set_title(type(trfrm).__name__)
    show_landmarks(**transformed_sample)
    
plt.show()
316/1:
from __future__ import print_function
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.optim.lr_scheduler import StepLR
316/2:
class Net(nn.Module):
    def__init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.50)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)
        
    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim= 1)
        return output
316/3:
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.50)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128, 10)
        
    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.dropout2(x)
        x = self.fc2(x)
        output = F.log_softmax(x, dim= 1)
        return output
316/4:
def train(args, model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % args.log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
316/5:
def test(args, model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in enumerate(test_loader):
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            
    test_loss /= len(test_loader.dataset)
    
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
316/6: #study argparser and then write main function
321/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
321/2: %matplotlib inline
321/3:
#Reading 2014 csv
df2014meter2 = pd.read_csv('HomeA-electrical/HomeA/2014/HomeA-meter2_2014.csv')
df2014meter3 = pd.read_csv('HomeA-electrical/HomeA/2014/HomeA-meter3_2014.csv')
df2014meter4 = pd.read_csv('HomeA-electrical/HomeA/2014/HomeA-meter4_2014.csv')

#Reading 2015 csv
df2015meter2 = pd.read_csv('HomeA-electrical/HomeA/2015/HomeA-meter2_2015.csv')
df2015meter3 = pd.read_csv('HomeA-electrical/HomeA/2015/HomeA-meter3_2015.csv')
df2015meter4 = pd.read_csv('HomeA-electrical/HomeA/2015/HomeA-meter4_2015.csv')

#Reading 2016 csv
df2016meter2 = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter2_2016.csv')
df2016meter3 = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter3_2016.csv')
df2016meter4 = pd.read_csv('HomeA-electrical/HomeA/2016/HomeA-meter4_2016.csv')
321/4:
#Drop 'use [kW]' and 'gen [kW]' for 2014 meters
df2014meter2 = df2014meter2.drop('use [kW]', axis = 1)
df2014meter3 = df2014meter3.drop('use [kW]', axis = 1)
df2014meter4 = df2014meter4.drop('use [kW]', axis = 1)

df2014meter2 = df2014meter2.drop('gen [kW]', axis = 1)
df2014meter3 = df2014meter3.drop('gen [kW]', axis = 1)
df2014meter4 = df2014meter4.drop('gen [kW]', axis = 1)

#Drop 'use [kW]' and 'gen [kW]' for 2015 meters
df2015meter2 = df2015meter2.drop('use [kW]', axis = 1)
df2015meter3 = df2015meter3.drop('use [kW]', axis = 1)
df2015meter4 = df2015meter4.drop('use [kW]', axis = 1)

df2015meter2 = df2015meter2.drop('gen [kW]', axis = 1)
df2015meter3 = df2015meter3.drop('gen [kW]', axis = 1)
df2015meter4 = df2015meter4.drop('gen [kW]', axis = 1)

#Drop 'use [kW]' and 'gen [kW]' for 2016 meters
df2016meter2 = df2016meter2.drop('use [kW]', axis = 1)
df2016meter3 = df2016meter3.drop('use [kW]', axis = 1)
df2016meter4 = df2016meter4.drop('use [kW]', axis = 1)

df2016meter2 = df2016meter2.drop('gen [kW]', axis = 1)
df2016meter3 = df2016meter3.drop('gen [kW]', axis = 1)
df2016meter4 = df2016meter4.drop('gen [kW]', axis = 1)
321/5:
#Convert object type to datetime for 2014 meters
df2014meter2['Date & Time'] = pd.to_datetime(df2014meter2['Date & Time'])
df2014meter3['Date & Time'] = pd.to_datetime(df2014meter3['Date & Time'])
df2014meter4['Date & Time'] = pd.to_datetime(df2014meter4['Date & Time'])

#Convert object type to datetime for 2015 meters
df2015meter2['Date & Time'] = pd.to_datetime(df2015meter2['Date & Time'])
df2015meter3['Date & Time'] = pd.to_datetime(df2015meter3['Date & Time'])
df2015meter4['Date & Time'] = pd.to_datetime(df2015meter4['Date & Time'])

#Convert object type to datetime for 2016 meters
df2016meter2['Date & Time'] = pd.to_datetime(df2016meter2['Date & Time'])
df2016meter3['Date & Time'] = pd.to_datetime(df2016meter3['Date & Time'])
df2016meter4['Date & Time'] = pd.to_datetime(df2016meter4['Date & Time'])
321/6:
#Split DateTime columns into Month, Day, Hour and Minute columns for 2014 meters
df2014meter2['Month'] = df2014meter2['Date & Time'].dt.month
df2014meter2['Day'] = df2014meter2['Date & Time'].dt.day
df2014meter2['Hour'] = df2014meter2['Date & Time'].dt.hour
df2014meter2['Minute'] = df2014meter2['Date & Time'].dt.minute

df2014meter3['Month'] = df2014meter3['Date & Time'].dt.month
df2014meter3['Day'] = df2014meter3['Date & Time'].dt.day
df2014meter3['Hour'] = df2014meter3['Date & Time'].dt.hour
df2014meter3['Minute'] = df2014meter3['Date & Time'].dt.minute

df2014meter4['Month'] = df2014meter4['Date & Time'].dt.month
df2014meter4['Day'] = df2014meter4['Date & Time'].dt.day
df2014meter4['Hour'] = df2014meter4['Date & Time'].dt.hour
df2014meter4['Minute'] = df2014meter4['Date & Time'].dt.minute

#Split DateTime columns into Month, Day, Hour and Minute columns for 2015 meters
df2015meter2['Month'] = df2015meter2['Date & Time'].dt.month
df2015meter2['Day'] = df2015meter2['Date & Time'].dt.day
df2015meter2['Hour'] = df2015meter2['Date & Time'].dt.hour
df2015meter2['Minute'] = df2015meter2['Date & Time'].dt.minute

df2015meter3['Month'] = df2015meter3['Date & Time'].dt.month
df2015meter3['Day'] = df2015meter3['Date & Time'].dt.day
df2015meter3['Hour'] = df2015meter3['Date & Time'].dt.hour
df2015meter3['Minute'] = df2015meter3['Date & Time'].dt.minute

df2015meter4['Month'] = df2015meter4['Date & Time'].dt.month
df2015meter4['Day'] = df2015meter4['Date & Time'].dt.day
df2015meter4['Hour'] = df2015meter4['Date & Time'].dt.hour
df2015meter4['Minute'] = df2015meter4['Date & Time'].dt.minute

#Split DateTime columns into Month, Day, Hour and Minute columns for 2016 meters
df2016meter2['Month'] = df2016meter2['Date & Time'].dt.month
df2016meter2['Day'] = df2016meter2['Date & Time'].dt.day
df2016meter2['Hour'] = df2016meter2['Date & Time'].dt.hour
df2016meter2['Minute'] = df2016meter2['Date & Time'].dt.minute

df2016meter3['Month'] = df2016meter3['Date & Time'].dt.month
df2016meter3['Day'] = df2016meter3['Date & Time'].dt.day
df2016meter3['Hour'] = df2016meter3['Date & Time'].dt.hour
df2016meter3['Minute'] = df2016meter3['Date & Time'].dt.minute

df2016meter4['Month'] = df2016meter4['Date & Time'].dt.month
df2016meter4['Day'] = df2016meter4['Date & Time'].dt.day
df2016meter4['Hour'] = df2016meter4['Date & Time'].dt.hour
df2016meter4['Minute'] = df2016meter4['Date & Time'].dt.minute
321/7:
#Drop 'Date & Time' column from 2014 meters
df2014meter2 = df2014meter2.drop('Date & Time', axis=1)
df2014meter3 = df2014meter3.drop('Date & Time', axis=1)
df2014meter4 = df2014meter4.drop('Date & Time', axis=1)

#Drop 'Date & Time' column from 2015 meters
df2015meter2 = df2015meter2.drop('Date & Time', axis=1)
df2015meter3 = df2015meter3.drop('Date & Time', axis=1)
df2015meter4 = df2015meter4.drop('Date & Time', axis=1)

#Drop 'Date & Time' column from 2016 meters
df2016meter2 = df2016meter2.drop('Date & Time', axis=1)
df2016meter3 = df2016meter3.drop('Date & Time', axis=1)
df2016meter4 = df2016meter4.drop('Date & Time', axis=1)
321/8:
#Columns' renaming for meter 2
df2014meter2.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
df2015meter2.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']
df2016meter2.columns = ['Furnace', 'Cellar Outlets', 'Washing Machine', 'Refrigerator', 'Dishwasher', 'Kitchen Lights', 'Bedroom 1 Outlets', 'Bedroom 1 Lights', 'Master Bedroom Outlets', 'Master Bedroom Lights', 'Heating Duct', 'Month', 'Day', 'Hour', 'Minute']

#Columns' renaming for meter 3
df2014meter3.columns = ['Electric Range', 'Dryer', 'Garage Mudroom Lights', 'Dining Room Outlets', 'Mudroom Outlets', 'Master Bath Outlets', 'Garage Outlets', 'Basement Outdoor Outlets', 'Month', 'Day', 'Hour', 'Minute']
df2015meter3.columns = ['Electric Range', 'Dryer', 'Garage Mudroom Lights', 'Dining Room Outlets', 'Mudroom Outlets', 'Master Bath Outlets', 'Garage Outlets', 'Basement Outdoor Outlets', 'Month', 'Day', 'Hour', 'Minute']
df2016meter3.columns = ['Electric Range', 'Dryer', 'Garage Mudroom Lights', 'Dining Room Outlets', 'Mudroom Outlets', 'Master Bath Outlets', 'Garage Outlets', 'Basement Outdoor Outlets', 'Month', 'Day', 'Hour', 'Minute']

#Columns' renaming for meter 4
df2014meter4.columns = ['Kitchen Den Lights', 'Master Bedroom Bath Lights', 'Master Outlets', 'Den Outdoor Lights', 'Den Outlets', 'Rear Basement Lights', 'Kitchen Outlets East', 'Kitchen Outlets South', 'Dishwasher Disposal Sink Light', 'Refrigerator', 'Microwave', 'Office Lights', 'Month', 'Day', 'Hour', 'Minute']
df2015meter4.columns = ['Kitchen Den Lights', 'Master Bedroom Bath Lights', 'Master Outlets', 'Den Outdoor Lights', 'Den Outlets', 'Rear Basement Lights', 'Kitchen Outlets East', 'Kitchen Outlets South', 'Dishwasher Disposal Sink Light', 'Refrigerator', 'Microwave', 'Office Lights', 'Month', 'Day', 'Hour', 'Minute']
df2016meter4.columns = ['Kitchen Den Lights', 'Master Bedroom Bath Lights', 'Master Outlets', 'Den Outdoor Lights', 'Den Outlets', 'Rear Basement Lights', 'Kitchen Outlets East', 'Kitchen Outlets South', 'Dishwasher Disposal Sink Light', 'Refrigerator', 'Microwave', 'Office Lights', 'Month', 'Day', 'Hour', 'Minute']
321/9:
# Convert kW to W for 2014 meter 2
df2014meter2['Furnace'] = df2014meter2['Furnace'].multiply(1000)
df2014meter2['Cellar Outlets'] = df2014meter2['Cellar Outlets'].multiply(1000)
df2014meter2['Washing Machine'] = df2014meter2['Washing Machine'].multiply(1000)
df2014meter2['Refrigerator'] = df2014meter2['Refrigerator'].multiply(1000)
df2014meter2['Dishwasher'] = df2014meter2['Dishwasher'].multiply(1000)
df2014meter2['Kitchen Lights'] = df2014meter2['Kitchen Lights'].multiply(1000)
df2014meter2['Bedroom 1 Outlets'] = df2014meter2['Bedroom 1 Outlets'].multiply(1000)
df2014meter2['Bedroom 1 Lights'] = df2014meter2['Bedroom 1 Lights'].multiply(1000)
df2014meter2['Master Bedroom Outlets'] = df2014meter2['Master Bedroom Outlets'].multiply(1000)
df2014meter2['Master Bedroom Lights'] = df2014meter2['Master Bedroom Lights'].multiply(1000)
df2014meter2['Heating Duct'] = df2014meter2['Heating Duct'].multiply(1000)

# Convert kW to W for 2015 meter 2
df2015meter2['Furnace'] = df2015meter2['Furnace'].multiply(1000)
df2015meter2['Cellar Outlets'] = df2015meter2['Cellar Outlets'].multiply(1000)
df2015meter2['Washing Machine'] = df2015meter2['Washing Machine'].multiply(1000)
df2015meter2['Refrigerator'] = df2015meter2['Refrigerator'].multiply(1000)
df2015meter2['Dishwasher'] = df2015meter2['Dishwasher'].multiply(1000)
df2015meter2['Kitchen Lights'] = df2015meter2['Kitchen Lights'].multiply(1000)
df2015meter2['Bedroom 1 Outlets'] = df2015meter2['Bedroom 1 Outlets'].multiply(1000)
df2015meter2['Bedroom 1 Lights'] = df2015meter2['Bedroom 1 Lights'].multiply(1000)
df2015meter2['Master Bedroom Outlets'] = df2015meter2['Master Bedroom Outlets'].multiply(1000)
df2015meter2['Master Bedroom Lights'] = df2015meter2['Master Bedroom Lights'].multiply(1000)
df2015meter2['Heating Duct'] = df2015meter2['Heating Duct'].multiply(1000)

# Convert kW to W for 2016 meter 2
df2016meter2['Furnace'] = df2016meter2['Furnace'].multiply(1000)
df2016meter2['Cellar Outlets'] = df2016meter2['Cellar Outlets'].multiply(1000)
df2016meter2['Washing Machine'] = df2016meter2['Washing Machine'].multiply(1000)
df2016meter2['Refrigerator'] = df2016meter2['Refrigerator'].multiply(1000)
df2016meter2['Dishwasher'] = df2016meter2['Dishwasher'].multiply(1000)
df2016meter2['Kitchen Lights'] = df2016meter2['Kitchen Lights'].multiply(1000)
df2016meter2['Bedroom 1 Outlets'] = df2016meter2['Bedroom 1 Outlets'].multiply(1000)
df2016meter2['Bedroom 1 Lights'] = df2016meter2['Bedroom 1 Lights'].multiply(1000)
df2016meter2['Master Bedroom Outlets'] = df2016meter2['Master Bedroom Outlets'].multiply(1000)
df2016meter2['Master Bedroom Lights'] = df2016meter2['Master Bedroom Lights'].multiply(1000)
df2016meter2['Heating Duct'] = df2016meter2['Heating Duct'].multiply(1000)
321/10:
# Convert kW to W for 2014 meter 3
df2014meter3['Electric Range'] = df2014meter3['Electric Range'].multiply(1000)
df2014meter3['Dryer'] = df2014meter3['Dryer'].multiply(1000)
df2014meter3['Garage Mudroom Lights'] = df2014meter3['Garage Mudroom Lights'].multiply(1000)
df2014meter3['Dining Room Outlets'] = df2014meter3['Dining Room Outlets'].multiply(1000)
df2014meter3['Mudroom Outlets'] = df2014meter3['Mudroom Outlets'].multiply(1000)
df2014meter3['Garage Outlets'] = df2014meter3['Garage Outlets'].multiply(1000)
df2014meter3['Basement Outdoor Outlets'] = df2014meter3['Basement Outdoor Outlets'].multiply(1000)

# Convert kW to W for 2015 meter 3
df2015meter3['Electric Range'] = df2015meter3['Electric Range'].multiply(1000)
df2015meter3['Dryer'] = df2015meter3['Dryer'].multiply(1000)
df2015meter3['Garage Mudroom Lights'] = df2015meter3['Garage Mudroom Lights'].multiply(1000)
df2015meter3['Dining Room Outlets'] = df2015meter3['Dining Room Outlets'].multiply(1000)
df2015meter3['Mudroom Outlets'] = df2015meter3['Mudroom Outlets'].multiply(1000)
df2015meter3['Garage Outlets'] = df2015meter3['Garage Outlets'].multiply(1000)
df2015meter3['Basement Outdoor Outlets'] = df2015meter3['Basement Outdoor Outlets'].multiply(1000)

# Convert kW to W for 2016 meter 3
df2016meter3['Electric Range'] = df2016meter3['Electric Range'].multiply(1000)
df2016meter3['Dryer'] = df2016meter3['Dryer'].multiply(1000)
df2016meter3['Garage Mudroom Lights'] = df2016meter3['Garage Mudroom Lights'].multiply(1000)
df2016meter3['Dining Room Outlets'] = df2016meter3['Dining Room Outlets'].multiply(1000)
df2016meter3['Mudroom Outlets'] = df2016meter3['Mudroom Outlets'].multiply(1000)
df2016meter3['Garage Outlets'] = df2016meter3['Garage Outlets'].multiply(1000)
df2016meter3['Basement Outdoor Outlets'] = df2016meter3['Basement Outdoor Outlets'].multiply(1000)
321/11:
# Convert kW to W for 2014 meter 4
df2014meter4['Kitchen Den Lights'] = df2014meter4['Kitchen Den Lights'].multiply(1000)
df2014meter4['Master Bedroom Bath Lights'] = df2014meter4['Master Bedroom Bath Lights'].multiply(1000)
df2014meter4['Master Outlets'] = df2014meter4['Master Outlets'].multiply(1000)
df2014meter4['Den Outdoor Lights'] = df2014meter4['Den Outdoor Lights'].multiply(1000)
df2014meter4['Den Outlets'] = df2014meter4['Den Outlets'].multiply(1000)
df2014meter4['Rear Basement Lights'] = df2014meter4['Rear Basement Lights'].multiply(1000)
df2014meter4['Kitchen Outlets East'] = df2014meter4['Kitchen Outlets East'].multiply(1000)
df2014meter4['Kitchen Outlets South'] = df2014meter4['Kitchen Outlets South'].multiply(1000)
df2014meter4['Dishwasher Disposal Sink Light'] = df2014meter4['Dishwasher Disposal Sink Light'].multiply(1000)
df2014meter4['Refrigerator'] = df2014meter4['Refrigerator'].multiply(1000)
df2014meter4['Microwave'] = df2014meter4['Microwave'].multiply(1000)
df2014meter4['Office Lights'] = df2014meter4['Office Lights'].multiply(1000)

# Convert kW to W for 2015 meter 4
df2015meter4['Kitchen Den Lights'] = df2015meter4['Kitchen Den Lights'].multiply(1000)
df2015meter4['Master Bedroom Bath Lights'] = df2015meter4['Master Bedroom Bath Lights'].multiply(1000)
df2015meter4['Master Outlets'] = df2015meter4['Master Outlets'].multiply(1000)
df2015meter4['Den Outdoor Lights'] = df2015meter4['Den Outdoor Lights'].multiply(1000)
df2015meter4['Den Outlets'] = df2015meter4['Den Outlets'].multiply(1000)
df2015meter4['Rear Basement Lights'] = df2015meter4['Rear Basement Lights'].multiply(1000)
df2015meter4['Kitchen Outlets East'] = df2015meter4['Kitchen Outlets East'].multiply(1000)
df2015meter4['Kitchen Outlets South'] = df2015meter4['Kitchen Outlets South'].multiply(1000)
df2015meter4['Dishwasher Disposal Sink Light'] = df2015meter4['Dishwasher Disposal Sink Light'].multiply(1000)
df2015meter4['Refrigerator'] = df2015meter4['Refrigerator'].multiply(1000)
df2015meter4['Microwave'] = df2015meter4['Microwave'].multiply(1000)
df2015meter4['Office Lights'] = df2015meter4['Office Lights'].multiply(1000)

# Convert kW to W for 2016 meter 4
df2016meter4['Kitchen Den Lights'] = df2016meter4['Kitchen Den Lights'].multiply(1000)
df2016meter4['Master Bedroom Bath Lights'] = df2016meter4['Master Bedroom Bath Lights'].multiply(1000)
df2016meter4['Master Outlets'] = df2016meter4['Master Outlets'].multiply(1000)
df2016meter4['Den Outdoor Lights'] = df2016meter4['Den Outdoor Lights'].multiply(1000)
df2016meter4['Den Outlets'] = df2016meter4['Den Outlets'].multiply(1000)
df2016meter4['Rear Basement Lights'] = df2016meter4['Rear Basement Lights'].multiply(1000)
df2016meter4['Kitchen Outlets East'] = df2016meter4['Kitchen Outlets East'].multiply(1000)
df2016meter4['Kitchen Outlets South'] = df2016meter4['Kitchen Outlets South'].multiply(1000)
df2016meter4['Dishwasher Disposal Sink Light'] = df2016meter4['Dishwasher Disposal Sink Light'].multiply(1000)
df2016meter4['Refrigerator'] = df2016meter4['Refrigerator'].multiply(1000)
df2016meter4['Microwave'] = df2016meter4['Microwave'].multiply(1000)
df2016meter4['Office Lights'] = df2016meter4['Office Lights'].multiply(1000)
321/12:
#Meter 2 boxplots for 'Furnace'
df2014meter2.boxplot(column='Furnace', by='Month')
df2015meter2.boxplot(column='Furnace', by='Month')
df2016meter2.boxplot(column='Furnace', by='Month')
321/13:
#Meter 2 boxplots for 'Cellar Outlets'
df2014meter2.boxplot(column='Cellar Outlets', by='Month')
df2015meter2.boxplot(column='Cellar Outlets', by='Month')
df2016meter2.boxplot(column='Cellar Outlets', by='Month')
321/14:
#Meter 2 boxplots for 'Washing Machine'
df2014meter2.boxplot(column='Washing Machine', by='Month')
df2015meter2.boxplot(column='Washing Machine', by='Month')
df2016meter2.boxplot(column='Washing Machine', by='Month')
321/15:
#Meter 2 boxplots for 'Refrigerator'
df2014meter2.boxplot(column='Refrigerator', by='Month')
df2015meter2.boxplot(column='Refrigerator', by='Month')
df2016meter2.boxplot(column='Refrigerator', by='Month')
321/16:
#Meter 2 boxplots for 'Dishwasher'
df2014meter2.boxplot(column='Dishwasher', by='Month')
df2015meter2.boxplot(column='Dishwasher', by='Month')
df2016meter2.boxplot(column='Dishwasher', by='Month')
321/17:
#Meter 2 boxplots for 'Kitchen Lights'
df2014meter2.boxplot(column='Kitchen Lights', by='Month')
df2015meter2.boxplot(column='Kitchen Lights', by='Month')
df2016meter2.boxplot(column='Kitchen Lights', by='Month')
321/18:
#Meter 2 boxplots for 'Bedroom 1 Outlets'
df2014meter2.boxplot(column='Bedroom 1 Outlets', by='Month')
df2015meter2.boxplot(column='Bedroom 1 Outlets', by='Month')
df2016meter2.boxplot(column='Bedroom 1 Outlets', by='Month')
321/19:
#Meter 2 boxplots for 'Bedroom 1 Lights'
df2014meter2.boxplot(column='Bedroom 1 Lights', by='Month')
df2015meter2.boxplot(column='Bedroom 1 Lights', by='Month')
df2016meter2.boxplot(column='Bedroom 1 Lights', by='Month')
321/20:
#Meter 2 boxplots for 'Master Bedroom Outlets'
df2014meter2.boxplot(column='Master Bedroom Outlets', by='Month')
df2015meter2.boxplot(column='Master Bedroom Outlets', by='Month')
df2016meter2.boxplot(column='Master Bedroom Outlets', by='Month')
321/21:
#Meter 2 boxplots for 'Master Bedroom Lights'
df2014meter2.boxplot(column='Master Bedroom Lights', by='Month')
df2015meter2.boxplot(column='Master Bedroom Lights', by='Month')
df2016meter2.boxplot(column='Master Bedroom Lights', by='Month')
321/22:
#Meter 2 boxplots for 'Heating Duct'
df2014meter2.boxplot(column='Heating Duct', by='Month')
df2015meter2.boxplot(column='Heating Duct', by='Month')
df2016meter2.boxplot(column='Heating Duct', by='Month')
321/23:
#Meter 3 boxplots for 'Electric Range'
df2014meter3.boxplot(column='Electric Range', by='Month')
df2015meter3.boxplot(column='Electric Range', by='Month')
df2016meter3.boxplot(column='Electric Range', by='Month')
321/24:
#Meter 3 boxplots for 'Dryer'
df2014meter3.boxplot(column='Dryer', by='Month')
df2015meter3.boxplot(column='Dryer', by='Month')
df2016meter3.boxplot(column='Dryer', by='Month')
321/25:
#Meter 3 boxplots for 'Garage Mudroom Lights'
df2014meter3.boxplot(column='Garage Mudroom Lights', by='Month')
df2015meter3.boxplot(column='Garage Mudroom Lights', by='Month')
df2016meter3.boxplot(column='Garage Mudroom Lights', by='Month')
321/26:
#Meter 3 boxplots for 'Dining Room Outlets'
df2014meter3.boxplot(column='Dining Room Outlets', by='Month')
df2015meter3.boxplot(column='Dining Room Outlets', by='Month')
df2016meter3.boxplot(column='Dining Room Outlets', by='Month')
321/27:
#Meter 3 boxplots for 'Mudroom Outlets'
df2014meter3.boxplot(column='Mudroom Outlets', by='Month')
df2015meter3.boxplot(column='Mudroom Outlets', by='Month')
df2016meter3.boxplot(column='Mudroom Outlets', by='Month')
321/28:
#Meter 3 boxplots for 'Garage Outlets'
df2014meter3.boxplot(column='Garage Outlets', by='Month')
df2015meter3.boxplot(column='Garage Outlets', by='Month')
df2016meter3.boxplot(column='Garage Outlets', by='Month')
321/29:
#Meter 3 boxplots for 'Basement Outdoor Outlets'
df2014meter3.boxplot(column='Basement Outdoor Outlets', by='Month')
df2015meter3.boxplot(column='Basement Outdoor Outlets', by='Month')
df2016meter3.boxplot(column='Basement Outdoor Outlets', by='Month')
321/30:
#Meter 4 boxplots for 'Kitchen Den Lights'
df2014meter4.boxplot(column='Kitchen Den Lights', by='Month')
df2015meter4.boxplot(column='Kitchen Den Lights', by='Month')
df2016meter4.boxplot(column='Kitchen Den Lights', by='Month')
321/31:
#Meter 4 boxplots for 'Master Bedroom Bath Lights'
df2014meter4.boxplot(column='Master Bedroom Bath Lights', by='Month')
df2015meter4.boxplot(column='Master Bedroom Bath Lights', by='Month')
df2016meter4.boxplot(column='Master Bedroom Bath Lights', by='Month')
321/32:
#Meter 4 boxplots for 'Master Outlets'
df2014meter4.boxplot(column='Master Outlets', by='Month')
df2015meter4.boxplot(column='Master Outlets', by='Month')
df2016meter4.boxplot(column='Master Outlets', by='Month')
321/33:
#Meter 4 boxplots for 'Den Outdoor Lights'
df2014meter4.boxplot(column='Den Outdoor Lights', by='Month')
df2015meter4.boxplot(column='Den Outdoor Lights', by='Month')
df2016meter4.boxplot(column='Den Outdoor Lights', by='Month')
321/34:
#Meter 4 boxplots for 'Den Outlets'
df2014meter4.boxplot(column='Den Outlets', by='Month')
df2015meter4.boxplot(column='Den Outlets', by='Month')
df2016meter4.boxplot(column='Den Outlets', by='Month')
321/35:
#Meter 4 boxplots for 'Rear Basement Lights'
df2014meter4.boxplot(column='Rear Basement Lights', by='Month')
df2015meter4.boxplot(column='Rear Basement Lights', by='Month')
df2016meter4.boxplot(column='Rear Basement Lights', by='Month')
321/36:
#Meter 4 boxplots for 'Kitchen Outlets East'
df2014meter4.boxplot(column='Kitchen Outlets East', by='Month')
df2015meter4.boxplot(column='Kitchen Outlets East', by='Month')
df2016meter4.boxplot(column='Kitchen Outlets East', by='Month')
321/37:
#Meter 4 boxplots for 'Kitchen Outlets South'
df2014meter4.boxplot(column='Kitchen Outlets South', by='Month')
df2015meter4.boxplot(column='Kitchen Outlets South', by='Month')
df2016meter4.boxplot(column='Kitchen Outlets South', by='Month')
321/38:
#Meter 4 boxplots for 'Dishwasher Disposal Sink Light'
df2014meter4.boxplot(column='Dishwasher Disposal Sink Light', by='Month')
df2015meter4.boxplot(column='Dishwasher Disposal Sink Light', by='Month')
df2016meter4.boxplot(column='Dishwasher Disposal Sink Light', by='Month')
321/39:
#Meter 4 boxplots for 'Refrigerator'
df2014meter4.boxplot(column='Refrigerator', by='Month')
df2015meter4.boxplot(column='Refrigerator', by='Month')
df2016meter4.boxplot(column='Refrigerator', by='Month')
321/40:
#Meter 4 boxplots for 'Microwave'
df2014meter4.boxplot(column='Microwave', by='Month')
df2015meter4.boxplot(column='Microwave', by='Month')
df2016meter4.boxplot(column='Microwave', by='Month')
321/41:
#Meter 4 boxplots for 'Office Lights'
df2014meter4.boxplot(column='Office Lights', by='Month')
df2015meter4.boxplot(column='Office Lights', by='Month')
df2016meter4.boxplot(column='Office Lights', by='Month')
321/42: plt.scatter(df2016meter4['Month'], df2016meter4['Office Lights'], label = "stars", color = 'm', marker = '*', s = 30)
322/1:
import numpy as np
from tqdm import tqdm_notebook as tqdm
from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
322/2: data = np.load("processed_data.npz")['data']
322/3: unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]
322/4: data
322/5: data.shape
322/6: data[1]
322/7: data[0]
322/8: data[1][0]
322/9: data[:5]
322/10: data[1][:3]
322/11: data.dtype
322/12: unique_states
322/13: len(unique_states)
322/14: data.shape[1]
322/15: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
322/16: states_map
322/17: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
322/18: episodes
322/19: episodes.shape
322/20: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
322/21: episodic_states
322/22: episodic_states[:5]
322/23: episodic_states[-1:]
322/24: episodic_states[-1:5]
322/25: episodic_states[-3:]
322/26: episodic_states[-2:]
322/27: print(episodic_states)
322/28: episodic_states = episodic_states.reshape([-1, 2])
322/29: episodic_states
322/30: np.random.seed(43)
322/31: np.random.shuffle(episodic_states)
322/32:
train_episodes = episodic_states[:int(0.7*len(episodic_states))]
val_episodes = episodic_states[int(0.7*len(episodic_states)):]
322/33: len(train_episodes)
322/34: len(val_episodes)
322/35: len(episodic_states)
322/36: train_episodes
322/37: episodes
322/38: train_episodes.unique
322/39: train_episodes.unique()
322/40: np.unique(train_episodes)
322/41: len(np.unique(train_episodes))
322/42: train_episodes[0]
322/43: train_episodes[1]
322/44: np.unique(train_episodes)
322/45: np.unique(train_episodes[0])
322/46: np.unique(train_episodes[:])
322/47: episodic_states
322/48: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
322/49: episodes
322/50: episodes.shape
322/51: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
322/52: episodic_states
322/53: episodic_states_reshaped = episodic_states.reshape([-1, 2])
322/54: episodic_states_reshaped
322/55: np.random.shuffle(episodic_states_reshaped)
322/56:
train_episodes = episodic_states_reshaped[:int(0.7*len(episodic_states))]
val_episodes = episodic_states_reshaped[int(0.7*len(episodic_states)):]
322/57: len(train_episodes)
322/58: len(val_episodes)
322/59:
train_episodes = episodic_states_reshaped[:int(0.7*len(episodic_states_reshaped))]
val_episodes = episodic_states_reshaped[int(0.7*len(episodic_states_reshaped)):]
322/60: len(train_episodes)
322/61: len(val_episodes)
322/62: train_episodes
322/63: episodes
322/64: np.unique(train_episodes[:])
322/65: train_episodes[0]
322/66: train_episodes[1]
322/67: episodic_states
322/68: episodic_states_reshaped
322/69: episodic_states_reshaped[0][0]
322/70: episodic_states_reshaped[0][1]
322/71: episodic_states_reshaped[0][0] == episodic_states_reshaped[0][1]
322/72: np.unique(episodic_states_reshaped)
322/73: len(np.unique(episodic_states_reshaped))
322/74: np.zeros[225][225][2]
322/75: transitions = np.zeros[225][225][2]
322/76: transitions = np.zeros(225,225,2)
322/77: transitions = np.zeros((225,225,2))
322/78: transitions
322/79: transitions[1]
322/80: transitions[1][1]
322/81: transitions[1][1][1]
322/82: transitions[1][1][0]
322/83: transitions[1][1][2]
322/84: transitions[1][1][1]
322/85: np.unique(episodic_states_reshaped)
322/86: for i,j in train_episodes[][0], train_episodes[][1]:
322/87: for i,j in train_episodes[:][0], train_episodes[:][1]:
322/88:     T = np.load("T.npy")
322/89: T
322/90: T.shape
322/91: T
322/92: T[1]
322/93: T
322/94: T[1]
322/95: T[1][1]
322/96: top5 = episodic_states_reshaped[:5]
322/97: top5
322/98: top5.sort(key = int)
322/99: list(top5)
322/100: top5.sort()
322/101: top5
322/102: top5s = list(top5)
322/103: top5s.sort()
322/104: np.all(top5)
322/105: top5s.sort()
322/106: top5s
322/107: unique_top5 = [np.unique(top5[:, e]) for e in range(top5.shape[1])]
322/108: unique_top5
322/109: unique_top5 = [np.unique(top5[:, e]) for e in range(top5.shape[0])]
322/110: unique_top5 = [np.unique(top5[:, e]) for e in range(top5.shape[1])]
322/111: unique_top5
322/112: unique_top5 = np.unique(top5)
322/113: unique_top5
322/114: top5[1][1]
322/115: top5
322/116: print(np.where(unique_top5 == top5[1][1]))
322/117: top5.shape
322/118: tran = np.zeros(9,9,2)
322/119: tran = np.zeros((9,9,2))
322/120: tran
322/121: T
322/122: top5
322/123:
for i,j in top5[:][0], top5[:][1]:
    if(i == j):
        tran[np.where(unique_top5 == i)][np.where(unique_top5 == j)][0] += 1
    else:
        tran[np.where(unique_top5 == i)][np.where(unique_top5 == j)][1] += 1
322/124: top[:][0]
322/125: top5[:][0]
322/126: top5[:][1]
322/127: top5[0][:]
322/128: top5[0]
322/129: top5[0][:-1]
322/130: top5.reshape(-1,1)
322/131: top5.reshape(-1,2)
322/132: top5.shape
322/133: top5[:,0]
322/134:
for i,j in top5[:,0], top5[:,1]:
    if(i == j):
        tran[np.where(unique_top5 == i)][np.where(unique_top5 == j)][0] += 1
    else:
        tran[np.where(unique_top5 == i)][np.where(unique_top5 == j)][1] += 1
322/135: top5[:,1]
323/1: import numpy as np
322/136: episodic_states
322/137: np.unique(episodic_states)
322/138: unique_states = np.unique(episodic_states)
322/139: unique_states
322/140: unique_states.shape
322/141: unique_states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
322/142: give_id = lambda t : n for n in range(225)
322/143:
for i in range(225):
    give_id = lambda t : i
    id_fun = np.vectorize(give_id)
    id_fun(unique_states)
322/144: id_fun
322/145: unique_states
322/146:
for i in range(225):
    give_id = lambda t : i
    id_fun = np.vectorize(give_id)
    result = id_fun(unique_states)
322/147: result
322/148:
for i in range(0,225):
    give_id = lambda t : i+1
    id_fun = np.vectorize(give_id)
    result = id_fun(unique_states)
322/149: result
322/150: unique_states = list(unique_states)
322/151: unique_states
322/152: {key: None for key in unique_states}
322/153: unique_states
322/154: key
322/155: states_dict = {key: None for key in unique_states}
322/156: states_dict
322/157: states_dict["1"]
322/158: states_dict.get["1"]
322/159: states_dict.get("1")
322/160: x = states_dict.get("1")
322/161: x
322/162: states_dict
322/163: print(x)
322/164: x = states_dict.get(y)
322/165: y = 21010
322/166: x = states_dict.get(y)
322/167: print(x)
322/168: states_dict = {key: 0 for key in unique_states}
322/169: states_dict
322/170: x = states_dict.get("0") + 1
322/171:
x = states_dict.get("0")
x = x += 1
322/172:
x = states_dict.get("0")
x = x +1
322/173: states_dict = {key: "0" for key in unique_states}
322/174:
x = states_dict.get("0")
x = x +1
322/175: states_dict
322/176: states_dict = {key: 0 for key in unique_states}
322/177: states_dict
322/178: states_dict = {key: (int)0 for key in unique_states}
322/179: x = states_dict.get("230")
322/180: print(x)
322/181: states_dict = {key: 0 for key in unique_states}
322/182: x = states_dict.get("230")
322/183: print(x)
322/184: x = states_dict.get("0")
322/185: print(x)
322/186: states_dict
322/187: states_dict = {key: int(None or 0) for key in unique_states}
322/188: x = states_dict.get("0")
322/189: print(x)
322/190: states_dict
322/191: states_dict = {key: int(0) for key in unique_states}
322/192: x = states_dict.get("0")
322/193: print(x)
322/194: states_dict
322/195: x = states_dict.get("1")
322/196: print(x)
322/197: states_dict = {key: int(1) for key in unique_states}
322/198: x = states_dict.get("1")
322/199: print(x)
322/200: states_dict
322/201: x = states_dict.get("1") + 1
322/202: x = int(states_dict.get("1")) + 1
323/2: import numpy as np
323/3: data = np.load("processed_data.npz")['data']
323/4: unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]
323/5: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
323/6: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
323/7: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
324/1: import numpy as np
324/2: data = np.load("processed_data.npz")['data']
324/3: unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]
324/4: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
324/5: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
324/6: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
325/1: import numpy as np
325/2: data = np.load("processed_data.npz")['data']
325/3: unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]
325/4: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
325/5: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
325/6: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
325/7: unique = np.unique(episodic_states)
325/8: unique
325/9: unique.shape
325/10: x = np.where(unique, 10)
325/11: print(np.where(unique == 10)
325/12: print(np.where(unique == 10))
325/13: unique
325/14: states_map
325/15: episodic_states
325/16: episodic_states[0]
325/17: episodic_states[0]==episodic_states[1]
325/18: episodic_states[1]
325/19: episodic_states
325/20: print(np.where(unique == episodic_states[0]))
325/21: transition_matrix = np.zeros((225,225,2))
325/22:
for i in range(len(episodic_states) + 1):
    if episodic_states[i] == episodic_states[i + 1]:
        transition_matrix[np.where(unique == episodic_states[i])][np.where(unique == episodic_states[i])][0] += 1
    else:
        transition_matrix[np.where(unique == episodic_states[i])][np.where(unique == episodic_stateso[i + 1])][1] += 1
325/23:
for i in range(len(episodic_states) + 1):
    if episodic_states[i] == episodic_states[i + 1]:
        transition_matrix[np.where(unique == episodic_states[i])][np.where(unique == episodic_states[i])][0] += 1
    else:
        transition_matrix[np.where(unique == episodic_states[i])][np.where(unique == episodic_states[i + 1])][1] += 1
325/24: len(episodic_states)
325/25: transition_matrix[126][126][0]
325/26: transition_matrix[126][126][1]
325/27: transition_matrix[225][225][1]
325/28: transition_matrix[224][224][1]
325/29: transition_matrix
325/30:
for i in range(len(episodic_states) + 1):
    if episodic_states[i] == episodic_states[i + 1]:
        transition_matrix[np.where(unique == episodic_states[i])][np.where(unique == episodic_states[i])][0] += 1
    else:
        transition_matrix[np.where(unique == episodic_states[i])][np.where(unique == episodic_states[i + 1])][0] += 1
325/31: len(episodic_states)+1
325/32:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i - 1])][0] += 1
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i])][1] += 1
325/33: len(transition_matrix[224][224][])
325/34: len(transition_matrix[224][224])
325/35:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i - 1])][0] += 1
        print(episodic_states[i-1])
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i])][1] += 1
        print(episodic_states[i-1])
325/36:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        print(episodic_states[i-1])
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i - 1])][0] += 1
        
    else:
        print(episodic_states[i-1])
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i])][1] += 1
325/37:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        print(episodic_states[i-1])
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i - 1])][0] += 1
        
    else:
        print(episodic_states[i-1])
        print(episodic_states[i])
        transition_matrix[np.where(unique == episodic_states[i - 1])][np.where(unique == episodic_states[i])][1] += 1
325/38: print(np.where(unique == 20020))
325/39: index = (np.where(unique == 20020))
325/40: transition_matrix[index][index][1]
325/41: index1 = (np.where(unique == 20000))
325/42: index2 = (np.where(unique == 20020))
325/43: transition_matrix[index1][index2][1]
325/44: len(transition_matrix)
325/45: len(transition_matrix[])
325/46: len(transition_matrix[224])
325/47: transition_matrix.shape
325/48: transition_matrix[index1].shape
325/49: transition_matrix[index1][index2].shape
325/50: index1
325/51: index2
325/52: gauss_indices = np.random.normal(size = 225)
325/53: gauss_indices
325/54: gauss_indices.shape
325/55: gauss_indices
325/56: gauss_indices = np.random.normal(scale = 1, size = 225)
325/57: gauss_indices
325/58:
mu, sigma = 0, 0.1
import matplotlib.pyplot as plt
count, bins, ignored = plt.hist(gauss_indices, 30, normed=True)
plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *
                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),
          linewidth=2, color='r')
plt.show()
325/59:
mu, sigma = 0, 0.1
import matplotlib.pyplot as plt
%matplotlib inline
count, bins, ignored = plt.hist(gauss_indices, 30, normed=True)
plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *
                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),
          linewidth=2, color='r')
plt.show()
325/60:
mu, sigma = 0, 0.1
s = np.random.normal(mu, sigma, 1000)
import matplotlib.pyplot as plt
%matplotlib inline
count, bins, ignored = plt.hist(s, 30, normed=True)
plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *
                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),
          linewidth=2, color='r')
plt.show()
325/61: s
325/62: gauss_indices = np.random.normal(scale = 0.5, size = 225)
325/63: gauss_indices
325/64:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
325/65:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=0.1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
325/66: gauss_indices = get_truncated_normal(0, 0.1, 0, 1)
325/67: gauss_indices
325/68: gauss_indices.rvs(225)
325/69: gauss = get_truncated_normal(0, 0.1, 0, 1)
325/70: gauss_indices = gauss.rvs(225)
325/71:
for i in range(225):
    for j in range(225):
        if transition_matrix[i][j][0] == 0:
            transition_matrix[i][j][1] = gauss_indices[i]*transition_matrix[i][j][0]
            transition_matrix[i][j][0] = 1 - transition_matrix[i][j][1]
        else:
            transition_matrix[i][j][0] = gauss_indices[i]*transition_matrix[i][j][1]
            transition_matrix[i][j][1] = 1 - transition_matrix[i][j][0]
325/72:
row_sum = np.zeros((225))
for i in range(225):    
    for j in range(225):
        row_sum[i] += transition_matrix[i][j][0] + transition_matrix[i][j][1]
325/73:
for i in range(225):
    for j in range(225):
        transition_matrix[i][j][0] /= row_sum[i]
        transition_matrix[i][j][1] /= row_sum[i]
325/74:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=0.1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
325/75: gauss = get_truncated_normal(0, 0.1, 0, 1)
325/76: gauss_indices = gauss.rvs(225)
325/77:
for i in range(225):
    for j in range(225):
        if transition_matrix[i][j][0] == 0:
            transition_matrix[i][j][1] = gauss_indices[i]*transition_matrix[i][j][0]
            transition_matrix[i][j][0] = 1 - transition_matrix[i][j][1]
        else:
            transition_matrix[i][j][0] = gauss_indices[i]*transition_matrix[i][j][1]
            transition_matrix[i][j][1] = 1 - transition_matrix[i][j][0]
325/78:
print("Saving Transitions Matrix in 'transitions.npy' ...")
np.save("transitions", transition_matrix)
print("Done!")
325/79: print(np.where(unique == episodic_states[0]), np.where(unique == episodic_states[1]))
325/80: print(np.where(unique == episodic_states[0])[0], np.where(unique == episodic_states[1])[0])
325/81: print(np.where(unique == episodic_states[0])[0][0], np.where(unique == episodic_states[1])[0])
325/82:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        print(episodic_states[i-1])
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i - 1])[0][0]][0] += 1
        
    else:
        print(episodic_states[i-1])
        print(episodic_states[i])
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i])[0][0]][1] += 1
325/83:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i - 1])[0][0]][0] += 1
        
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i])[0][0]][1] += 1
325/84: transition_matrix
325/85:
row_sum = np.zeros((225))
for i in range(225):    
    for j in range(225):
        row_sum[i] += transition_matrix[i][j][0] + transition_matrix[i][j][1]
325/86: row_sum
325/87:
add = 0
for i in range(len(row_sum)):
    add += row_sum[i]
325/88: add
325/89:
for i in range(225):
    for j in range(225):
        transition_matrix[i][j][0] /= row_sum[i]
        transition_matrix[i][j][1] /= row_sum[i]
325/90: transition_matrix
325/91: row
325/92: row_sum
325/93: row_sum[0]
325/94: transition_matrix[1]
325/95: transition_matrix[1][1]
325/96: print(np.where(unique == episodic_states[0])[0][0], np.where(unique == episodic_states[1])[0][0])
325/97: transition_matrix
325/98: transition_matrix[0][1][0]
325/99: transition_matrix[0][1][1]
325/100: transition_matrix = np.zeros((225,225,2))
325/101: transition_matrix
325/102: transition_matrix = np.zeros((225,225,2))
325/103:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i - 1])[0][0]][0] += int(1)
        
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i])[0][0]][1] += int(1)
325/104: transition_matrix[0][1][1]
325/105: transition_matrix
325/106: transition_matrix[0][0][0]
325/107: sum(transition_matrix)
325/108:
row_sum = np.zeros((225))
for i in range(225):    
    for j in range(225):
        row_sum[i] += transition_matrix[i][j][0] + transition_matrix[i][j][1]
325/109: transition_matrix[1][1]
325/110: row_sum
325/111:
add = 0
for i in range(len(row_sum)):
    add += row_sum[i]
325/112: add
325/113: len(episodic_states)
325/114:
for i in range(225):
    for j in range(225):
        transition_matrix[i][j][0] /= row_sum[i]
        transition_matrix[i][j][1] /= row_sum[i]
325/115: transition_matrix
325/116:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=0.1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
325/117: gauss = get_truncated_normal(0, 0.1, 0, 1)
325/118: gauss_indices = gauss.rvs(225)
325/119:
for i in range(225):
    for j in range(225):
        if transition_matrix[i][j][0] == 0:
            transition_matrix[i][j][1] = gauss_indices[i]*transition_matrix[i][j][0]
            transition_matrix[i][j][0] = 1 - transition_matrix[i][j][1]
        else:
            transition_matrix[i][j][0] = gauss_indices[i]*transition_matrix[i][j][1]
            transition_matrix[i][j][1] = 1 - transition_matrix[i][j][0]
325/120: transition_matrix
325/121: transition_matrix = np.zeros((225,225,2))
325/122:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i - 1])[0][0]][0] += int(1)
        
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i])[0][0]][1] += int(1)
325/123:
row_sum = np.zeros((225))
for i in range(225):    
    for j in range(225):
        row_sum[i] += transition_matrix[i][j][0] + transition_matrix[i][j][1]
325/124: len(episodic_states)
325/125:
add = 0
for i in range(len(row_sum)):
    add += row_sum[i]
325/126: add
325/127:
for i in range(225):
    for j in range(225):
        transition_matrix[i][j][0] /= row_sum[i]
        transition_matrix[i][j][1] /= row_sum[i]
325/128:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=0.1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
325/129: gauss = get_truncated_normal(0, 0.1, 0, 1)
325/130: gauss_indices = gauss.rvs(225)
325/131: gauss_indices
325/132: gauss_indices[0]
325/133:
for i in range(225):
    for j in range(225):
        if transition_matrix[i][j][0] == 0:
            transition_matrix[i][j][1] = float(gauss_indices[i]*transition_matrix[i][j][0])
            transition_matrix[i][j][0] = float(1 - transition_matrix[i][j][1])
        else:
            transition_matrix[i][j][0] = float(gauss_indices[i]*transition_matrix[i][j][1])
            transition_matrix[i][j][1] = float(1 - transition_matrix[i][j][0])
325/134: transition_matrix
327/1: import numpy as np
327/2: data = np.load("processed_data.npz")['data']
327/3: unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]
327/4: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
327/5: states_map
327/6: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
327/7: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
327/8: unique = np.unique(episodic_states)
327/9: transition_matrix = np.zeros((225,225,2))
327/10:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i - 1])[0][0]][0] += int(1)
        
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i])[0][0]][1] += int(1)
327/11:
row_sum = np.zeros((225))
for i in range(225):    
    for j in range(225):
        row_sum[i] += transition_matrix[i][j][0] + transition_matrix[i][j][1]
327/12: len(episodic_states)
327/13:
add = 0
for i in range(len(row_sum)):
    add += row_sum[i]
327/14: add
327/15: add
327/16:
for i in range(225):
    for j in range(225):
        transition_matrix[i][j][0] /= row_sum[i]
        transition_matrix[i][j][1] /= row_sum[i]
327/17: transition_matrix
327/18:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=0.1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
327/19: gauss = get_truncated_normal(0, 0.1, 0, 1)
327/20: gauss_indices = gauss.rvs(225)
327/21: gauss
327/22: gauss_indices
327/23: gauss_indices[0]
327/24: gauss_indices[224]
327/25: transition_matrix
327/26: transition_matrix[0][0][0]
327/27: gauss_indices[0]
327/28: gauss_indices[0] * transition_matrix[0][0][0]
327/29: gauss_indices[0] * transition_matrix[0][0][1]
327/30: gauss_indices[0] * transition_matrix[0][0][0]
327/31: 1 - gauss_indices[0] * transition_matrix[0][0][0]
327/32:
for i in range(225):
    for j in range(225):
        if transition_matrix[i][j][0] == 0:
            transition_matrix[i][j][1] = float(gauss_indices[i]*transition_matrix[i][j][1])
            transition_matrix[i][j][0] = float(1 - transition_matrix[i][j][1])
        else:
            transition_matrix[i][j][0] = float(gauss_indices[i]*transition_matrix[i][j][0])
            transition_matrix[i][j][1] = float(1 - transition_matrix[i][j][0])
327/33: transition_matrix
327/34:
print("Saving Transitions Matrix in 'transitions.npy' ...")
np.save("transitions", transition_matrix)
print("Done!")
326/1: import numpy as np
326/2:
def return_policy_evaluation(p, u, r, T, gamma):
    for s in range(225):
        if not np.isnan(p[s]):
            v = np.zeros((1,225))
            v[0,s] = 1.0
            action = int(p[s])
            u[s] = r[s] + gamma * np.sum(np.multiply(u, np.dot(v, T[:,:,action])))
    return u
326/3:
def return_policy_evaluation_linalg(p, r, T, gamma):
    u = np.zeros(225)
    for s in range(225):
        if not np.isnan(p[s]):
            action = int(p[s])
            u[s] = np.linalg.solve(np.identity(225) - gamma*T[:,:,action], r)[s]
    return u
326/4:
def return_expected_action(u, T, v):
    """Return the expected action.
    It returns an action based on the
    expected utility of doing a in state s, 
    according to T and u. This action is
    the one that maximize the expected
    utility.
    @param u utility vector
    @param T transition matrix
    @param v starting vector
    @return expected action (int)
    """
    actions_array = np.zeros(2)
    for action in range(2):
         #Expected utility of doing a in state s, according to T and u.
        actions_array[action] = np.sum(np.multiply(u, np.dot(v, T[:,:,action])))
    return np.argmax(actions_array)
326/5:
def main_iterative():
    """Finding the solution using the iterative approach
    """
    gamma = 0.999
    iteration = 0
    T = np.load("transitions.npy")

    #Generate the first policy randomly
    # Nan=Nothing, 0 = Stay, 1 = Move
    p = np.random.randint(0, 2, size=(225)).astype(np.float32)
#     p[5] = np.NaN
#     p[3] = p[7] = -1

    #Utility vectors
#     u = np.array([0.0, 0.0, 0.0,  0.0,
#                    0.0, 0.0, 0.0,  0.0,
#                    0.0, 0.0, 0.0,  0.0])

    u = np.zeros((225))

    #Reward vector
#     r = np.array([-0.04, -0.04, -0.04,  +1.0,
#                   -0.04,   0.0, -0.04,  -1.0,
#                   -0.04, -0.04, -0.04, -0.04])

    r = np.zeros((225))
    
    ### SET REWARD MATRIX BASED ON EPISODIC_STATES ###

    while True:
        iteration += 1
        epsilon = 0.0001
        #1- Policy evaluation
        u1 = u.copy()
        u = return_policy_evaluation(p, u, r, T, gamma)
        #Stopping criteria
        delta = np.absolute(u - u1).max()
        if delta < epsilon * (1 - gamma) / gamma: break
        for s in range(225):
            if not np.isnan(p[s]) and not p[s]==-1:
                v = np.zeros((1,225))
                v[0,s] = 1.0
                #2- Policy improvement
                a = return_expected_action(u, T, v)         
                if a != p[s]: p[s] = a
#         print_policy(p, shape=(3,4))

    print("=================== FINAL RESULT ==================")
    print("Iterations: " + str(iteration))
    print("Delta: " + str(delta))
    print("Gamma: " + str(gamma))
    print("Epsilon: " + str(epsilon))
    print("===================================================")
    print(u)
#     print(u[4:8])
#     print(u[8:12])
    print("===================================================")
#     print_policy(p, shape=(3,4))
#     print("===================================================")
326/6:
def main_linalg():
    """Finding the solution using a linear algebra approach
    """
    gamma = 0.999
    iteration = 0
    T = np.load("T.npy")

    #Generate the first policy randomly
    # Nan=Nothing, -1=Terminal, 0=Up, 1=Left, 2=Down, 3=Right
    p = np.random.randint(0, 4, size=(12)).astype(np.float32)
    p[5] = np.NaN
    p[3] = p[7] = -1

    #Utility vectors
    u = np.array([0.0, 0.0, 0.0,  0.0,
                   0.0, 0.0, 0.0,  0.0,
                   0.0, 0.0, 0.0,  0.0])

    #Reward vector
    r = np.array([-0.04, -0.04, -0.04,  +1.0,
                  -0.04,   0.0, -0.04,  -1.0,
                  -0.04, -0.04, -0.04, -0.04])

    while True:
        iteration += 1
        epsilon = 0.0001
        #1- Policy evaluation
        #u1 = u.copy()
        u = return_policy_evaluation_linalg(p, r, T, gamma)
        #Stopping criteria
        #delta = np.absolute(u - u1).max()
        #if (delta < epsilon * (1 - gamma) / gamma) or iteration > 100: break
        unchanged = True
        for s in range(12):
            if not np.isnan(p[s]) and not p[s]==-1:
                v = np.zeros((1,12))
                v[0,s] = 1.0
                #2- Policy improvement
                a = return_expected_action(u, T, v)         
                if a != p[s]: 
                    p[s] = a
                    unchanged = False
        print_policy(p, shape=(3,4))

        if unchanged: break

    print("=================== FINAL RESULT ==================")
    print("Iterations: " + str(iteration))
    #print("Delta: " + str(delta))
    print("Gamma: " + str(gamma))
    print("Epsilon: " + str(epsilon))
    print("===================================================")
    print(u[0:4])
    print(u[4:8])
    print(u[8:12])
    print("===================================================")
    print_policy(p, shape=(3,4))
    print("===================================================")
326/7:
main_iterative()
#main_linalg()
326/8:    p = np.random.randint(0, 2, size=(225)).astype(np.float32)
326/9: p
329/1:
import numpy as np

data = np.load("processed_data.npz")['data']

unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]

states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
329/2: states_map
329/3:
episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T

episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])

unique = np.unique(episodic_states)

transition_matrix = np.zeros((225,225,2))
329/4:
for i in range(1, len(episodic_states)):
    if episodic_states[i - 1] == episodic_states[i]:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i - 1])[0][0]][0] += int(1)
        
    else:
        transition_matrix[np.where(unique == episodic_states[i - 1])[0][0]][np.where(unique == episodic_states[i])[0][0]][1] += int(1)
329/5:
row_sum = np.zeros((225))
for i in range(225):    
    for j in range(225):
        row_sum[i] += transition_matrix[i][j][0] + transition_matrix[i][j][1]
329/6: len(episodic_states)
329/7:
add = 0
for i in range(len(row_sum)):
    add += row_sum[i]
329/8: add
329/9:
for i in range(225):
    for j in range(225):
        transition_matrix[i][j][0] /= row_sum[i]
        transition_matrix[i][j][1] /= row_sum[i]
329/10:
from scipy.stats import truncnorm

def get_truncated_normal(mean=0, sd=0.1, low=0, upp=1):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)

gauss = get_truncated_normal(0, 0.1, 0, 1)

gauss_indices = gauss.rvs(225)
329/11:
for i in range(225):
    for j in range(225):
        if transition_matrix[i][j][0] == 0:
            transition_matrix[i][j][1] = float(gauss_indices[i]*transition_matrix[i][j][1])
            transition_matrix[i][j][0] = float(1 - transition_matrix[i][j][1])
        else:
            transition_matrix[i][j][0] = float(gauss_indices[i]*transition_matrix[i][j][0])
            transition_matrix[i][j][1] = float(1 - transition_matrix[i][j][0])
329/12:
print("Saving Transitions Matrix in 'transitions.npy' ...")
np.save("transitions", transition_matrix)
print("Done!")
328/1:
import numpy as np

data = np.load("processed_data.npz")['data']

unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]

states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
328/2: states_map
328/3:
episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T

episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])

unique = np.unique(episodic_states)

transition_matrix = np.zeros((225))
328/4:
episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T

episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])

unique = np.unique(episodic_states)

reward_matrix = np.zeros((225))
328/5: states_map[0]
330/1:
import numpy as np
from tqdm import tqdm_notebook as tqdm
from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
330/2: data = np.load("processed_data.npz")["data"]
330/3: unique_states = [np.unique(data[:, e]) for e in range(data.shape[1])]
330/4: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
330/5: states_map = [{e[k]:k for k in range(len(e))} for e in unique_states]
330/6:
def get_random_state():
    state = np.array([np.random.randint(e) for e in [len(e) for e in unique_states]])
    return int("".join(state.astype(np.str)))

get_clashes = lambda x1, x2 : (int_to_int_array(x1)!=int_to_int_array(x2)).astype(np.float32)
int_to_int_array = lambda integer : np.array(list("{:05d}".format(integer))).astype(np.int32)
state_array_to_energy = lambda  state_array: [unique_states[k][state_array[k]] for k in range(data.shape[1])]
state_int_to_energy = lambda  x1: state_array_to_energy(int_to_int_array(x1))

get_energy_reward = lambda x1, x2 : -(-1*np.sum(state_int_to_energy(x1))+1*np.sum(state_int_to_energy(x2))).astype(np.float32)

def get_tm_reward(x1, x2):
    if x1 in base_map and x2 in base_map:
        return trans_mat[base_map[x1], base_map[x2]]
    else:
        return 0

get_reward = lambda x1, x2, C1, C2 : C1*get_energy_reward(x1, x2) + C2*get_tm_reward(x1, x2)

def 


(state, state_transition):
    rand = np.random.uniform()

    if state not in state_transition:
        return get_random_state()
    
    if rand < 0.01:
        items = list(state_transition[state].items())
        index = np.random.randint(len(items))
        return items[index][0]
    
    return sorted(state_transition[state].items(), key=lambda x: x[1])[-1][0]

num_clashes = lambda data, Q_table : [get_clashes(each_data[1], get_next_state(each_data[0], Q_table)) for each_data in data]
num_reward = lambda data, Q_table, C1, C2 : [get_reward(each_data[1], get_next_state(each_data[0], Q_table), C1, C2) for each_data in data]

def get_transition_matrix(states):
    base_states = np.unique(states)
    transistion_matrix = np.zeros([len(base_states), len(base_states)])
    base_map = {i:v for v, i in enumerate(base_states)}
    
    for e in range(1, len(states)):
        transistion_matrix[base_map[states[e-1]], base_map[states[e]]] += 1
    
    transistion_matrix /= np.sum(transistion_matrix, axis=1)
    return transistion_matrix, base_map
330/7:
def get_random_state():
    state = np.array([np.random.randint(e) for e in [len(e) for e in unique_states]])
    return int("".join(state.astype(np.str)))

get_clashes = lambda x1, x2 : (int_to_int_array(x1)!=int_to_int_array(x2)).astype(np.float32)
int_to_int_array = lambda integer : np.array(list("{:05d}".format(integer))).astype(np.int32)
state_array_to_energy = lambda  state_array: [unique_states[k][state_array[k]] for k in range(data.shape[1])]
state_int_to_energy = lambda  x1: state_array_to_energy(int_to_int_array(x1))

get_energy_reward = lambda x1, x2 : -(-1*np.sum(state_int_to_energy(x1))+1*np.sum(state_int_to_energy(x2))).astype(np.float32)

def get_tm_reward(x1, x2):
    if x1 in base_map and x2 in base_map:
        return trans_mat[base_map[x1], base_map[x2]]
    else:
        return 0

get_reward = lambda x1, x2, C1, C2 : C1*get_energy_reward(x1, x2) + C2*get_tm_reward(x1, x2)

def get_next_state(state, state_transition):
    rand = np.random.uniform()

    if state not in state_transition:
        return get_random_state()
    
    if rand < 0.01:
        items = list(state_transition[state].items())
        index = np.random.randint(len(items))
        return items[index][0]
    
    return sorted(state_transition[state].items(), key=lambda x: x[1])[-1][0]

num_clashes = lambda data, Q_table : [get_clashes(each_data[1], get_next_state(each_data[0], Q_table)) for each_data in data]
num_reward = lambda data, Q_table, C1, C2 : [get_reward(each_data[1], get_next_state(each_data[0], Q_table), C1, C2) for each_data in data]

def get_transition_matrix(states):
    base_states = np.unique(states)
    transistion_matrix = np.zeros([len(base_states), len(base_states)])
    base_map = {i:v for v, i in enumerate(base_states)}
    
    for e in range(1, len(states)):
        transistion_matrix[base_map[states[e-1]], base_map[states[e]]] += 1
    
    transistion_matrix /= np.sum(transistion_matrix, axis=1)
    return transistion_matrix, base_map
330/8: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
330/9: episodes = np.array([[states_map[e][data[k, e]] for k in range(data.shape[0])] for e in range(data.shape[1])]).T
330/10:
def get_random_state():
    state = np.array([np.random.randint(e) for e in [len(e) for e in unique_states]])
    return int("".join(state.astype(np.str)))

get_clashes = lambda x1, x2 : (int_to_int_array(x1)!=int_to_int_array(x2)).astype(np.float32)
int_to_int_array = lambda integer : np.array(list("{:05d}".format(integer))).astype(np.int32)
state_array_to_energy = lambda  state_array: [unique_states[k][state_array[k]] for k in range(data.shape[1])]
state_int_to_energy = lambda  x1: state_array_to_energy(int_to_int_array(x1))

get_energy_reward = lambda x1, x2 : -(-1*np.sum(state_int_to_energy(x1))+1*np.sum(state_int_to_energy(x2))).astype(np.float32)

def get_tm_reward(x1, x2):
    if x1 in base_map and x2 in base_map:
        return trans_mat[base_map[x1], base_map[x2]]
    else:
        return 0

get_reward = lambda x1, x2, C1, C2 : C1*get_energy_reward(x1, x2) + C2*get_tm_reward(x1, x2)

def get_next_state(state, state_transition):
    rand = np.random.uniform()

    if state not in state_transition:
        return get_random_state()
    
    if rand < 0.01:
        items = list(state_transition[state].items())
        index = np.random.randint(len(items))
        return items[index][0]
    
    return sorted(state_transition[state].items(), key=lambda x: x[1])[-1][0]

num_clashes = lambda data, Q_table : [get_clashes(each_data[1], get_next_state(each_data[0], Q_table)) for each_data in data]
num_reward = lambda data, Q_table, C1, C2 : [get_reward(each_data[1], get_next_state(each_data[0], Q_table), C1, C2) for each_data in data]

def get_transition_matrix(states):
    base_states = np.unique(states)
    transistion_matrix = np.zeros([len(base_states), len(base_states)])
    base_map = {i:v for v, i in enumerate(base_states)}
    
    for e in range(1, len(states)):
        transistion_matrix[base_map[states[e-1]], base_map[states[e]]] += 1
    
    transistion_matrix /= np.sum(transistion_matrix, axis=1)
    return transistion_matrix, base_map
330/11: episodic_states = np.array([int("".join(episodes[e].astype(str))) for e in range(episodes.shape[0])])
330/12: trans_mat, base_map = get_transition_matrix(episodic_states)
330/13: episodic_states = episodic_states.reshape([-1, 2])
330/14: np.random.seed(43)
330/15: np.random.shuffle(episodic_states)
330/16:
train_episodes = episodic_states[:int(0.7*len(episodic_states))]
val_episodes = episodic_states[int(0.7*len(episodic_states)):]
330/17:
discount = 0.5
num_epochs = 10
label_clashes = ["heater", "furnace", "lights", "fridge", "washer"]
330/18:
from concurrent.futures import ThreadPoolExecutor
executor = ThreadPoolExecutor(max_workers=4)
330/19:
def algorithm(lr, df, alpha, beta):
    state_transition = {}
    learning_Rate = lr
    discount_factor = df
    clashes = []
    rewards = []
    data = train_episodes
    index = 0
    
    for each_episode in tqdm(data):
        
        if index %200 ==1:
            clashes.append(np.mean(num_clashes(val_episodes, state_transition), axis=0))
            rewards.append(np.mean(num_reward(val_episodes, state_transition, 1, 0), axis=0))

        reward = get_reward(each_episode[0], each_episode[1], alpha, beta)
        
        max_value = 0
        next_state = each_episode[1]

        if next_state in state_transition:
            max_value = np.max(list(state_transition[next_state].values()))

        if each_episode[0] not in state_transition:
            state_transition[each_episode[0]] = {}

        if next_state not in state_transition[each_episode[0]]:
            state_transition[each_episode[0]][next_state] = 0

        state_transition[each_episode[0]][next_state] += learning_Rate*(reward + discount_factor*max_value - state_transition[each_episode[0]][next_state])
        
        index+=1

    return clashes, rewards
330/20:
second_output = algorithm(0.1, 0.3, 0, 1)
first_output = algorithm(0.1, 0.3, 1, 0)
output = algorithm(0.1, 0.3, 0.5, 0.5)
333/1:
import numpy as np
import torch
333/2: numpy.ones(2,2)
333/3: np.ones(2,2)
333/4: np.ones((2,2))
333/5: arr = np.ones((2,2))
333/6: torch.Tensor(arr)
333/7: torch.rand(2,2)
333/8:
torch.manual_seed(100)
torch.rand(2,2)
333/9:
torch.manual_seed(100)
torch.rand(2,2)
333/10:
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(100)
333/11: torch.cuda.is_available()
333/12: hello = torch.ones(2,2)
333/13: torch.cuda(hello)
333/14: hello.cuda()
333/15:
if torch.cuda.is_available():
    hello.cuda()
333/16: hello
333/17: hello.cp()
333/18: hello.cpu()
333/19:
a = torch.ones(2,2)
print(a)
333/20: a.view(4)
333/21: a.view(4).size()
333/22: b = torch.ones(2,2)
333/23: b.view(4)
333/24: c = torch.add(a,b)
333/25: c
333/26:
print(c)
c.add_(a)
print(c)
333/27: print(a.sub(b))
333/28: print(c.sub(a))
333/29: print(c)
333/30: print(c.sub_(a))
333/31: print(c)
333/32: from torch.autograd import Variable
333/33: a = Variable(torch.ones(2,2), requires_grad=True)
333/34: a
333/35: y = 5 * ((x + 1) ** 2)
333/36:
x = Variable(torch.ones(2), requires_grad = True)
y = 5 * ((x + 1) ** 2)
333/37: y
333/38: o = (1/2) * torch.sum(y)
333/39: o
333/40: o.backward()
333/41:
o.backward(torch.FloatTensor[1.0, 1.0])
x.grad
333/42:
o.backward(torch.FloatTensor([1.0, 1.0])
x.grad
333/43:
o.backward(torch.FloatTensor([1.0, 1.0]))
x.grad
333/44:
x = Variable(torch.ones(2), requires_grad = True)
x
333/45: y = 5 * ((x + 1) ** 2)
333/46: y
333/47: o = (1/2) * torch.sum(y)
333/48: o
333/49: y = 5 * (x + 1) ** 2
333/50: y
333/51: o = (1/2) * torch.sum(y)
333/52: o
333/53: o.backward()
333/54: x.grad
333/55:
o.backward(torch.FloatTensor([1.0, 1.0]))
x.grad
334/1:
import numpy as np
import matplotlib as plt
334/2:
np.random.seed(1)
n = 50
x = np.random.randn(n)
y = x * np.random.randn(n)

colors = np.random.randn(n)
plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))

plt.scatter(x, y, c = colors, alpha = 0.5)
plt.show()
334/3:
import numpy as np
import matplotlib.pyplot as plt
334/4:
np.random.seed(1)
n = 50
x = np.random.randn(n)
y = x * np.random.randn(n)

colors = np.random.randn(n)
plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))

plt.scatter(x, y, c = colors, alpha = 0.5)
plt.show()
334/5:
x_values = [i for i in range(11)]
x_values
334/6:
x_train = np.array(x_values, dtype=np.float32)
x_train.shape()
334/7:
x_train = np.array(x_values, dtype=np.float32)
x_train.shape
334/8:
x_train = x_train.shape(-1,1)
x_train.shape
334/9:
x_train = x_train.reshape(-1,1)
x_train.shape
334/10:
y_values = [2*i + 1 for i in x_values]
y_values
334/11:
y_train = np.array(y_values, dtype=np.float32)
y_train.shape
334/12:
y_train = y_train.reshape(-1,1)
y_train.shape
334/13:
import torch
import torch.nn as nn
from torch.autograd as Variable
334/14:
import torch
import torch.nn as nn
from torch.autograd import Variable
335/1:
class LinearRegressionModel(nn.Module):
    def __init__(self, input_size, output_size):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_size, output_size)
        
    def forward(self, x):
        out = self.linear(x)
        return out
336/1:
import numpy as np
import matplotlib.pyplot as plt
336/2:
np.random.seed(1)
n = 50
x = np.random.randn(n)
y = x * np.random.randn(n)

colors = np.random.randn(n)
plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))

plt.scatter(x, y, c = colors, alpha = 0.5)
plt.show()
336/3:
x_values = [i for i in range(11)]
x_values
336/4:
x_train = np.array(x_values, dtype=np.float32)
x_train.shape
336/5:
x_train = x_train.reshape(-1,1)
x_train.shape
336/6:
y_values = [2*i + 1 for i in x_values]
y_values
336/7:
y_train = np.array(y_values, dtype=np.float32)
y_train.shape
336/8:
y_train = y_train.reshape(-1,1)
y_train.shape
336/9:
import torch
import torch.nn as nn
from torch.autograd import Variable
336/10:
class LinearRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, output_dim)
    
    def forward(self, x):
        out = self.linear(x)
        return out
336/11:
input_dim = 1
output_dim = 1
model = LinearRegressionModel(input_dim, output_dim)
336/12: criterion = nn.MSELoss()
336/13:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
336/14: epochs = 100
336/15:
for epoch in range(epochs):
    epoch+=1
    inputs = Variable(torch.from_numpy(x_train))
    labels = Variable(torch.from_numpy(y_train))
    
    optimizer.zero_grad()
    
    outputs = model(inputs)
    
    loss = criterion(outputs, labels)
    
    loss.backward()
    
    optimizer.step()
    
    print("Epoch {}, loss {}".format(epoch, loss.data[0]))
336/16:
for epoch in range(epochs):
    epoch+=1
    inputs = Variable(torch.from_numpy(x_train))
    labels = Variable(torch.from_numpy(y_train))
    
    optimizer.zero_grad()
    
    outputs = model(inputs)
    
    loss = criterion(outputs, labels)
    
    loss.backward()
    
    optimizer.step()
    
    print('Epoch {}, loss {}' .format(epoch, loss))
336/17:
predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()
predicted
336/18:
plt.clf()

plt.plot(x_train, y_train, 'go', label = 'True data', alpha = 0.5)

plt.plot(x_train, predicted, '--', label = 'Predicted data', alpha = 0.5)

plt.legend(loc = 'best')

plt.show()
336/19: %save
336/20:
save_model = False
if save_model is True:
    torch.save(model.state_dict(), 'trial_model.pkl')
336/21:
load_model = False
if load_model is True:
    model.load_state_dict(torch.load('trial_model.pkl'))
336/22: model
336/23:
if torch.cuda.is_available():
    model.cuda()
336/24: epochs = 100
336/25:
for epoch in range(epochs):
    epoch += 1
    
    if torch.cuda.is_available():
        inputs = Variable(torch.from_numpy(x_train).cuda())
        labels = Variable(torch.from_numpy(y_train).cuda())
    else:
        inputs = Variable(torch.from_numpy(x_train))
        labels = Variable(torch.from_numpy(y_train))
    
    optimizer.zero_grad()
    
    outputs = model(inputs)
    
    loss = criterion(outputs, labels)
    
    loss.backward()
    
    optimizer.step()
    
    print("Epoch {}, Loss {}".format(epoch, loss))
337/1:
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.autograd import Variable
337/2:
train_dataset = datasets.MNIST('./data', 
                              train=True,
                              transform=transforms.ToTensor(),
                              download=True)
337/3: len(train_dataset)
337/4: train_dataset.shape
337/5: train_dataset[0].shape
337/6: train_dataset[0]
337/7: train_dataset[0][0].shape
337/8: train_dataset[0][0].size
337/9: train_dataset[0][0].size()
337/10: train_dataset[0][1]
337/11:
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
337/12: train_dataset[0][0].numpy().shape
337/13: show_img = train_dataset[0][0].numpy().reshape(28,28)
337/14: plt.imshow(show_img, cmap='gray')
337/15: plt.imshow(show_img, cmap='white')
337/16: plt.imshow(show_img, cmap='black')
337/17: plt.imshow(show_img, cmap='gray')
337/18:
test_dataset = datasets.MNIST('./data',
                             train=False,
                             transform = transforms.ToTensor())
337/19: len(test_dataset)
337/20:
batch_size = 100
n_iters = 3000
337/21:
num_epochs = n_iters/(len(train_dataset)/batch_size)
num_epochs
337/22:
train_loader = torch.utils.data.dataloader(dataset = train_dataset,
                                          batch_size = batch_size,
                                          shuffle = False)
337/23:
train_loader = torch.utils.data.Dataloader(dataset = train_dataset,
                                          batch_size = batch_size,
                                          shuffle = False)
337/24:
train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                          batch_size = batch_size,
                                          shuffle = False)
337/25:
train_loader = torch.utils.data.DataLoader(dataset = train_dataset,
                                          batch_size = batch_size,
                                          shuffle = True)
337/26:
import collections
isinstance(train_loader, collections.Iterable)
337/27:
test_loader = torch.utils.data.DataLoader(dataset = test_dataset,
                                         batch_size = batch_size,
                                         shuffle = False)
337/28: isinstance(test_loader, collections.Iterable)
337/29:
class LogisticRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LogisticRegressionModel, self).__init__()
        self.Linear = nn.Linear(input_dim, output_dim)
        
    def forward(self, x):
        out = self.linear(x)
        return out
337/30:
input_dim = 28*28
output_dim = 10

model = LogisticRegressionModel(input_dim=input_dim, output_dim=output_dim)
337/31: criterion = nn.CrossEntropyLoss()
337/32:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
337/33:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%100 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss.data[0], accuracy))
337/34:
class LogisticRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LogisticRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, output_dim)
        
    def forward(self, x):
        out = self.linear(x)
        return out
337/35:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%100 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss.data[0], accuracy))
336/26:
class LinearRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, output_dim)
    
    def forward(self, x):
        out = self.linear(x)
        return out
337/36:
class LogisticRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(LogisticRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, output_dim)
        
    def forward(self, x):
        out = self.linear(x)
        return out
337/37:
input_dim = 28*28
output_dim = 10

model = LogisticRegressionModel(input_dim=input_dim, output_dim=output_dim)
337/38: criterion = nn.CrossEntropyLoss()
337/39:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
337/40:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%100 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss.data[0], accuracy))
337/41:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%100 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
337/42:
batch_size = 100
n_iters = 6000
337/43:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%100 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 1000 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
337/44:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28))
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%1000 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
337/45:
save_model = True
if save_model is True:
    torch.save(model.state_dict(), 'log_reg.pkl')
337/46:
if torch.cuda.is_available():
    model.cuda()
337/47:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28).cuda())
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%1000 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted.cpu() == labels.cpu()).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
337/48:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28).cuda())
        labels = Variable(labels.cuda())
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%1000 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted.cpu() == labels.cpu()).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
337/49:
iter = 0

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28).cuda())
        labels = Variable(labels.cuda())
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter += 1
        
        if iter%1000 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28).cuda())
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted.cpu() == labels.cpu()).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
338/1:
import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transform
from torch.autgrad import Variable
338/2:
import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transform
from torch.autograd import Variable
338/3:
train_dataset = dsets.MNIST(root = './data',
                           train = True,
                           transform = transform.ToTensor(),
                           shuffle = True)

test_dataset = dsets.MNIST(root = './data',
                          train = False,
                          transform = transform.ToTensor())
338/4:
train_dataset = dsets.MNIST(root = './data',
                           train = True,
                           transform = transform.ToTensor(),
                           download = True)

test_dataset = dsets.MNIST(root = './data',
                          train = False,
                          transform = transform.ToTensor())
338/5:
batch_size = 100
n_iters = 3000
num_epochs = n_iters / (len(train_dataset)/batch_size)
num_epochs = int(num_epochs)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                          batch_size=batch_size,
                                          shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                         batch_size=batch_size,
                                         shuffle=False)
338/6:
class FeedForwardNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(FeedForwardNeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.sigmoid = nn.Sigmoid()
        self.fc2 = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        out = self.fc1(x)
        out = self.sigmoid(out)
        out = self.fc2(out)
        return out
338/7:
input_dim = 28*28
hidden_dim = 100
output_dim = 10

model = FeedForwardNeuralNetwork(input_dim, hidden_dim, output_dim)
338/8: criterion = nn.CrossEntropyLoss()
338/9:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)
338/10: print(model.parameters())
338/11: print(len(list(model.parameters())))
338/12: print(list(model.parameters())[0].size)
338/13: print(list(model.parameters())[0].size())
338/14: print(list(model.parameters())[1].size())
338/15: print(list(model.parameters())[2].size())
338/16: print(list(model.parameters())[3].size())
338/17: print(list(model.parameters()).size())
338/18: print(list(model.parameters()))
338/19: enumerate(train_loader)
338/20: enumerate(train_loader).size
338/21: enumerate(train_loader).size()
338/22: list(enumerate(train_loader)).size()
338/23: list(enumerate(train_loader)).shape
338/24: list(enumerate(train_loader))[00.shape
338/25: list(enumerate(train_loader))[0].shape
338/26:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        iter+=1
        
        if iter%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
338/27:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if iter%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
338/28:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iter%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(iter, loss, accuracy))
338/29:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iter%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(n_iter, loss, accuracy))
338/30:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iters%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                outputs = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(n_iters, loss, accuracy))
338/31:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iters%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                output = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(n_iters, loss, accuracy))
338/32:
class FeedForwardNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(FeedForwardNeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.tanh = nn.Tanh()
        self.fc2 = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        out = self.fc1(x)
        out = self.tanh(out)
        out = self.fc2(out)
        return out
338/33:
input_dim = 28*28
hidden_dim = 100
output_dim = 10

model = FeedForwardNeuralNetwork(input_dim, hidden_dim, output_dim)
338/34: criterion = nn.CrossEntropyLoss()
338/35:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)
338/36:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iters%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                output = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(n_iters, loss, accuracy))
338/37:
class FeedForwardNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(FeedForwardNeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out
338/38:
input_dim = 28*28
hidden_dim = 100
output_dim = 10

model = FeedForwardNeuralNetwork(input_dim, hidden_dim, output_dim)
338/39: criterion = nn.CrossEntropyLoss()
338/40:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)
338/41:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iters%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                output = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(n_iters, loss, accuracy))
338/42:
class FeedForwardNeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(FeedForwardNeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden_size, output_size)
        
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu1(out)
        out = self.fc2(out)
        out = self.relu2(out)
        out = self.fc3(out)
        return out
338/43:
input_dim = 28*28
hidden_dim = 100
output_dim = 10

model = FeedForwardNeuralNetwork(input_dim, hidden_dim, output_dim)
338/44: criterion = nn.CrossEntropyLoss()
338/45:
learning_rate = 0.01

optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)
338/46:
n_iters = 0
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = Variable(images.view(-1, 28*28)) 
        labels = Variable(labels)
        
        optimizer.zero_grad()
        
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        
        loss.backward()
        
        optimizer.step()
        
        n_iters+=1
        
        if n_iters%500 == 0:
            correct = 0
            total = 0
            
            for images, labels in test_loader:
                images = Variable(images.view(-1, 28*28))
                output = model(images)
                _, predicted = torch.max(output.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum()
                
            accuracy = 100 * correct/total
            
            print("Iteration: {}, Loss: {}, Accuracy: {}".format(n_iters, loss, accuracy))
339/1:
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as dsets
from torch.autograd import Variable
339/2:
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transforms=transforms.ToTensor(),
                            shuffle=True)

test_dataset = dsets.MNIST(root='./data',
                          train=False,
                          transforms=transforms.ToTensor())
339/3:
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transforms=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                          train=False,
                          transforms=transforms.ToTensor())
339/4:
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data',
                          train=False,
                          transform=transforms.ToTensor())
339/5: print(train_dataset.train_data.size())
339/6: print(test_dataset.test_data.size())
339/7:
batch_size = 100
n_iters = 3000
num_epochs = n_iters / (len(train_dataset)/batch_size)
num_epochs = int(num_epochs)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                          batch_size=batch_size,
                                          shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                         batch_size=batch_size,
                                         shuffle=False)
345/1:

"""
@author: sumanyumuku98
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
%matplotlib inline
from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
346/1:

"""
@author: sumanyumuku98
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
%matplotlib inline
from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
346/2:
# """
# COnverting the Multi-Class Problem into Binary-CLass

# C0: Undistracted driving
# C1-C9: Distracted driving
# """
# INFO_FILE = pd.read_csv("state-farm-distracted-driver-detection/driver_imgs_list.csv")
# INFO_FILE['Binary_labels'] = INFO_FILE.apply(lambda row: 0 if row.classname=='c0' else 1, axis=1 )
# NUM_CLASSES=2
# INFO_FILE.head()
temp_dir='data/v1_cam1_no_split/'
NUM_CLASSES=10
CLASS_LABELS=['c' + str(i) for i in range(10)]
CLASSES_LIST=['Drive Safe', 'Text Right', 'Talk Right', 'Text Left', 'Talk Left',
              'Adjust Radio', 'Drink', 'Reach Behind', 'Hair & Makeup', 'Talk Passenger']
346/3:
IMAGE_PREDIR = 'data/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
346/4:

"""
@author: sumanyumuku98
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
%matplotlib inline
from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
346/5:
# """
# COnverting the Multi-Class Problem into Binary-CLass

# C0: Undistracted driving
# C1-C9: Distracted driving
# """
# INFO_FILE = pd.read_csv("state-farm-distracted-driver-detection/driver_imgs_list.csv")
# INFO_FILE['Binary_labels'] = INFO_FILE.apply(lambda row: 0 if row.classname=='c0' else 1, axis=1 )
# NUM_CLASSES=2
# INFO_FILE.head()
temp_dir='data/v1_cam1_no_split/'
NUM_CLASSES=10
CLASS_LABELS=['c' + str(i) for i in range(10)]
CLASSES_LIST=['Drive Safe', 'Text Right', 'Talk Right', 'Text Left', 'Talk Left',
              'Adjust Radio', 'Drink', 'Reach Behind', 'Hair & Makeup', 'Talk Passenger']
346/6:
# Pretrained Models

inception = models.inception_v3(pretrained=True)
for param in inception.parameters():
    param.requires_grad=False
inception.fc = torch.nn.Linear(2048,NUM_CLASSES)
#######################################################
mobilenet = models.mobilenet_v2(pretrained=True)
for param in mobilenet.parameters():
    param.requires_grad=False
mobilenet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
########################################################
resnet = models.resnet50(pretrained=True)
for param in resnet.parameters():
    param.requires_grad=False
resnet.fc = torch.nn.Linear(2048,NUM_CLASSES)
########################################################
vgg = models.vgg16(pretrained=True)
for param in vgg.parameters():
    param.requires_grad=False
vgg.classifier[6] = torch.nn.Linear(4096,NUM_CLASSES)
vgg.classifier.add_module("softmax",torch.nn.Softmax(dim=-1))
346/7:
mobilenet = models.mobilenet_v2(pretrained=True)
for param in mobilenet.parameters():
    param.requires_grad=False
mobilenet.classifier[1]=torch.nn.Linear(1280,NUM_CLASSES)
346/8:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
mnasnet = models.mnasnet1_0(pretrained=True)
for param in mnasnet.parameters():
    param.requires_grad=False
mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/9:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
mnasnet = models.mnasnet(pretrained=True)
for param in mnasnet.parameters():
    param.requires_grad=False
mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/10:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
mnasnet = models.mnasnet1_0()(pretrained=True)
for param in mnasnet.parameters():
    param.requires_grad=False
mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/11:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
mnasnet = models.mnasnet1_0(pretrained=True)
for param in mnasnet.parameters():
    param.requires_grad=False
mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/12: torch.__version__
346/13: torchvision.__version__
346/14:
import torchvision
torchvision.__version__
346/15:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
mnasnet = models.mnasnet1_0(pretrained=True)
for param in mnasnet.parameters():
    param.requires_grad=False
mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/16:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
# mnasnet = models.mnasnet1_0(pretrained=True)
# for param in mnasnet.parameters():
#     param.requires_grad=False
# mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/17:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
# mnasnet = models.mnasnet1_0(pretrained=True)
# for param in mnasnet.parameters():
#     param.requires_grad=False
# mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
346/18:
squeezenetMod=torch.nn.Sequential(squeezenet,
                                  torch.nn.Linear(1000,NUM_CLASSES))
346/19:
# a = torch.FloatTensor(np.random.randint(0,2,(2,3)))
# soft = torch.nn.Softmax(dim=-1)
# print(a,soft(a))
346/20:
"""
Preprocess for pytorch pretrained models
"""

def preprocess(sample):
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
    transform=  transforms.Compose([
        transforms.RandomResizedCrop(299),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize,])
    
    img = sample['image']
    label = sample['label']
    
#     print(label, type(label))
    
    sample['image'] = transform(img)
    sample['label'] = torch.as_tensor(label)
    
    return sample
    
class Driver_Dataset(Dataset):
    
    def __init__(self,IMAGE_PREDIR,preprocess = None, mode='train',split=0.8):
        
        self.root_dir = IMAGE_PREDIR
        self.transform = preprocess
        self.mode=mode
        self.split=split
        self.totalTrainImages=[]
        self.totalTrainLabels=[]
        self.totalTestImages=[]
        self.totalTestLabels=[]
        self.images=None
        self.labels=None
        
        for c in CLASS_LABELS:
            for name in glob.glob(self.root_dir+CAMERA1+'/train/'+c+'/*.jpg'):
                self.totalTrainImages.append(name)
                self.totalTrainLabels.append(CLASS_LABELS.index(c))
            for name in glob.glob(self.root_dir+CAMERA2+'/train/'+c+'/*.jpg'):
                self.totalTrainImages.append(name)
                self.totalTrainLabels.append(CLASS_LABELS.index(c))
                
            for name in glob.glob(self.root_dir+CAMERA1+'/test/'+c+'/*.jpg'):
                self.totalTestImages.append(name)
                self.totalTestLabels.append(CLASS_LABELS.index(c))
            for name in glob.glob(self.root_dir+CAMERA2+'/test/'+c+'/*.jpg'):
                self.totalTestImages.append(name)
                self.totalTestLabels.append(CLASS_LABELS.index(c))
                
        if self.mode=='train':
            length=len(self.totalTrainImages)
            self.images= self.totalTrainImages[:int(self.split*length)]
            self.labels=self.totalTrainLabels[:int(self.split*length)]
        
        elif self.mode=='val':
            length=len(self.totalTrainImages)
            self.images= self.totalTrainImages[int(self.split*length):]
            self.labels=self.totalTrainLabels[int(self.split*length):]
        else:
            self.images=self.totalTestImages
            self.labels=self.totalTestLabels

        
        
    def __len__(self):
        return len(self.images)
        
    def __getitem__(self, idx):
        
        label = self.labels[idx]
#         print(type(label))
        img_name = self.images[idx]
        img = Image.open(img_name)

        sample = {'image': img, 'label': label}
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample
    
    def listcheck(self):
        return self.images,self.labels
346/21:
trainData= Driver_Dataset(IMAGE_PREDIR,preprocess,'train',0.95)
valData=Driver_Dataset(IMAGE_PREDIR,preprocess,'val',0.95)
trainLoader=DataLoader(trainData,batch_size=16,shuffle=True)
valLoader=DataLoader(valData,batch_size=16,shuffle=True)
346/22:
IMAGE_PREDIR = 'data/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
346/23:
trainData= Driver_Dataset(IMAGE_PREDIR,preprocess,'train',0.95)
valData=Driver_Dataset(IMAGE_PREDIR,preprocess,'val',0.95)
trainLoader=DataLoader(trainData,batch_size=16,shuffle=True)
valLoader=DataLoader(valData,batch_size=16,shuffle=True)
347/1:

"""
@author: pickle0412
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader

%matplotlib inline

from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
347/2:
resnet18 = models.resnet18()
alexnet = models.alexnet()
vgg16 = models.vgg16()
squeezenet = models.squeezenet1_0()
densenet = models.densenet161()
inception = models.inception_v3()
googlenet = models.googlenet()
shufflenet = models.shufflenet_v2_x1_0()
mobilenet = models.mobilenet_v2()
resnext50_32x4d = models.resnext50_32x4d()
wide_resnet50_2 = models.wide_resnet50_2()
mnasnet = models.mnasnet1_0()
347/3:
resnet18 = models.resnet18()
alexnet = models.alexnet()
vgg16 = models.vgg16()
squeezenet = models.squeezenet1_0()
densenet = models.densenet161()
inception = models.inception_v3()
googlenet = models.googlenet()
shufflenet = models.shufflenet_v2_x1_0()
mobilenet = models.mobilenet_v2()
resnext50_32x4d = models.resnext50_32x4d()

mnasnet = models.mnasnet1_0()
347/4:
resnet18 = models.resnet18()
alexnet = models.alexnet()
vgg16 = models.vgg16()
squeezenet = models.squeezenet1_0()
densenet = models.densenet161()
inception = models.inception_v3()
googlenet = models.googlenet()
shufflenet = models.shufflenet_v2_x1_0()
mobilenet = models.mobilenet_v2()
resnext50_32x4d = models.resnext50_32x4d()
347/5:
resnet18 = models.resnet18(pretrained=True)
alexnet = models.alexnet(pretrained=True)
squeezenet = models.squeezenet1_0(pretrained=True)
vgg16 = models.vgg16(pretrained=True)
densenet = models.densenet161(pretrained=True)
inception = models.inception_v3(pretrained=True)
googlenet = models.googlenet(pretrained=True)
shufflenet = models.shufflenet_v2_x1_0(pretrained=True)
mobilenet = models.mobilenet_v2(pretrained=True)
resnext50_32x4d = models.resnext50_32x4d(pretrained=True)
347/6:
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}
348/1:

"""
@author: sumanyumuku98
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
%matplotlib inline
from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
348/2:
# """
# COnverting the Multi-Class Problem into Binary-CLass

# C0: Undistracted driving
# C1-C9: Distracted driving
# """
# INFO_FILE = pd.read_csv("state-farm-distracted-driver-detection/driver_imgs_list.csv")
# INFO_FILE['Binary_labels'] = INFO_FILE.apply(lambda row: 0 if row.classname=='c0' else 1, axis=1 )
# NUM_CLASSES=2
# INFO_FILE.head()
temp_dir='data/v1_cam1_no_split/'
NUM_CLASSES=10
CLASS_LABELS=['c' + str(i) for i in range(10)]
CLASSES_LIST=['Drive Safe', 'Text Right', 'Talk Right', 'Text Left', 'Talk Left',
              'Adjust Radio', 'Drink', 'Reach Behind', 'Hair & Makeup', 'Talk Passenger']
348/3:
IMAGE_PREDIR = 'data/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
348/4:
# Pretrained Models

inception = models.inception_v3(pretrained=True)
for param in inception.parameters():
    param.requires_grad=False
inception.fc = torch.nn.Linear(2048,NUM_CLASSES)
#######################################################
mobilenet = models.mobilenet_v2(pretrained=True)
for param in mobilenet.parameters():
    param.requires_grad=False
mobilenet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
########################################################
resnet = models.resnet50(pretrained=True)
for param in resnet.parameters():
    param.requires_grad=False
resnet.fc = torch.nn.Linear(2048,NUM_CLASSES)
########################################################
vgg = models.vgg16(pretrained=True)
for param in vgg.parameters():
    param.requires_grad=False
vgg.classifier[6] = torch.nn.Linear(4096,NUM_CLASSES)
vgg.classifier.add_module("softmax",torch.nn.Softmax(dim=-1))
348/5:
mobilenet = models.mobilenet_v2(pretrained=True)
for param in mobilenet.parameters():
    param.requires_grad=False
mobilenet.classifier[1]=torch.nn.Linear(1280,NUM_CLASSES)
348/6:
import torchvision
torchvision.__version__
348/7:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
# squeezenet.add_module("fc", torch.nn.Linear(1000,NUM_CLASSES))
#############################
# mnasnet = models.mnasnet1_0(pretrained=True)
# for param in mnasnet.parameters():
#     param.requires_grad=False
# mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
348/8:
squeezenetMod=torch.nn.Sequential(squeezenet,
                                  torch.nn.Linear(1000,NUM_CLASSES))
348/9:
# a = torch.FloatTensor(np.random.randint(0,2,(2,3)))
# soft = torch.nn.Softmax(dim=-1)
# print(a,soft(a))
348/10:
"""
Preprocess for pytorch pretrained models
"""

def preprocess(sample):
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
    transform=  transforms.Compose([
        transforms.RandomResizedCrop(299),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize,])
    
    img = sample['image']
    label = sample['label']
    
#     print(label, type(label))
    
    sample['image'] = transform(img)
    sample['label'] = torch.as_tensor(label)
    
    return sample
    
class Driver_Dataset(Dataset):
    
    def __init__(self,IMAGE_PREDIR,preprocess = None, mode='train',split=0.8):
        
        self.root_dir = IMAGE_PREDIR
        self.transform = preprocess
        self.mode=mode
        self.split=split
        self.totalTrainImages=[]
        self.totalTrainLabels=[]
        self.totalTestImages=[]
        self.totalTestLabels=[]
        self.images=None
        self.labels=None
        
        for c in CLASS_LABELS:
            for name in glob.glob(self.root_dir+CAMERA1+'/train/'+c+'/*.jpg'):
                self.totalTrainImages.append(name)
                self.totalTrainLabels.append(CLASS_LABELS.index(c))
            for name in glob.glob(self.root_dir+CAMERA2+'/train/'+c+'/*.jpg'):
                self.totalTrainImages.append(name)
                self.totalTrainLabels.append(CLASS_LABELS.index(c))
                
            for name in glob.glob(self.root_dir+CAMERA1+'/test/'+c+'/*.jpg'):
                self.totalTestImages.append(name)
                self.totalTestLabels.append(CLASS_LABELS.index(c))
            for name in glob.glob(self.root_dir+CAMERA2+'/test/'+c+'/*.jpg'):
                self.totalTestImages.append(name)
                self.totalTestLabels.append(CLASS_LABELS.index(c))
                
        if self.mode=='train':
            length=len(self.totalTrainImages)
            self.images= self.totalTrainImages[:int(self.split*length)]
            self.labels=self.totalTrainLabels[:int(self.split*length)]
        
        elif self.mode=='val':
            length=len(self.totalTrainImages)
            self.images= self.totalTrainImages[int(self.split*length):]
            self.labels=self.totalTrainLabels[int(self.split*length):]
        else:
            self.images=self.totalTestImages
            self.labels=self.totalTestLabels

        
        
    def __len__(self):
        return len(self.images)
        
    def __getitem__(self, idx):
        
        label = self.labels[idx]
#         print(type(label))
        img_name = self.images[idx]
        img = Image.open(img_name)

        sample = {'image': img, 'label': label}
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample
    
    def listcheck(self):
        return self.images,self.labels
348/11:
trainData= Driver_Dataset(IMAGE_PREDIR,preprocess,'train',0.95)
valData=Driver_Dataset(IMAGE_PREDIR,preprocess,'val',0.95)
trainLoader=DataLoader(trainData,batch_size=16,shuffle=True)
valLoader=DataLoader(valData,batch_size=16,shuffle=True)
348/12: # print(vgg)
348/13:
def train(model,dataloaderList,epochs, device = 'cpu',saveName=None):
    model.to(device)
    trainloader=dataloaderList[0]
    valloader=dataloaderList[1]
    optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)
    Crossloss=torch.nn.CrossEntropyLoss()
    valAccList=[]
    
    print('Start Training...')
    for epoch in range(epochs):
        running_loss=0
        
        for i_batch, data in enumerate(trainloader):
            
            optimizer.zero_grad()

            images=Variable(data['image'],requires_grad=True).to(device)
            labels=Variable(data['label']).to(device)
            
            outputs=model(images)
            loss=Crossloss(outputs,labels)
            loss.backward()
            optimizer.step()
            
            running_loss+=loss.item()
            
            # Print Training Statistics
            del images,labels,outputs
            
            if i_batch%100==99:
                print('[%2d,%5d] Training Loss: %.3f'  % 
                      (epoch+1,i_batch+1,running_loss/100))
                running_loss=0
                
        print('Validating the model')
        
        with torch.no_grad():
            valPreds=[]
            valLabels=[]
            for i_batch, data in enumerate(valloader):
                
                images= data['image'].to(device)
                labels= data['label'].numpy()
                
                preds=model(images)
                preds=preds.cpu().numpy()
                
                pred_labels=np.argmax(preds,axis=1)
                valPreds.append(pred_labels)
                valLabels.append(labels)
            
            valPreds=np.concatenate(valPreds)
            valLabels=np.concatenate(valLabels)
        
            acc=accuracy_score(valLabels,valPreds)
            valAccList.append(acc)
            print('Accuracy after epoch %2d is %.3f' % (epoch+1,acc))
    
    print("Finished Training")
    print("Saving Model")
    torch.save(model.state_dict,'Model_weights/'+saveName+'.pt')
    
    return model,valAccList
348/14: inceptionTrainedModel,valAcc=  train(inception,[trainLoader,valLoader],1,device,'inception')
348/15: mobilenetTrainedModel,valAcc=  train(mobilenet,[trainLoader,valLoader],1,device,'mobilenet')
348/16:
def train(model,dataloaderList,epochs, device = device ,saveName=None):
    model.to(device)
    trainloader=dataloaderList[0]
    valloader=dataloaderList[1]
    optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)
    Crossloss=torch.nn.CrossEntropyLoss()
    valAccList=[]
    
    print('Start Training...')
    for epoch in range(epochs):
        running_loss=0
        
        for i_batch, data in enumerate(trainloader):
            
            optimizer.zero_grad()

            images=Variable(data['image'],requires_grad=True).to(device)
            labels=Variable(data['label']).to(device)
            
            outputs=model(images)
            loss=Crossloss(outputs,labels)
            loss.backward()
            optimizer.step()
            
            running_loss+=loss.item()
            
            # Print Training Statistics
            del images,labels,outputs
            
            if i_batch%100==99:
                print('[%2d,%5d] Training Loss: %.3f'  % 
                      (epoch+1,i_batch+1,running_loss/100))
                running_loss=0
                
        print('Validating the model')
        
        with torch.no_grad():
            valPreds=[]
            valLabels=[]
            for i_batch, data in enumerate(valloader):
                
                images= data['image'].to(device)
                labels= data['label'].numpy()
                
                preds=model(images)
                preds=preds.cpu().numpy()
                
                pred_labels=np.argmax(preds,axis=1)
                valPreds.append(pred_labels)
                valLabels.append(labels)
            
            valPreds=np.concatenate(valPreds)
            valLabels=np.concatenate(valLabels)
        
            acc=accuracy_score(valLabels,valPreds)
            valAccList.append(acc)
            print('Accuracy after epoch %2d is %.3f' % (epoch+1,acc))
    
    print("Finished Training")
    print("Saving Model")
    torch.save(model.state_dict,'Model_weights/'+saveName+'.pt')
    
    return model,valAccList
348/17: mobilenetTrainedModel,valAcc=  train(mobilenet,[trainLoader,valLoader],1,device,'mobilenet')
348/18: resnetTrainedModel,valAcc=  train(resnet,[trainLoader,valLoader],1,device,'resnet')
348/19: device
348/20:

"""
@author: sumanyumuku98
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
%matplotlib inline
from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd
import random

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
348/21:
# """
# COnverting the Multi-Class Problem into Binary-CLass

# C0: Undistracted driving
# C1-C9: Distracted driving
# """
# INFO_FILE = pd.read_csv("state-farm-distracted-driver-detection/driver_imgs_list.csv")
# INFO_FILE['Binary_labels'] = INFO_FILE.apply(lambda row: 0 if row.classname=='c0' else 1, axis=1 )
# NUM_CLASSES=2
# INFO_FILE.head()
# temp_dir='data/v1_cam1_no_split/'
NUM_CLASSES=10
CLASS_LABELS=['c' + str(i) for i in range(10)]
CLASSES_LIST=['Drive Safe', 'Text Right', 'Talk Right', 'Text Left', 'Talk Left',
              'Adjust Radio', 'Drink', 'Reach Behind', 'Hair & Makeup', 'Talk Passenger']
348/22:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
349/1:

"""
@author: sumanyumuku98
"""

import numpy as np
import matplotlib.pyplot as plt
import torch 
import torchvision.models as models
from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader
%matplotlib inline
from numpy import moveaxis
from skimage import io, transform
from torch.autograd import Variable
from PIL import Image
import os
import glob
import pandas as pd
import random

import plotly
# import bokeh
from sklearn.metrics import accuracy_score

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# device='cpu'
print(device)
349/2:
# """
# COnverting the Multi-Class Problem into Binary-CLass

# C0: Undistracted driving
# C1-C9: Distracted driving
# """
# INFO_FILE = pd.read_csv("state-farm-distracted-driver-detection/driver_imgs_list.csv")
# INFO_FILE['Binary_labels'] = INFO_FILE.apply(lambda row: 0 if row.classname=='c0' else 1, axis=1 )
# NUM_CLASSES=2
# INFO_FILE.head()
# temp_dir='data/v1_cam1_no_split/'
NUM_CLASSES=10
CLASS_LABELS=['c' + str(i) for i in range(10)]
CLASSES_LIST=['Drive Safe', 'Text Right', 'Talk Right', 'Text Left', 'Talk Left',
              'Adjust Radio', 'Drink', 'Reach Behind', 'Hair & Makeup', 'Talk Passenger']
349/3:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
349/4:
# Pretrained Models
#######################################################
mobilenet = models.mobilenet_v2(pretrained=True)
for param in mobilenet.parameters():
    param.requires_grad=False
mobilenet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
# mobilenet.classifier.add_module("2",torch.nn.Softmax(dim=-1))
########################################################
resnet = models.resnet50(pretrained=True)
for param in resnet.parameters():
    param.requires_grad=False
resnet.fc = torch.nn.Linear(2048,NUM_CLASSES)
# resnet.add_module("softmax",torch.nn.Softmax(dim=-1))
########################################################
vgg = models.vgg16(pretrained=True)
for param in vgg.parameters():
    param.requires_grad=False
vgg.classifier[6] = torch.nn.Linear(4096,NUM_CLASSES)
# vgg.classifier.add_module("softmax",torch.nn.Softmax(dim=-1))
349/5:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
squeezenet.classifier[1]=torch.nn.Conv2d(512,NUM_CLASSES,kernel_size=(1,1),stride=(1,1))
    
#############################
mnasnet = models.mnasnet1_0(pretrained=True)
for param in mnasnet.parameters():
    param.requires_grad=False
mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
# mnasnet.classifier.add_module("2",torch.nn.Softmax(dim=-1))
349/6: trainedModel,valAcc=  train(squeezenet,[trainLoader,valLoader],1,device,'squeezenet')
349/7:
squeezenet = models.squeezenet1_1(pretrained=True)
for param in squeezenet.parameters():
    param.requires_grad=False
squeezenet.classifier[1]=torch.nn.Conv2d(512,NUM_CLASSES,kernel_size=(1,1),stride=(1,1))
    
#############################
# mnasnet = models.mnasnet1_0(pretrained=True)
# for param in mnasnet.parameters():
#     param.requires_grad=False
# mnasnet.classifier[1] = torch.nn.Linear(1280,NUM_CLASSES)
# mnasnet.classifier.add_module("2",torch.nn.Softmax(dim=-1))
349/8:
"""
Preprocess for pytorch pretrained models
"""

def preprocess(sample):
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
    transform=  transforms.Compose([
        transforms.RandomResizedCrop(299),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        normalize,])
    
    img = sample['image']
    label = sample['label']
    
#     print(label, type(label))
    
    sample['image'] = transform(img)
    sample['label'] = torch.as_tensor(label)
    
    return sample
    
class Driver_Dataset(Dataset):
    
    def __init__(self,IMAGE_PREDIR,preprocess = None, mode='train',split=0.8):
        
        self.root_dir = IMAGE_PREDIR
        self.transform = preprocess
        self.mode=mode
        self.split=split
        self.totalTrainImages=[]
        self.totalTrainLabels=[]
        self.totalTestImages=[]
        self.totalTestLabels=[]
        self.images=None
        self.labels=None
        
        for c in CLASS_LABELS:
            for name in glob.glob(self.root_dir+CAMERA1+'/train/'+c+'/*.jpg'):
                self.totalTrainImages.append(name)
                self.totalTrainLabels.append(CLASS_LABELS.index(c))
            for name in glob.glob(self.root_dir+CAMERA2+'/train/'+c+'/*.jpg'):
                self.totalTrainImages.append(name)
                self.totalTrainLabels.append(CLASS_LABELS.index(c))
                
            for name in glob.glob(self.root_dir+CAMERA1+'/test/'+c+'/*.jpg'):
                self.totalTestImages.append(name)
                self.totalTestLabels.append(CLASS_LABELS.index(c))
            for name in glob.glob(self.root_dir+CAMERA2+'/test/'+c+'/*.jpg'):
                self.totalTestImages.append(name)
                self.totalTestLabels.append(CLASS_LABELS.index(c))
        
        shuffle_list=list(zip(self.totalTrainImages,self.totalTrainLabels))
        random.shuffle(shuffle_list)
        self.totalTrainImages,self.totalTrainLabels=zip(*shuffle_list)
        
        if self.mode=='train':
            length=len(self.totalTrainImages)
            self.images= self.totalTrainImages[:int(self.split*length)]
            self.labels=self.totalTrainLabels[:int(self.split*length)]
        
        elif self.mode=='val':
            length=len(self.totalTrainImages)
            self.images= self.totalTrainImages[int(self.split*length):]
            self.labels=self.totalTrainLabels[int(self.split*length):]
        else:
            self.images=self.totalTestImages
            self.labels=self.totalTestLabels

        
        
    def __len__(self):
        return len(self.images)
        
    def __getitem__(self, idx):
        
        label = self.labels[idx]
#         print(type(label))
        img_name = self.images[idx]
        img = Image.open(img_name)

        sample = {'image': img, 'label': label}
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample
    
    def listcheck(self):
        return self.images,self.labels
349/9:
trainData= Driver_Dataset(IMAGE_PREDIR,preprocess,'train',0.95)
valData=Driver_Dataset(IMAGE_PREDIR,preprocess,'val',0.95)
trainLoader=DataLoader(trainData,batch_size=16,num_workers=4)
valLoader=DataLoader(valData,batch_size=16,num_workers=4)
# DataLoader?
349/10: Crossloss=torch.nn.CrossEntropyLoss()
349/11:
def train(model,dataloaderList,epochs, device = 'cpu',saveName=None):
    model.to(device)
    trainloader=dataloaderList[0]
    valloader=dataloaderList[1]
    paramsToUpdate=[]
    
    for param in model.parameters():
        if param.requires_grad:
            paramsToUpdate.append(param)
    
    optimizer=torch.optim.SGD(paramsToUpdate,lr=1e-4)

    valAccList=[]
    
    print('Start Training...')
    for epoch in range(epochs):
        running_loss=0
        
        for i_batch, data in enumerate(trainloader):
            

            images=Variable(data['image'],requires_grad=True).to(device)
            labels=Variable(data['label']).to(device)
            
            outputs=model(images)
            
            optimizer.zero_grad()

            loss=Crossloss(outputs,labels)
            loss.backward()
            optimizer.step()
            
            running_loss+=loss.item()
            
            # Print Training Statistics
            del images,labels,outputs
            
            if i_batch%100==99:
                print('[%2d,%5d] Training Loss: %.3f'  % 
                      (epoch+1,i_batch+1,running_loss/100))
                running_loss=0
                
        print('Validating the model')
        
        with torch.no_grad():
            valPreds=[]
            valLabels=[]
            for i_batch, data in enumerate(valloader):
                
                images= data['image'].to(device)
                labels= data['label'].numpy()
                
                preds=model(images)
                preds=preds.cpu().numpy()
                
                pred_labels=np.argmax(preds,axis=-1)
                valPreds.append(pred_labels)
                valLabels.append(labels)
            
            valPreds=np.concatenate(valPreds)
            valLabels=np.concatenate(valLabels)
            size=valPreds.shape[0]
            running_corrects=np.sum(valPreds==valLabels)
        
            acc=float(running_corrects)/size
            valAccList.append(acc)
            print('Accuracy after epoch %2d is %.3f' % (epoch+1,acc))
#             print(valPreds)
#             print(valLabels)
    
    print("Finished Training")
    print("Saving Model")
    torch.save(model.state_dict(),'Model_weights/'+saveName+'.pt')
    
    return model,valAccList
349/12: trainedModel,valAcc=  train(squeezenet,[trainLoader,valLoader],1,device,'squeezenet')
349/13: squeezenetTrainedModel,valAcc=  train(squeezenet,[trainLoader,valLoader],10,device,'squeezenet')
349/14: mobilenetTrainedModel,valAcc=  train(mobilenet,[trainLoader,valLoader],10,device,'mobilenet')
349/15: resnetTrainedModel,valAcc=  train(resnet,[trainLoader,valLoader],10,device,'resnet')
349/16: vggTrainedModel,valAcc=  train(vgg,[trainLoader,valLoader],10,device,'vgg')
350/1:
import numpy as np
import cv2
from matplotlib import pyplot as plt
350/2:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
350/3:
img = cv2.imread(IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg')
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (50,50,450,290)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/4: cv2.imshow((IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg'))
350/5: cv2.imshow(IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg')
350/6: cv2.imshow("", IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg')
350/7: cv2.imshow("custom", IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg')
350/8: plt.imshow(IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg')
350/9: image= IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg'
350/10: image.shape
350/11: sample = cv2.imread(IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg', cv2.IMREAD_UNCHANGEDN)
350/12: sample = cv2.imread(IMAGE_PREDIR+CAMERA1+'train'+'c0'+'1000.jpg', cv2.IMREAD_UNCHANGED)
350/13: sample.shape
350/14: sample.dtype
350/15: dtype(sample)
350/16: sample
350/17: sample = cv2.imread(IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg', cv2.IMREAD_UNCHANGED)
350/18: sample
350/19: sample.shape
350/20: plt.imshow(sample)
350/21:
img = cv2.imread(sample)
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (50,50,450,290)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/22:
img = cv2.imread("", sample)
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (50,50,450,290)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/23:
img = cv2.imread(sample)
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (50,50,450,290)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/24:
img = sample
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (50,50,450,290)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/25:
img = sample
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (300,0,1200,1080)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/26:
img = sample
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (300,100,1200,980)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
350/27:
import os
import glob
350/28:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
IMAGE_POSTDIR = 'AUCdata_preprocessed/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1'
CAMERA2='Camera 2'
350/29:
def grabcut_image(img):
    mask = np.zeros(img.shape[:2],np.uint8)

    bgdModel = np.zeros((1,65),np.float64)
    fgdModel = np.zeros((1,65),np.float64)

    rect = (300,100,1200,980)
    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
    img = img*mask2[:,:,np.newaxis]
350/30:
def grabcut_image(img):
    mask = np.zeros(img.shape[:2],np.uint8)

    bgdModel = np.zeros((1,65),np.float64)
    fgdModel = np.zeros((1,65),np.float64)

    rect = (300,100,1200,980)
    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
    img = img*mask2[:,:,np.newaxis]
    
    return img
350/31: plt.imshow(grabcut_image(sample))
350/32:
for i in range(10):
    for name in glob.glob(IMAGE_PREDIR+CAMERA1+'/train/'+c+'/*.jpg'):
        image = grabcut_image(name)
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'/train/'+c+'/*.jpg', image)
350/33:
for i in range(10):
    for name in glob.glob(IMAGE_PREDIR+CAMERA1+'/train/'+'c'+'/*.jpg'):
        image = grabcut_image(name)
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'/train/'+c+'/*.jpg', image)
350/34:
for i in range(10):
    for name in glob.glob(IMAGE_PREDIR+CAMERA1+'/train/'+'c'+'/*.jpg'):
        image = grabcut_image(name)
        print(image)
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'/train/'+c+'/*.jpg', image)
350/35:
for name in glob.glob(IMAGE_PREDIR+CAMERA1+'/train/'+'c0'+'/*.jpg'):
    image = grabcut_image(name)
    print(image)
    cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'/train/'+'c0'+'/*.jpg', image)
350/36:
for name in glob.glob(IMAGE_PREDIR+CAMERA1+'/train/'+'c0'+'/*.jpg'):
    image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
    image = grabcut_image(image)
    cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'/train/'+'c0'+'/*.jpg', image)
350/37:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
IMAGE_POSTDIR = 'AUCdata_preprocessed/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1/'
CAMERA2='Camera 2/'
350/38:
d = 0
for name in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+'c0'+'/*.jpg'):
    image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
    image = grabcut_image(image)
    cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+'c0'+'/_%d.jpg'%d, image) 
    d += 1
350/39:
CLASS_LABELS=['c' + str(i) for i in range(10)]
d = 1
for c in CLASS_LABELS:
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/40:
import os
import glob
import tqdm
350/41:
CLASS_LABELS=['c' + str(i) for i in range(10)]
for c in CLASS_LABELS:
    d = 1
    for image in tqdm(glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg')):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/42:
CLASS_LABELS=['c' + str(i) for i in range(10)]
for c in tqdm(CLASS_LABELS):
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/43:
CLASS_LABELS=['c' + str(i) for i in tqdm(range(10))]
for c in CLASS_LABELS:
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/44:
CLASS_LABELS=['c' + str(i) for i in tqdm(range(0, 10))]
for c in CLASS_LABELS:
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/45:
import os
import glob
from tqdm import tqdm
350/46:
CLASS_LABELS=['c' + str(i) for i in tqdm(range(0, 10))]
for c in CLASS_LABELS:
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/47:
CLASS_LABELS=['c' + str(i) for i in range(0, 10)]
for c in CLASS_LABELS:
    d = 1
    for image in tqdm(glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg')):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = str(d) + ".jpg"
        cv2.imwrite(IMAGE_POSTDIR+CAMERA1+'train/'+c+'/', name) 
        d += 1
    print("Class "+c+" done!")
350/48:
CLASS_LABELS=['c' + str(i) for i in range(0, 10)]
for c in CLASS_LABELS:
    d = 1
    for image in tqdm(glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg')):
        image = cv2.imread(name, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = IMAGE_POSTDIR+CAMERA1+'train/'+c+'/' + str(d) + ".jpg"
        cv2.imwrite(name, image) 
        d += 1
    print("Class "+c+" done!")
350/49:
CLASS_LABELS=['c' + str(i) for i in range(0, 10)]
for c in CLASS_LABELS:
    d = 1
    for image in tqdm(glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg')):
        image = cv2.imread(image, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = IMAGE_POSTDIR+CAMERA1+'train/'+c+'/' + str(d) + ".jpg"
        cv2.imwrite(name, image) 
        d += 1
    print("Class "+c+" done!")
350/50:
CLASS_LABELS=['c' + str(i) for i in range(0, 10)]
for c in tqdm(CLASS_LABELS):
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(image, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        name = IMAGE_POSTDIR+CAMERA1+'train/'+c+'/' + str(d) + ".jpg"
        cv2.imwrite(name, image) 
        d += 1
    print("Class "+c+" done!")
350/51:
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
name = IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg"
cv2.imwrite(name, image)
350/52:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
name = IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg"
cv2.imwrite(name, image)
350/53:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
name = r+IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg"
cv2.imwrite(name, image)
350/54:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
# name = r+IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg"
cv2.imwrite(r'AUCdata_preprocessed/v2_cam1_cam2_ split_by_driver/'+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg", image)
350/55:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
# name = r+IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg"
cv2.imwrite('AUCdata_preprocessed/v2_cam1_cam2_ split_by_driver/'+CAMERA1+'train/'+'c0/'+ str(1) + ".jpg", image)
350/56:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
file_path = IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'
file_name = str(1) + '.jpg'
cv2.imwrite(os.path.join(file_name, file_path), image)
350/57:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
file_path = IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'
file_name = str(1) + '.jpg'
cv2.imwrite(os.path.join(file_path, file_name), image)
350/58:
from PIL import Image
import PIL
350/59: print(file_path+file_name)
350/60:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
IMAGE_POSTDIR = 'AUCdata_preprocessed/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1/'
CAMERA2='Camera 2/'
350/61: print(file_path+file_name)
350/62:
sample = IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg'
image = cv2.imread(sample, cv2.IMREAD_UNCHANGED)
image = grabcut_image(image)
file_path = IMAGE_POSTDIR+CAMERA1+'train/'+'c0/'
file_name = str(1) + '.jpg'
cv2.imwrite(os.path.join(file_path, file_name), image)
350/63:
CLASS_LABELS=['c' + str(i) for i in range(0, 10)]
for c in CLASS_LABELS:
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(image, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        file_path = IMAGE_POSTDIR+CAMERA1+'train/'+c+'/'
        file_name = str(d) + ".jpg"
        cv2.imwrite(os.path.join(file_path, file_name), image) 
        d += 1
    print("Class "+c+" done!")
353/1:
import numpy as np
import cv2
from matplotlib import pyplot as plt
353/2:
IMAGE_PREDIR = 'AUCdata/v2_cam1_cam2_ split_by_driver/'
IMAGE_POSTDIR = 'AUCdata_preprocessed/v2_cam1_cam2_ split_by_driver/'
CAMERA1='Camera 1/'
CAMERA2='Camera 2/'
353/3: sample = cv2.imread(IMAGE_PREDIR+CAMERA1+'/train'+'/c0'+'/1000.jpg', cv2.IMREAD_UNCHANGED)
353/4: sample.shape
353/5: plt.imshow(sample)
353/6:
img = sample
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

rect = (300,100,1200,980)
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
img = img*mask2[:,:,np.newaxis]

plt.imshow(img),plt.colorbar(),plt.show()
353/7:
def grabcut_image(img):
    mask = np.zeros(img.shape[:2],np.uint8)

    bgdModel = np.zeros((1,65),np.float64)
    fgdModel = np.zeros((1,65),np.float64)

    rect = (300,100,1200,980)
    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
    img = img*mask2[:,:,np.newaxis]
    
    return img
353/8: plt.imshow(grabcut_image(sample))
353/9:
import os
import glob
from tqdm import tqdm
353/10:
CLASS_LABELS=['c' + str(i) for i in range(0, 10)]
for c in CLASS_LABELS:
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA1+'train/'+c+'/*.jpg'):
        image = cv2.imread(image, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        file_path = IMAGE_POSTDIR+CAMERA1+'train/'+c+'/'
        file_name = str(d) + ".jpg"
        cv2.imwrite(os.path.join(file_path, file_name), image) 
        d += 1
    print("Class "+c+" done!")
    

for c in CLASS_LABELS:
    d = 1
    for image in glob.glob(IMAGE_PREDIR+CAMERA2+'train/'+c+'/*.jpg'):
        image = cv2.imread(image, cv2.IMREAD_UNCHANGED)
        image = grabcut_image(image)
        file_path = IMAGE_POSTDIR+CAMERA2+'train/'+c+'/'
        file_name = str(d) + ".jpg"
        cv2.imwrite(os.path.join(file_path, file_name), image) 
        d += 1
    print("Class "+c+" done!")
354/1:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as dsets
from torch.autograd import Variable
354/2:
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=2)
        self.relu1 = nn.ReLU()
        
        self.maxpool1 = nn.MaxPool2d(kernel_size=3)
        self.Dropout(p=0.3)
        
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=2)
        self.relu2 = nn.ReLU()
        
        self.maxpool2 = nn.MaxPool2d(kernel_size=3)
        self.Dropout(p=0.3)
        
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=2)
        self.relu3 = nn.ReLU()
        
        self.maxpool3 = nn.MaxPool2d(kernel_size=3)
        self.Dropout(p=0.3)
        
        self.fc1 = nn.Linear(256*25*25, 192)
        self.Dropout(p=0.3)
        
        self.fc2 = nn.Linear(192, 10)
        self.softmax = torch.nn.Softmax(10)
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        
        out = self.maxpool1(out)
        
        out = self.conv2(out)
        out = self.relu2(out)
        
        out = self.maxpool2(out)
        
        out = self.conv3(out)
        out = self.relu3(out)
        
        out = self.maxpool3(out)
        
        out = out.view(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.fc2(out)
        out = self.softmax(out)
        
        return out
354/3: model = CNNModel()
354/4:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as dsets
from torch.autograd import Variable
354/5:
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=2)
        self.relu1 = nn.ReLU()
        
        self.maxpool1 = nn.MaxPool2d(kernel_size=3)
        self.Dropout(p=0.3)
        
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=2)
        self.relu2 = nn.ReLU()
        
        self.maxpool2 = nn.MaxPool2d(kernel_size=3)
        self.nn.Dropout(p=0.3)
        
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=2)
        self.relu3 = nn.ReLU()
        
        self.maxpool3 = nn.MaxPool2d(kernel_size=3)
        self.nn.Dropout(p=0.3)
        
        self.fc1 = nn.Linear(256*25*25, 192)
        self.nn.Dropout(p=0.3)
        
        self.fc2 = nn.Linear(192, 10)
        self.softmax = torch.nn.Softmax(10)
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        
        out = self.maxpool1(out)
        
        out = self.conv2(out)
        out = self.relu2(out)
        
        out = self.maxpool2(out)
        
        out = self.conv3(out)
        out = self.relu3(out)
        
        out = self.maxpool3(out)
        
        out = out.view(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.fc2(out)
        out = self.softmax(out)
        
        return out
354/6: model = CNNModel()
354/7:
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=2)
        self.relu1 = nn.ReLU()
        
        self.maxpool1 = nn.MaxPool2d(kernel_size=3)
        self.nn.Dropout(p=0.3)
        
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=2)
        self.relu2 = nn.ReLU()
        
        self.maxpool2 = nn.MaxPool2d(kernel_size=3)
        self.nn.Dropout(p=0.3)
        
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=2)
        self.relu3 = nn.ReLU()
        
        self.maxpool3 = nn.MaxPool2d(kernel_size=3)
        self.nn.Dropout(p=0.3)
        
        self.fc1 = nn.Linear(256*25*25, 192)
        self.nn.Dropout(p=0.3)
        
        self.fc2 = nn.Linear(192, 10)
        self.softmax = torch.nn.Softmax(10)
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        
        out = self.maxpool1(out)
        
        out = self.conv2(out)
        out = self.relu2(out)
        
        out = self.maxpool2(out)
        
        out = self.conv3(out)
        out = self.relu3(out)
        
        out = self.maxpool3(out)
        
        out = out.view(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.fc2(out)
        out = self.softmax(out)
        
        return out
354/8: model = CNNModel()
354/9:
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=2)
        self.relu1 = nn.ReLU()
        
        self.maxpool1 = nn.MaxPool2d(kernel_size=3)
        self.dropout1 = nn.Dropout(p=0.3)
        
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=2)
        self.relu2 = nn.ReLU()
        
        self.maxpool2 = nn.MaxPool2d(kernel_size=3)
        self.dropout2 = nn.Dropout(p=0.3)
        
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=2)
        self.relu3 = nn.ReLU()
        
        self.maxpool3 = nn.MaxPool2d(kernel_size=3)
        self.dropout3 = nn.Dropout(p=0.3)
        
        self.fc1 = nn.Linear(256*25*25, 192)
        self.dropout4 = nn.Dropout(p=0.3)
        
        self.fc2 = nn.Linear(192, 10)
        self.softmax = torch.nn.Softmax(10)
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        
        out = self.maxpool1(out)
        out = self.dropout1(out)
        
        out = self.conv2(out)
        out = self.relu2(out)
        
        out = self.maxpool2(out)
        out = self.dropout2(out)
        
        out = self.conv3(out)
        out = self.relu3(out)
        
        out = self.maxpool3(out)
        out = self.dropout3(out)
        
        out = out.view(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.dropout4(out) 
        
        out = self.fc2(out)
        out = self.softmax(out)
        
        return out
354/10: model = CNNModel()
354/11: model?
354/12: model.parameters
354/13: sample_input = torch.rand(100,100,3)
354/14: sample_input
354/15: res = model(sample_input)
354/16: sample_input = torch.rand(10,3, 100,100)
354/17: res = model(sample_input)
354/18:
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=2)
        self.relu1 = nn.ReLU()
        
        self.maxpool1 = nn.MaxPool2d(kernel_size=3)
        self.dropout1 = nn.Dropout(p=0.3)
        
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=2)
        self.relu2 = nn.ReLU()
        
        self.maxpool2 = nn.MaxPool2d(kernel_size=3)
        self.dropout2 = nn.Dropout(p=0.3)
        
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=2)
        self.relu3 = nn.ReLU()
        
        self.maxpool3 = nn.MaxPool2d(kernel_size=3)
        self.dropout3 = nn.Dropout(p=0.3)
        
        self.fc1 = nn.Linear(256, 192)
        self.dropout4 = nn.Dropout(p=0.3)
        
        self.fc2 = nn.Linear(192, 10)
        self.softmax = torch.nn.Softmax(10)
        
    def forward(self, x):
        out = self.conv1(x)
        out = self.relu1(out)
        
        out = self.maxpool1(out)
        out = self.dropout1(out)
        
        out = self.conv2(out)
        out = self.relu2(out)
        
        out = self.maxpool2(out)
        out = self.dropout2(out)
        
        out = self.conv3(out)
        out = self.relu3(out)
        
        out = self.maxpool3(out)
        out = self.dropout3(out)
        
        out = out.view(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.dropout4(out) 
        
        out = self.fc2(out)
        out = self.softmax(out)
        
        return out
354/19: model = CNNModel()
354/20: sample_input = torch.rand(10,3, 100,100)
354/21: res = model(sample_input)
354/22:
batch_size = 1

input = torch.randn(3, 100, 100)
354/23: res = model(batch_size, input)
354/24: res = model(input)
354/25: res = model(1, input)
357/1: import pandas_datareader.data as web
357/2: from datetime import datetime
357/3:
start = datetime(2016, 9, 1)
end = datetime(2018, 9, 1)
357/4: f = web.DataReader('F', 'iex', start, end)
357/5:  os.environ["IEX_API_KEY"] = pk_531a49f4937a410b98760aa717e5dd34
357/6:  os.environ["IEX_API_KEY"] = 'pk_531a49f4937a410b98760aa717e5dd34'
357/7:
import pandas_datareader.data as web
import os
357/8:  os.environ["IEX_API_KEY"] = 'pk_531a49f4937a410b98760aa717e5dd34'
357/9: f = web.DataReader('F', 'iex', start, end)
357/10: f.loc['2018-08-31']
   1: %history -g -f are_you_paying_attention
