{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# from utils import *\n",
    "from models import init_vgg, Mononito\n",
    "from utils import *\n",
    "# from utils import progress_bar\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from numpy import moveaxis\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZO_AdaMM(object):\n",
    "    \"\"\"\n",
    "    Black Box optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,inputVar,func,timesteps=1,alpha=None,beta_1=None,beta_2=None,m=None,v=None,\n",
    "                 v_app=None,device='cpu'):\n",
    "        self.inputVar=inputVar\n",
    "        self.orgShape=self.inputVar.shape\n",
    "        \n",
    "        if len(self.orgShape)!=0:\n",
    "            self.inputVar=torch.flatten(self.inputVar)\n",
    "            self.dim=np.prod(self.orgShape)\n",
    "            self.scalar=False\n",
    "        else:\n",
    "            self.scalar=True\n",
    "        \n",
    "        try:\n",
    "            if not torch.is_tensor(self.inputVar):\n",
    "                raise TypeError\n",
    "        except TypeError:\n",
    "            print(\"Input should be a tensor\")\n",
    "         \n",
    "        #self.inputVar.requires_grad_()\n",
    "        self.func=func\n",
    "        \n",
    "        self.args={'timesteps':timesteps,'alpha':alpha,'beta_1':beta_1,'beta_2':beta_2,\n",
    "                   'm':m,'v':v,'v_app':v_app}\n",
    "        \n",
    "        self.timesteps=timesteps\n",
    "        self.mu=1.0\n",
    "        \n",
    "        if alpha==None:\n",
    "            self.alpha=np.random.uniform(1e-3,1e-2,size=(self.timesteps,))\n",
    "            \n",
    "        if beta_1==None:\n",
    "            self.beta_1=np.random.uniform(1e-3,1e-2,size=(self.timesteps,))\n",
    "        \n",
    "        if beta_2==None:\n",
    "            self.beta_2=np.random.uniform(0,1)\n",
    "            \n",
    "        if m==None:\n",
    "            if not self.scalar:\n",
    "                self.m=torch.zeros(self.dim).double().to(device)\n",
    "            else:\n",
    "                self.m=torch.tensor(0.0).to(device)\n",
    "        if v==None:\n",
    "            if not self.scalar:\n",
    "                self.v=torch.zeros(self.dim).double().to(device)\n",
    "            else:\n",
    "                self.v=torch.tensor(0.0).to(device)\n",
    "        \n",
    "        if v_app==None:\n",
    "            if not self.scalar:\n",
    "                self.v_app=torch.zeros(self.dim).double().to(device)\n",
    "            else:\n",
    "                self.v_app=torch.tensor(0.0).to(device)\n",
    "        \n",
    "        if not self.scalar:\n",
    "            self.grad=torch.zeros(self.dim).double().to(device)\n",
    "        else:\n",
    "            self.grad=torch.tensor(0.0).to(device)\n",
    "        \n",
    "    def step(self):\n",
    "        for t in range(self.timesteps):\n",
    "            if not self.scalar:\n",
    "                u=torch.tensor(np.random.uniform(0,1,self.dim)).double().to(device)\n",
    "            else:\n",
    "                u=torch.tensor(np.random.uniform()).to(device)\n",
    "            \n",
    "            if not self.scalar:\n",
    "                g_t= (self.func((self.inputVar+self.mu*u).reshape(self.orgShape))-\n",
    "                      self.func(self.inputVar.reshape(self.orgShape)))*(self.dim/self.mu)*u\n",
    "#                 print(g_t.dtype)\n",
    "            else:\n",
    "                g_t= (self.func(self.inputVar+self.mu*u)-self.func(self.inputVar))*(1.0/self.mu)*u\n",
    "            \n",
    "            self.m=self.beta_1[t]*self.m + (1.0-self.beta_1[t])*g_t\n",
    "            self.v=self.beta_2*self.v + (1.0-self.beta_2)*(g_t**2)\n",
    "            \n",
    "            self.v_app=torch.max(self.v_app,self.v)\n",
    "            \n",
    "            if not self.scalar:\n",
    "                if device=='cpu':\n",
    "                    v_app_np= np.diag(self.v_app.flatten().detach().numpy())\n",
    "                else:\n",
    "                    v_app_np= np.diag(self.v_app.flatten().cpu().detach().numpy())\n",
    "\n",
    "            else:\n",
    "                v_app_np=self.v_app.numpy()\n",
    "            \n",
    "            \n",
    "            if not self.scalar:\n",
    "                if device=='cpu':\n",
    "                    self.grad= torch.tensor(np.matmul(self.alpha[t]*linalg.fractional_matrix_power(v_app_np,-0.5),\n",
    "                                                      self.m.flatten().detach().numpy())).to(device)\n",
    "                else:\n",
    "                    self.grad= torch.tensor(np.matmul(self.alpha[t]*linalg.fractional_matrix_power(v_app_np,-0.5),\n",
    "                                                      self.m.flatten().cpu().detach().numpy())).to(device)\n",
    "            else:\n",
    "                self.grad=torch.tensor(self.alpha[t]*np.power(v_app_np,-0.5)*self.m.numpy()).to(device)\n",
    "            \n",
    "            self.inputVar=self.inputVar-self.grad\n",
    "            \n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.__init__(self.inputVar,self.func,**self.args)\n",
    "    \n",
    "    def returnInput(self):\n",
    "        if not self.scalar:\n",
    "            return self.inputVar.reshape(self.orgShape)\n",
    "        else:\n",
    "            return self.inputVar\n",
    "            \n",
    "    def gradFn(self):\n",
    "        return self.grad.reshape(self.orgShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PATH='./Model_weights/'\n",
    "TEST_PATH='./data/v2_cam1_cam2_ split_by_driver/Camera 1/train'\n",
    "classes=[\"c\"+ str(i) for i in range(10)]\n",
    "# classes.index(\"c3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualseed=random.randint(1,10000)\n",
    "random.seed(manualseed)\n",
    "np.random.seed(manualseed)\n",
    "torch.manual_seed(manualseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(manualseed)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.3, inplace=False)\n",
       "  (3): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Dropout(p=0.2, inplace=False)\n",
       "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vggModel=init_vgg()\n",
    "vggWeights=torch.load(WEIGHT_PATH+'vgg.pt')\n",
    "vggModel.load_state_dict(vggWeights)\n",
    "vggModel.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mononito(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout1): Dropout(p=0.3, inplace=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout3): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=192, bias=True)\n",
       "  (dropout4): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=192, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mononitoModel=Mononito()\n",
    "mononitoWeights=torch.load(WEIGHT_PATH+'are_you_paying_attention.pt')\n",
    "mononitoModel.load_state_dict(mononitoWeights)\n",
    "mononitoModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.216\n",
      "[1,  4000] loss: 1.885\n",
      "[1,  6000] loss: 1.672\n",
      "[1,  8000] loss: 1.589\n",
      "[1, 10000] loss: 1.519\n",
      "[1, 12000] loss: 1.469\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=False, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_in, max_in = 32, 32\n",
    "min_in, max_in = np.array([min_in, min_in, min_in]), np.array([max_in, max_in, max_in])\n",
    "mean, std = np.array(0.5), np.array(0.5) \n",
    "min_out, max_out = np.min((min_in-mean)/std), np.max((max_in-mean)/std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to define\n",
    "\n",
    "target = 0\n",
    "conf_target = 0.9\n",
    "max_count = 100\n",
    "patch_type = 'circle'\n",
    "patch_size = 0.05\n",
    "image_size = 32\n",
    "train_size = 50000\n",
    "test_size = 10000\n",
    "plot_all = 1\n",
    "outf='./tmp'\n",
    "# logfile='./tmp/log.txt'\n",
    "zoAdamm=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier,train_loader, epoch, patch, patch_shape):\n",
    "    classifier.eval()\n",
    "    success = 0\n",
    "    total = 0\n",
    "    recover_time = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.double().to(device)\n",
    "#             print(data.dtype)\n",
    "            labels = labels.to(device)\n",
    "        data, labels = Variable(data), Variable(labels)\n",
    "\n",
    "        prediction = classifier(data)\n",
    " \n",
    "        # only computer adversarial examples on examples that are originally classified correctly        \n",
    "        if prediction.data.max(1)[1][0] != labels.data[0]:\n",
    "            continue\n",
    "     \n",
    "        total += 1\n",
    "        \n",
    "        # transform path\n",
    "        data_shape = data.data.cpu().numpy().shape\n",
    "        if patch_type == 'circle':\n",
    "            patch, mask, patch_shape = circle_transform(patch, data_shape, patch_shape, image_size)\n",
    "        elif patch_type == 'square':\n",
    "            patch, mask  = square_transform(patch, data_shape, patch_shape, image_size)\n",
    "        patch, mask = torch.FloatTensor(patch), torch.FloatTensor(mask)\n",
    "        if torch.cuda.is_available():\n",
    "            patch, mask = patch.to(device), mask.to(device)\n",
    "        patch, mask = Variable(patch), Variable(mask)\n",
    " \n",
    "        adv_x, mask, patch = attack(classifier, data, patch, mask)\n",
    "        \n",
    "        adv_label = classifier(adv_x).data.max(1)[1][0]\n",
    "        ori_label = labels.data[0]\n",
    "        \n",
    "        if adv_label == target:\n",
    "            success += 1\n",
    "      \n",
    "            if plot_all == 1: \n",
    "                # plot source image\n",
    "                vutils.save_image(data.data, \"./%s/%d_%d_original.png\" %(outf, batch_idx, ori_label), normalize=True)\n",
    "                \n",
    "                # plot adversarial image\n",
    "                vutils.save_image(adv_x.data, \"./%s/%d_%d_adversarial.png\" %(outf, batch_idx, adv_label), normalize=True)\n",
    " \n",
    "        masked_patch = torch.mul(mask, patch)\n",
    "        patch = masked_patch.data.cpu().numpy()\n",
    "        new_patch = np.zeros(patch_shape)\n",
    "        for i in range(new_patch.shape[0]): \n",
    "            for j in range(new_patch.shape[1]): \n",
    "                new_patch[i][j] = submatrix(patch[i][j])\n",
    " \n",
    "        patch = new_patch\n",
    "\n",
    "        # log to file  \n",
    "        progress_bar(batch_idx, len(train_loader), \"Train Patch Success: {:.3f}\".format(success/total))\n",
    "\n",
    "    return patch\n",
    "\n",
    "def test(classifier,test_loader, epoch, patch, patch_shape):\n",
    "    classifier.eval()\n",
    "    success = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.double().to(device)\n",
    "            labels = labels.to(device)\n",
    "        data, labels = Variable(data), Variable(labels)\n",
    "\n",
    "        prediction = classifier(data)\n",
    "\n",
    "        # only computer adversarial examples on examples that are originally classified correctly        \n",
    "        if prediction.data.max(1)[1][0] != labels.data[0]:\n",
    "            continue\n",
    "      \n",
    "        total += 1 \n",
    "        \n",
    "        # transform path\n",
    "        data_shape = data.data.cpu().numpy().shape\n",
    "        if patch_type == 'circle':\n",
    "            patch, mask, patch_shape = circle_transform(patch, data_shape, patch_shape, image_size)\n",
    "        elif patch_type == 'square':\n",
    "            patch, mask = square_transform(patch, data_shape, patch_shape, image_size)\n",
    "        patch, mask = torch.FloatTensor(patch), torch.FloatTensor(mask)\n",
    "        if torch.cuda.is_available():\n",
    "            patch, mask = patch.to(device), mask.to(device)\n",
    "        patch, mask = Variable(patch), Variable(mask)\n",
    " \n",
    "        adv_x = torch.mul((1-mask),data) + torch.mul(mask,patch)\n",
    "        adv_x = torch.clamp(adv_x, min_out, max_out)\n",
    "        \n",
    "        adv_label = classifier(adv_x).data.max(1)[1][0]\n",
    "        ori_label = labels.data[0]\n",
    "        \n",
    "        if adv_label == target:\n",
    "            success += 1\n",
    "       \n",
    "        masked_patch = torch.mul(mask, patch)\n",
    "        patch = masked_patch.data.cpu().numpy()\n",
    "        new_patch = np.zeros(patch_shape)\n",
    "        for i in range(new_patch.shape[0]): \n",
    "            for j in range(new_patch.shape[1]): \n",
    "                new_patch[i][j] = submatrix(patch[i][j])\n",
    " \n",
    "        patch = new_patch\n",
    "\n",
    "        # log to file  \n",
    "        progress_bar(batch_idx, len(test_loader), \"Test Success: {:.3f}\".format(success/total))\n",
    "\n",
    "def attack(classifier,x, patch, mask):\n",
    "    classifier.eval()\n",
    "\n",
    "    x_out = F.softmax(classifier(x))\n",
    "    target_prob = x_out.data[0][target]\n",
    "    \n",
    "    patch=patch.double()\n",
    "    mask=mask.double()\n",
    "    adv_x = (torch.mul((1-mask),x) + torch.mul(mask,patch)).double()\n",
    "#     adv_x=adv_x.double()\n",
    "#     print(adv_x.dtype)\n",
    "    \n",
    "    count = 0 \n",
    "   \n",
    "    while conf_target > target_prob:\n",
    "        count += 1\n",
    "        adv_x = Variable(adv_x.data, requires_grad=True)\n",
    "        \n",
    "        if not zoAdamm:\n",
    "            adv_out = F.log_softmax(classifier(adv_x))\n",
    "       \n",
    "            adv_out_probs, adv_out_labels = adv_out.max(1)\n",
    "        \n",
    "            Loss = -adv_out[0][target]\n",
    "            Loss.backward()\n",
    "     \n",
    "            adv_grad = adv_x.grad.clone()\n",
    "        \n",
    "            adv_x.grad.data.zero_()\n",
    "       \n",
    "            patch -= adv_grad \n",
    "        else:\n",
    "#             adv_x=adv_x.double()\n",
    "            def func(adv_input):\n",
    "#                 print(adv_input.dtype)\n",
    "                adv_out = F.log_softmax(classifier(adv_input))\n",
    "                Loss = -adv_out[0][target]\n",
    "                return Loss\n",
    "\n",
    "            opt=ZO_AdaMM(adv_x,func,timesteps=1,device=device)\n",
    "#             print(opt)\n",
    "            opt.step()\n",
    "#             print(opt.grad())\n",
    "            patch-=opt.gradFn()\n",
    "            \n",
    "        \n",
    "        adv_x = (torch.mul((1-mask),x) + torch.mul(mask,patch)).double()\n",
    "        adv_x = torch.clamp(adv_x, min_out, max_out)\n",
    " \n",
    "        out = F.softmax(classifier(adv_x))\n",
    "        target_prob = out.data[0][target]\n",
    "        #y_argmax_prob = out.data.max(1)[0][0]\n",
    "        \n",
    "        #print(count, conf_target, target_prob, y_argmax_prob)  \n",
    "\n",
    "        if count >= max_count:\n",
    "            break\n",
    "\n",
    "\n",
    "    return adv_x, mask, patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=np.random.rand(1,3,4)\n",
    "# np.prod(x.shape)\n",
    "# z=torch.rand(1,2,3).flatten()\n",
    "# x=torch.FloatTensor(np.random.rand(1,3,32,32))\n",
    "# net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [>..................................] Train Patch Success: 1.000 | Step: 6s249ms | Tot: 10m46 196/50000  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-544f4440cee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_patch_circle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-4c40ef193667>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(classifier, train_loader, epoch, patch, patch_shape)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0madv_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-4c40ef193667>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(classifier, x, patch, mask)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mZO_AdaMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m#             print(opt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;31m#             print(opt.grad())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mpatch\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-3a28c0fe847b>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                                       self.m.flatten().detach().numpy())).to(device)\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     self.grad= torch.tensor(np.matmul(self.alpha[t]*linalg.fractional_matrix_power(v_app_np,-0.5),\n\u001b[0m\u001b[1;32m     99\u001b[0m                                                       self.m.flatten().cpu().detach().numpy())).to(device)\n\u001b[1;32m    100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/matfuncs.py\u001b[0m in \u001b[0;36mfractional_matrix_power\u001b[0;34m(A, t)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matfuncs_inv_ssq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matfuncs_inv_ssq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fractional_matrix_power\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/_matfuncs_inv_ssq.py\u001b[0m in \u001b[0;36m_fractional_matrix_power\u001b[0;34m(A, p)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_power\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;31m# Compute singular values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvdvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m     \u001b[0;31m# Inverse scaling and squaring cannot deal with a singular matrix,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;31m# because the process of repeatedly taking square roots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvdvals\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         return svd(a, compute_uv=0, overwrite_a=overwrite_a,\n\u001b[0;32m--> 228\u001b[0;31m                    check_finite=False)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0;32m--> 129\u001b[0;31m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "patch,patch_shape = init_patch_circle(image_size,patch_size)\n",
    "for epoch in range(1,2):\n",
    "    patch=train(net,train_loader,epoch,patch,patch_shape)\n",
    "    test(net,test_loader,epoch,patch,patch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
